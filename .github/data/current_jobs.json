[
  {
    "job_id": "D-LGq5o0FMB3KQT1AAAAAA==",
    "job_title": "Analytics Engineer",
    "employer_name": "Advocate Aurora Health",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRmPrUobFkxZ6o2Sn3cafDGFnva_mdPRfZBzxfr&s=0",
    "employer_website": "https://www.advocatehealth.org",
    "job_publisher": "ZipRecruiter",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.ziprecruiter.com/c/Advocate-Aurora-Health/Job/Analytics-Engineer/-in-Winston-Salem,NC?jid=005a1efa1fd04622&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": true,
    "apply_options": [
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Advocate-Aurora-Health/Job/Analytics-Engineer/-in-Winston-Salem,NC?jid=005a1efa1fd04622&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/1318aed47e1192eb94800cfeecaa7e6f?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/analytics-engineer-at-atrium-health-wake-forest-baptist-4364119117?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/analytics-engineer_7ea1a473c37bb38a657b5fd8072026eeed264?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Tech Jobs Personalized",
        "apply_link": "https://builtin.com/job/analytics-engineer/8494007?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/analytics-engineer-atrium-health-JV_IC1139151_KO0,18_KE19,32.htm?jl=1010033785363&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/G_JVTmQOUaeMh48lerkstc3sqW34SO6Fnteixh0m9yQsb3-OJ-cmpQ?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Talentify",
        "apply_link": "https://www.talentify.io/job/analytics-engineer-winston-salem-north-carolina-us-advocate-aurora-health-r200711?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Department:\n\n85000 Wake Forest University Health Sciences - Academic Deans Office\n\nStatus:\n\nFull time\n\nBenefits Eligible:\n\nYes\n\nHours Per Week:\n\n40\n\nSchedule Details/Additional Information:\n\nTo achieve excellence and guide strategy, Wake Forest University School of Medicine (WFUSM) seeks to have measurable, transparent, and scalable indicators of our growth and performance in core missions of education, research, and academically integrated clinical care. The CAPTURE (Centralized Analytic Platform for Performance, Transparency, Utilization, and Real-Time Excellence) initiative will develop a series of integrated data dashboards across our core missions, enabling faculty, staff, and leadership to continuously monitor and improve their performance and effectiveness at the School and across the clinical enterprise.\n\nThe DIVE team (Data, Integration, Visualization, Evaluation) is seeking an analytics engineer to drive growth and maintenance of education and research data warehouses, academic applications, and the informatics components of strategic projects. This role will specifically support the CAPTURE initiative under the leadership of the inaugural Office of Institutional Learning and Transformation at WFUSM.\n\nThe analytics engineer will be responsible for transforming raw data into robust, high-level models that support reporting and dashboard creation. This role emphasizes model design and implementation, data quality, standardization, and documentation. The analytics engineer will collaborate closely with data engineers and BI/reporting teams, apply strong SQL and dimensional modeling skills, and may develop subject matter expertise in specific data domains while maintaining broad familiarity to ensure cross-team support and avoid silos.\n\nProficiency in Python required, Snowflake and dbt core preferred.\n\nPay Range\n$30.70 - $46.05\n\nEDUCATION/EXPERIENCE: Bachelor's degree with computer courses. Two years' experience in computer programming or operations research; or, an equivalent combination of education and experience in computer programming. LICENSURE, CERTIFICATION, and/or REGISTRATION: N/A ESSENTIAL FUNCTIONS: 1. Oversees all phases of database design, development, management and reporting for medium-sized projects. 2. Consults with users on project design needs. Maintains a professional relationship with project personnel. 3. Maintains software and troubleshoot simple software products. 4. Performs a range of ad hoc queries to databases and the implementation of automated reporting schemes. Analyzes quality control needs of moderate sized projects. 5. Performs a wide variety of data transfers and conversions. 6. Creates and maintains user manuals and documentation of software products. 7. Design and implements a comprehensive software testing plan for software products. 8. Performs other related duties incidental to work described herein. SKILLS/QUALIFICATIONS: Strong initiative and proven ability to work independently Ability to communicate on a professional level with customers and staff Superior problem solving skills WORK ENVIRONMENT: Comfortable, well-lit office setting Occasionally subject to long and/or irregular hours Subject to interruptions PHYSICAL REQUIREMENTS: 0% 35% 65% to to to 35% 65% 100% N/A Activity X Standing X Walking X Sitting X Bending X Reaching with arms X Finger and hand dexterity X Talking X Hearing X Seeing Lifting, carrying, pushing and or pulling: X 20 lbs. maximum X 50 lbs. maximum X 100 lbs. maximum\n\nOur CommitmenttoYou:\n\nAdvocate Health offers a comprehensive suite of Total Rewards: benefits and well-being programs, competitive compensation, generous retirement offerings, programs that invest in your career development and so much more - so you can live fully at and away from work, including:\n\nCompensation\n• Base compensation listed within the listed pay range based on factors such as qualifications, skills, relevant experience, and/or training\n• Premium pay such as shift, on call, and more based on a teammate's job\n• Incentive pay for select positions\n• Opportunity for annual increases based on performance\n\nBenefits and more\n• Paid Time Off programs\n• Health and welfare benefits such as medical, dental, vision, life, andShort- and Long-Term Disability\n• Flexible Spending Accounts for eligible health care and dependent care expenses\n• Family benefits such as adoption assistance and paid parental leave\n• Defined contribution retirement plans with employer match and other financial wellness programs\n• Educational Assistance Program\n\nAbout Advocate Health\n\nAdvocate Health is the third-largest nonprofit, integrated health system in the United States, created from the combination of Advocate Aurora Health and Atrium Health. Providing care under the names Advocate Health Care in Illinois; Atrium Health in the Carolinas, Georgia and Alabama; and Aurora Health Care in Wisconsin, Advocate Health is a national leader in clinical innovation, health outcomes, consumer experience and value-based care. Headquartered in Charlotte, North Carolina, Advocate Health services nearly 6 million patients and is engaged in hundreds of clinical trials and research studies, with Wake Forest University School of Medicine serving as the academic core of the enterprise. It is nationally recognized for its expertise in cardiology, neurosciences, oncology, pediatrics and rehabilitation, as well as organ transplants, burn treatments and specialized musculoskeletal programs. Advocate Health employs 155,000 teammates across 69 hospitals and over 1,000 care locations, and offers one of the nation's largest graduate medical education programs with over 2,000 residents and fellows across more than 200 programs. Committed to providing equitable care for all, Advocate Health provides more than $6 billion in annual community benefits.",
    "job_is_remote": false,
    "job_posted_at": "2 days ago",
    "job_posted_at_timestamp": 1771027200,
    "job_posted_at_datetime_utc": "2026-02-14T00:00:00.000Z",
    "job_location": "Winston-Salem, NC",
    "job_city": "Winston-Salem",
    "job_state": "North Carolina",
    "job_country": "US",
    "job_latitude": 36.0948221,
    "job_longitude": -80.2434028,
    "job_benefits": [
      "dental_coverage",
      "health_insurance",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DD-LGq5o0FMB3KQT1AAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_min_salary": 30.7,
    "job_max_salary": 46.05,
    "job_salary_period": "HOUR",
    "job_highlights": {
      "Qualifications": [
        "EDUCATION/EXPERIENCE: Bachelor's degree with computer courses",
        "Two years' experience in computer programming or operations research; or, an equivalent combination of education and experience in computer programming",
        "LICENSURE, CERTIFICATION, and/or REGISTRATION: N/A ESSENTIAL FUNCTIONS: 1",
        "Maintains a professional relationship with project personnel",
        "SKILLS/QUALIFICATIONS: Strong initiative and proven ability to work independently Ability to communicate on a professional level with customers and staff Superior problem solving skills WORK ENVIRONMENT: Comfortable, well-lit office setting Occasionally subject to long and/or irregular hours Subject to interruptions PHYSICAL REQUIREMENTS: 0% 35% 65% to to to 35% 65% 100% N/A Activity X Standing X Walking X Sitting X Bending X Reaching with arms X Finger and hand dexterity X Talking X Hearing X Seeing Lifting, carrying, pushing and or pulling: X 20 lbs",
        "maximum X 50 lbs",
        "maximum X 100 lbs"
      ],
      "Benefits": [
        "$30.70 - $46.05",
        "Advocate Health offers a comprehensive suite of Total Rewards: benefits and well-being programs, competitive compensation, generous retirement offerings, programs that invest in your career development and so much more - so you can live fully at and away from work, including:",
        "Base compensation listed within the listed pay range based on factors such as qualifications, skills, relevant experience, and/or training",
        "Premium pay such as shift, on call, and more based on a teammate's job",
        "Incentive pay for select positions",
        "Opportunity for annual increases based on performance",
        "Benefits and more",
        "Paid Time Off programs",
        "Health and welfare benefits such as medical, dental, vision, life, andShort- and Long-Term Disability",
        "Flexible Spending Accounts for eligible health care and dependent care expenses",
        "Family benefits such as adoption assistance and paid parental leave",
        "Defined contribution retirement plans with employer match and other financial wellness programs",
        "Educational Assistance Program",
        "Committed to providing equitable care for all, Advocate Health provides more than $6 billion in annual community benefits"
      ],
      "Responsibilities": [
        "The CAPTURE (Centralized Analytic Platform for Performance, Transparency, Utilization, and Real-Time Excellence) initiative will develop a series of integrated data dashboards across our core missions, enabling faculty, staff, and leadership to continuously monitor and improve their performance and effectiveness at the School and across the clinical enterprise",
        "The DIVE team (Data, Integration, Visualization, Evaluation) is seeking an analytics engineer to drive growth and maintenance of education and research data warehouses, academic applications, and the informatics components of strategic projects",
        "This role will specifically support the CAPTURE initiative under the leadership of the inaugural Office of Institutional Learning and Transformation at WFUSM",
        "The analytics engineer will be responsible for transforming raw data into robust, high-level models that support reporting and dashboard creation",
        "This role emphasizes model design and implementation, data quality, standardization, and documentation",
        "The analytics engineer will collaborate closely with data engineers and BI/reporting teams, apply strong SQL and dimensional modeling skills, and may develop subject matter expertise in specific data domains while maintaining broad familiarity to ensure cross-team support and avoid silos",
        "Oversees all phases of database design, development, management and reporting for medium-sized projects",
        "Consults with users on project design needs",
        "Maintains software and troubleshoot simple software products",
        "Performs a range of ad hoc queries to databases and the implementation of automated reporting schemes",
        "Analyzes quality control needs of moderate sized projects",
        "Performs a wide variety of data transfers and conversions",
        "Creates and maintains user manuals and documentation of software products",
        "Design and implements a comprehensive software testing plan for software products",
        "Performs other related duties incidental to work described herein"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-ziprecruiter-com-c-advocate-aurora-health-job-analytics-engineer-in-winston-salem-nc",
    "_source": "new_jobs"
  },
  {
    "job_id": "3fku_9fysjJRZIuuAAAAAA==",
    "job_title": "AI Analytics Engineer Washington, DC REMOTE 40",
    "employer_name": "Ark Solutions",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTI4YVw6ssg5R4ZkgAWCWYQoktfgdavC7UZx4-N&s=0",
    "employer_website": "https://arksolutionsinc.com",
    "job_publisher": "Jobilize",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.jobilize.com/job/us-ri-all-cities-ai-analytics-engineer-washington-dc-remote-40-ark?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Jobilize",
        "apply_link": "https://www.jobilize.com/job/us-ri-all-cities-ai-analytics-engineer-washington-dc-remote-40-ark?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "AI Analytics Engineer\n\nLocation: Washington, DC (REMOTE)\n\nDuration: 7+ months\n\nTasks to be performed:\n• Conduct a thorough assessment of the current HRTS applications landscape and document existing gaps and opportunities for AI and Automation.\n• Propose solutions and recommendations for system enhancements, including software updates, integrations, and process improvements.\n• Generate AI Models and Algorithms for HR purposes.\n• Develop project documentation, including project plans, timelines, and progress reports.\n• Communicate effectively with other team members, stakeholders, and business partners.\nRequired Skills:\n• Minimum of 3-5 years' experience in software development leveraging AI, Analytics Support, and Leadership role.\n• Four years' proven work experience as an AI Engineer or similar role.\n• Knowledge of Oracle Forms/Reports, SAP ERP, WebSphere, Tomcat, Java, Python, and GitHub.\nEducation:\n• A four-year degree from an accredited College/University in the applicable field of services is preferred or additional 4 years of relevant work experience is required.",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Rhode Island",
    "job_city": null,
    "job_state": "Rhode Island",
    "job_country": "US",
    "job_latitude": 41.5800945,
    "job_longitude": -71.4774291,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D3fku_9fysjJRZIuuAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Minimum of 3-5 years' experience in software development leveraging AI, Analytics Support, and Leadership role",
        "Four years' proven work experience as an AI Engineer or similar role",
        "Knowledge of Oracle Forms/Reports, SAP ERP, WebSphere, Tomcat, Java, Python, and GitHub"
      ],
      "Responsibilities": [
        "Conduct a thorough assessment of the current HRTS applications landscape and document existing gaps and opportunities for AI and Automation",
        "Propose solutions and recommendations for system enhancements, including software updates, integrations, and process improvements",
        "Generate AI Models and Algorithms for HR purposes",
        "Develop project documentation, including project plans, timelines, and progress reports",
        "Communicate effectively with other team members, stakeholders, and business partners"
      ]
    },
    "job_onet_soc": "15111100",
    "job_onet_job_zone": "5",
    "id": "www-jobilize-com-job-us-ri-all-cities-ai-analytics-engineer-washington-dc-remote-40-ark",
    "_source": "new_jobs"
  },
  {
    "job_id": "zfD8D0M8uxVfRNpfAAAAAA==",
    "job_title": "Analytics Engineer",
    "employer_name": "Hearst",
    "employer_logo": null,
    "employer_website": "https://www.hearst.com",
    "job_publisher": "Sign In",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://eevd.fa.us6.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/requisitions/preview/2026058?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Sign In",
        "apply_link": "https://eevd.fa.us6.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/requisitions/preview/2026058?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Hearst/Job/Analytics-Engineer/-in-Charlotte,NC?jid=c7558868074bbdef&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Career.io",
        "apply_link": "https://career.io/job/analytics-engineer-charlotte-hearst-communications-b17bfbb0a880de508a0d7afa6d4c3e88?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/analytics-engineer-at-hearst-television-charlotte-4364464181?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/f8d07f12457608b4310958373c78053f?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/analytics-engineer_7ea1ad5d85d0b8433e7b78b8b3e3cb87e37fc?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Broadcast Career Link",
        "apply_link": "https://jobs.broadcastcareerlink.com/job/analytics-engineer/82498609/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Experteer",
        "apply_link": "https://us.experteer.com/career/view-jobs/analytics-engineer-charlotte-nc-usa-56181061?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Hearst Television (HTV) is hiring an Analytics Engineer. The ideal candidate will act as the vital bridge between raw data and executive insights. You will take \"Bronze\" data and transform it into high-value Silver (Cleansed) and Gold (Aggregated) layers. Your primary goal is to codify complex media sales logic such as Revenue Pacing, Share of Wallet, and Yield into high-performance Semantic Models that power our Power BI dashboards and AI Data Agents. This role ensures our data is not just accessible, but actionable and intelligent.\n\nWhat You’ll Do\n\n· Medallion Transformation: Use Spark and SQL to architect the Silver and Gold layers of our Lakehouse, ensuring all data is rigorously tested, clean, and documented.\n\n· Semantic Modeling: Design and maintain the Microsoft Fabric Semantic Model (Direct Lake mode) to provide a \"Single Source of Truth\" across the entire organization.\n\n· Business Logic Codification: Partner closely with Sales and Finance stakeholders to translate \"What\" and \"Why\" business questions into precise technical data definitions.\n\n· AI Data Readiness: Structure data specifically for LLM consumption, enabling our AI Data Agents to accurately navigate complex hierarchies of stations, advertisers, and categories.\n\n· Data Governance & Security: Implement Row-Level Security (RLS) and maintain data lineage to ensure compliance with Hearst’s unified data strategy.\n\n· Technical Leadership: Lead the design of project-specific data models, prepare design specifications, and conduct feature estimations in collaboration with cross-functional teams.\n\n· Optimization & RCA: Perform root cause analysis on anomalies and implement solutions to minimize points of failure and optimize data pipeline performance.\n\nRequirements\n\n· Experience: 7+ years in business analytics, data modeling, or data engineering (or a Master’s degree with 5+ years of experience).\n\n· Modeling Expertise: 5+ years of deep experience with relational modeling concepts and Microsoft tabular semantic models.\n\n· Technical Proficiency: Expert-level SQL skills and 5+ years of experience with Power BI, DAX, and Spark (Spark SQL/PySpark/Scala).\n\n· Platform Knowledge: Strong hands-on experience with Microsoft Fabric tools and the Delta Lake format.\n\n· Logic & Design: Demonstrated experience translating complex business requirements into technical requirements using Star Schema/Dimensional modeling.\n\n· DevOps: Familiarity with Git, CI/CD, and modern development workflows.\n\n· Communication: Proven ability to collaborate with stakeholders and escalate data requirements or constraints effectively.\n\nPreferred Qualifications\n\n· Familiarity with governance, security best practices, and performance tuning in a cloud environment.\n\n· Experience in the media or broadcasting industry is a plus.\n\n· Knowledge of serverless architectures and containerized deployment.\n\nValues in Action\n\nAt Hearst Television we tell stories every day. Stories about people of all backgrounds, perspectives, and identities. That’s why, behind the scenes, we believe in being an organization that fosters collaboration and open communication, ensuring that the content we create is authentic, accurate, and connected to the communities we serve.\n\nBenefits\n\nHearst's benefit programs are modern, flexible and designed to focus on you. As a Hearst employee, you and your spouse or partner or dependents would have access to the following benefits:\n\n· Medical | Dental | Vision\n\n· 401(k) matching\n\n· Emotional Wellness Support\n\n· Paid Time Off & Parental Leave\n\n· LGBTQ+ Health Services",
    "job_is_remote": false,
    "job_posted_at": "3 days ago",
    "job_posted_at_timestamp": 1770940800,
    "job_posted_at_datetime_utc": "2026-02-13T00:00:00.000Z",
    "job_location": "Charlotte, NC",
    "job_city": "Charlotte",
    "job_state": "North Carolina",
    "job_country": "US",
    "job_latitude": 35.2270768,
    "job_longitude": -80.84089329999999,
    "job_benefits": [
      "paid_time_off",
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DzfD8D0M8uxVfRNpfAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Experience: 7+ years in business analytics, data modeling, or data engineering (or a Master’s degree with 5+ years of experience)",
        "Modeling Expertise: 5+ years of deep experience with relational modeling concepts and Microsoft tabular semantic models",
        "Technical Proficiency: Expert-level SQL skills and 5+ years of experience with Power BI, DAX, and Spark (Spark SQL/PySpark/Scala)",
        "Platform Knowledge: Strong hands-on experience with Microsoft Fabric tools and the Delta Lake format",
        "Logic & Design: Demonstrated experience translating complex business requirements into technical requirements using Star Schema/Dimensional modeling",
        "DevOps: Familiarity with Git, CI/CD, and modern development workflows",
        "Communication: Proven ability to collaborate with stakeholders and escalate data requirements or constraints effectively"
      ],
      "Benefits": [
        "Hearst's benefit programs are modern, flexible and designed to focus on you",
        "Medical | Dental | Vision",
        "401(k) matching",
        "Emotional Wellness Support",
        "Paid Time Off & Parental Leave",
        "LGBTQ+ Health Services"
      ],
      "Responsibilities": [
        "The ideal candidate will act as the vital bridge between raw data and executive insights",
        "You will take \"Bronze\" data and transform it into high-value Silver (Cleansed) and Gold (Aggregated) layers",
        "Your primary goal is to codify complex media sales logic such as Revenue Pacing, Share of Wallet, and Yield into high-performance Semantic Models that power our Power BI dashboards and AI Data Agents",
        "Medallion Transformation: Use Spark and SQL to architect the Silver and Gold layers of our Lakehouse, ensuring all data is rigorously tested, clean, and documented",
        "Semantic Modeling: Design and maintain the Microsoft Fabric Semantic Model (Direct Lake mode) to provide a \"Single Source of Truth\" across the entire organization",
        "Business Logic Codification: Partner closely with Sales and Finance stakeholders to translate \"What\" and \"Why\" business questions into precise technical data definitions",
        "AI Data Readiness: Structure data specifically for LLM consumption, enabling our AI Data Agents to accurately navigate complex hierarchies of stations, advertisers, and categories",
        "Data Governance & Security: Implement Row-Level Security (RLS) and maintain data lineage to ensure compliance with Hearst’s unified data strategy",
        "Technical Leadership: Lead the design of project-specific data models, prepare design specifications, and conduct feature estimations in collaboration with cross-functional teams",
        "Optimization & RCA: Perform root cause analysis on anomalies and implement solutions to minimize points of failure and optimize data pipeline performance"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "eevd-fa-us6-oraclecloud-com-hcmui-candidateexperience-en-sites-cx_1-requisitions-preview-2026058",
    "_source": "new_jobs"
  },
  {
    "job_id": "tYKJ_R_W-BuLd6exAAAAAA==",
    "job_title": "Digital – Manager, Data and Analytics Engineer",
    "employer_name": "140 Pfizer Inc",
    "employer_logo": null,
    "employer_website": null,
    "job_publisher": "Workday",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://pfizer.wd1.myworkdayjobs.com/en-US/PfizerCareers/job/Manager---HR---Corporate-Functions-Data---Analytics-Engineering_4939096-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Workday",
        "apply_link": "https://pfizer.wd1.myworkdayjobs.com/en-US/PfizerCareers/job/Manager---HR---Corporate-Functions-Data---Analytics-Engineering_4939096-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=1ed9c59354463a7a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/digital-manager-data-and-analytics-engineer-pfizer-JV_IC1154429_KO0,43_KE44,50.htm?jl=1009944999383&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Xtalks",
        "apply_link": "https://xtalks.com/job/digital-manager-data-and-analytics-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/3XGeL-WXgBE-FTdj_osHbQ6EYiGJAyBKM4Z-3WaPWjRpllde0xE8PA?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/621f15d6bda660c2123665511b18f9a7?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/digital-%E2%80%93-manager-data-and-analytics-engineer-at-pfizer-4369276254?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "FactoryFix",
        "apply_link": "https://jobs.factoryfix.com/jobs/digital-manager-data-and-analytics-engineer--tampa--fl--4254991986--V2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Use Your Power for Purpose At Pfizer, our purpose—Breakthroughs that change patients’ lives—drives every decision we make. Digital & Technology accelerates this mission by turning data into insights that power smarter science, stronger operations, and an exceptional colleague experience. Within this organization, the Enabling Functions Creation Center (EFCC) supports HR, Finance, Global Business Services, and Legal with the digital capabilities they need to operate effectively and unlock value. As a hands‑on Manager - Data & Analytics Engineer, you will lead and build innovative data solutions that strengthen our enterprise data foundation, empower our enabling function partners, and help unleash the power of our people—ultimately supporting the breakthroughs that matter most to patients. What You Will Achieve As a hands-on engineer, you will build scalable data pipelines to provide accurate and impactful business analytics and insights Design and implementation of data architecture and infrastructure. Lead the development of data management strategies and policies. Manage a team of project data engineers and analysts, providing guidance and mentorship. Ensure data quality and integrity across all data platforms. Collaborate with cross-functional teams to align data initiatives with business goals. Develop and maintain data governance frameworks. Oversee the integration of new data technologies and tools. Ensure compliance with data privacy regulations and standards. Drive the optimization of data processing workflows and pipelines. Lead the development of analytics solutions to support business decision-making. Manage relationships with external data vendors and partners. Oversee the creation and maintenance of data documentation and metadata. Develop and monitor key performance indicators for data initiatives. Ensure the scalability and performance of data systems. Basic Qualifications: Candidates should possess a BA/BS with at least 4 years of experience, an MBA/MS with at least 2 years of experience, a PhD/JD with any years of experience, an associate's degree with at least 8 years of experience, or a high school diploma (or equivalent) with at least 10 years of relevant experience. Data Architecture Design: Designing and structuring modern databases and modern data systems: Expert Data Warehousing: Building and managing data warehouses (Preferably Snowflake): Expert SQL: Advanced querying and database management: Expert Data pipelines / ETL Processes: Designing and managing modern ETL (Extract, Transform, Load) processes and data engineering pipelines: Expert Data Integration: Combining and transforming data from different sources: Expert Cloud Platforms (e.g., AWS, Azure, Google Cloud): Managing data infrastructure on cloud platforms: Advanced Big Data Technologies (e.g., SnowFlake, Data Bricks, Spark): Handling and processing large datasets: Advanced Data Modeling: Creating data models to support analytics: Advanced Visual Analytics and Business Intelligence Tools: Using BI tools to derive insights from data: Advanced Data Governance: Implementing policies and procedures for data management: Advanced Data Visualization Tools (e.g., Tableau, Power BI): Creating visual representations of data and data story telling: Advanced Programming Languages (e.g., Python, R): Writing code for data manipulation and analysis: Expert Data Security: Implementing security measures to protect data: Intermediate Data Quality Management: Ensuring accuracy and consistency of data: Advanced Statistical Analysis: Applying statistical methods to analyze data: Intermediate Leadership: Guiding and motivating a team to achieve goals: Expert Strategic Thinking: Planning and executing long-term data strategies: Expert Communication: Clearly conveying complex data concepts to stakeholders: Advanced Problem Solving: Identifying and resolving data-related issues: Advanced Collaboration: Working effectively with cross-functional teams: Advanced Hands on experience with vibe coding and Generative AI based data pipeline and analytics solutions development to increase efficiency, reduce overall delivery cost and reduce time to market. Emerging skills Machine Learning: Applying machine learning techniques for data analysis: Intermediate Adaptability: Adjusting to new technologies and methodologies: Intermediate Critical Thinking: Analyzing data critically to derive insights: Advanced Time Management: Prioritizing tasks to meet deadlines: Advanced Decision Making: Making informed decisions based on data insights: Advanced Preferred Qualifications: People Analytics experience using SaaS tools such as Visier, One Model, Perceptyx, Workday Prism Analytics, Workday People Analytics, SAP Success Factors Workforce Analytics is a big plus. Familiarity with cloud/SaaS-based Human Capital Management (HCM) systems such as Workday is a big plus. Experience with Global HR data integration and prior experience with Mergers, Acquisitions, and Divestitures is a plus. Familiarity with EU Global Data Privacy Regulations (GDPR) and other related international regulations is nice to have. Prior experience with data architecture designs and data engineering development related to the GDPR and data privacy guiding principles such as data minimization, right to be forgotten, etc is nice to have. · Experience with Global HR data integration and prior experience with Mergers, Acquisitions, and Divestitures is a plus. Experience with Software engineering best practices, including but not limited to version control (Git/GitHub, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops is highly beneficial but not required. Experience with sourcing and modeling data from application APIs and publishing data and analytics services via APIs / Data Services is highly beneficial but not required · Experience deploying through an agile methodology and working in a SCRUM or SAFe team is highly beneficial but not required. 5 or more years of experience with one or more general-purpose data processing programming languages, including but not limited to: SQL, Scala, Python, Java, etc Architected end-to-end data pipelines with a major cloud stack is a plus · Experience in Cloud computing, machine learning, text analysis, NLP, and developing and deploying data and analytics services such as recommendation engines experience is a plus Domain experience in the Human Resources field Work Location Assignment: Hybrid The annual base salary for this position ranges from $99,200.00 to $160,500.00. In addition, this position is eligible for participation in Pfizer’s Global Performance Plan with a bonus target of 12.5% of the base salary and eligibility to participate in our share based long term incentive program. We offer comprehensive and generous benefits and programs to help our colleagues lead healthy lives and to support each of life’s moments. Benefits offered include a 401(k) plan with Pfizer Matching Contributions and an additional Pfizer Retirement Savings Contribution, paid vacation, holiday and personal days, paid caregiver/parental and medical leave, and health benefits to include medical, prescription drug, dental and vision coverage. Learn more at Pfizer Candidate Site – U.S. Benefits | (uscandidates.mypfizerbenefits.com). Pfizer compensation structures and benefit packages are aligned based on the location of hire. The United States salary range provided applies to the Tampa, FL location only. The salary range provided does not apply to any other United States location or locations outside of the United States. Relocation assistance may be available based on business needs and/or eligibility. Sunshine Act Pfizer reports payments and other transfers of value to health care providers as required by federal and state transparency laws and implementing regulations. These laws and regulations require Pfizer to provide government agencies with information such as a health care provider’s name, address and the type of payments or other value received, generally for public disclosure. Subject to further legal review and statutory or regulatory clarification, which Pfizer intends to pursue, reimbursement of recruiting expenses for licensed physicians may constitute a reportable transfer of value under the federal transparency law commonly known as the Sunshine Act. Therefore, if you are a licensed physician who incurs recruiting expenses as a result of interviewing with Pfizer that we pay or reimburse, your name, address and the amount of payments made currently will be reported to the government. If you have questions regarding this matter, please do not hesitate to contact your Talent Acquisition representative. EEO & Employment Eligibility Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. Pfizer also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as work authorization and employment eligibility verification requirements of the Immigration and Nationality Act and IRCA. Pfizer is an E-Verify employer. This position requires permanent work authorization in the United States. Pfizer endeavors to make www.pfizer.com/careers accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process and/or interviewing, please email disabilityrecruitment@pfizer.com. This is to be used solely for accommodation requests with respect to the accessibility of our website, online application process and/or interviewing. Requests for any other reason will not be returned. Information & Business Tech Pfizer careers are like no other. In our culture of individual ownership, we believe in our ability to improve future healthcare, and potential to transform millions of lives. We’re looking for new talent to join our global community, to unearth new innovative therapies that make the world a healthier place.",
    "job_is_remote": false,
    "job_posted_at": "12 days ago",
    "job_posted_at_timestamp": 1770163200,
    "job_posted_at_datetime_utc": "2026-02-04T00:00:00.000Z",
    "job_location": "Tampa, FL",
    "job_city": "Tampa",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 27.951689599999998,
    "job_longitude": -82.45875269999999,
    "job_benefits": [
      "dental_coverage",
      "health_insurance",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DtYKJ_R_W-BuLd6exAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {},
    "job_onet_soc": "11302100",
    "job_onet_job_zone": "4",
    "id": "pfizer-wd1-myworkdayjobs-com-en-us-pfizercareers-job-manager-hr-corporate-functions-data-analytics-engineering_4939096-2",
    "_source": "new_jobs"
  },
  {
    "job_id": "LnGFK8e-I20MJtnHAAAAAA==",
    "job_title": "SCM Analytics Engineer - Full-time",
    "employer_name": "Southern Glazer's Wine and Spirits",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSo589aPoxsES92lx6gGXgSyhXQjevcTInpnhA0&s=0",
    "employer_website": "https://www.southernglazers.com",
    "job_publisher": "Snagajob",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.snagajob.com/jobs/1160086327?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Snagajob",
        "apply_link": "https://www.snagajob.com/jobs/1160086327?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "**What You Need To Know**\n\nShape a remarkable future with us. Build a career working for an industry leader that truly invests in their people – and equips them with leading technology, continuous learning, and the ability to bring their best selves to work. As the premier wine and spirits distributor, Southern Glazer’s isn't just one of Forbes’ Top Private Companies; it's a family-owned business with deep roots dating back to 1933.\n\nThe reputation of Southern Glazer’s is well-established, and it's no surprise that we are regularly recognized for our culture. Southern Glazer’s has been recognized by Newsweek as one of America’s Greatest Workplaces for Inclusion and Diversity, as well as for Women and Parents and Families. These accolades speak volumes about our commitment to creating a supportive and inclusive culture of belonging for all employees.\n\nAs a full-time employee, you can choose from a wide-ranging menu of our Top Shelf Benefits, including comprehensive medical and prescription drug coverage, dental and vision plans, tax-saving Flexible Spending Accounts, disability coverage, life insurance plans, and a 401(k) plan. We also offer tuition assistance, a wellness program, parental leave, vacation accrual, paid sick leave, and more.\n\nBy joining Southern Glazer’s, you would be part of a team that values excellence, innovation, and community. This is more than just a job – it's an opportunity to build the future of beverage distribution and grow with a company that truly cares about its people.\n• *Must be eligible to work as a full-time employee in the US without sponsorship.**\n• *Overview**\n\nThe SCM Analytics Developer will partner with functional members of Supply Chain to understand the current and future business requirements. They will be responsible for gathering data across various sources, analyzing it, and providing insights used for informed decision-making. They will ensure the appropriate use of analytical tools so that analysis and reporting are accurate, timely, thorough, and professional. They will also optimize existing data processes and resources, setting clear goals and benchmarks for improvement, development, and effective management of sound business practices.\n• *Primary Responsibilities**\n\n+ Develop reporting on SAP Business Objects, Tableau Dashboards, and create Excel refreshable files through Open Database Connectivity (ODBC) connections and Power Queries\n\n+ Automate processes using Amazon Web Services (AWS), including Step Functions, EventBridge, Simple Storage Service (S3) Buckets, and AWS Glue. Additionally, leveraged SharePoint Site services—such as lists and workflows—integrated through Power Automate\n\n+ Maintain data quality through identifying issues, removing duplicates, data cleansing, and enriching data quality\n\n+ Develop, design, and manage efficient processes, tabular reports, list reports, score cards, dynamic models, and dashboards that effectively monitor various key performance indicators (KPI)s and assist the supply chain business teams\n\n+ Apply the appropriate use of analytical tools to optimize reporting for current business requirements and create new processes and solutions for future business requirements\n\n+ Provide mentoring and support to other analysts to assist in their development surrounding data, processes, reporting, and utilizing self-service tools\n\n+ Assist with timely, accurate, pertinent information and analysis, as well as aid in monitoring, evaluating, and improving performance and related metrics of the Supply Chain\n• *Additional Primary Responsibilities**\n\n+ Support the long-term vision of the supply chain through the effective implementation of data reporting\n\n+ Ability to understand and translate data into business insights\n\n+ Summarize analysis and findings for users\n\n+ Ability to join data from multiple systems and sources through the use of Excel, SQL, Python, AWS services, and other components\n\n+ Ability to mine large sets of data analytics and insights\n\n+ Perform other job-related duties as assigned\n• *Minimum Qualifications**\n\n+ Bachelor’s Degree and three years of experience or equivalent education and related experience\n\n+ Experience in data preparation, blending, discovery, and visualization using modern BI & Analytics tools such as AWS services like Step Functions, Glue, Sage Maker, and other components, SAP Business Objects, Tableau, Alteryx, and Excel\n\n+ Expert knowledge in Excel, including pivot tables, Power Queries, vlookup, and other advanced formulas\n\n+ Intermediate knowledge of SQL (Joins, Stored Procedures, Views, Jobs, and Troubleshooting)\n\n+ Experience developing, improving, and streamlining processes and reporting\n\n+ Thorough analytical, investigative, and problem-solving skills\n\n+ Timeliness, accuracy, and professionalism\n• *Physical Demands**\n\n+ Physical demands include a considerable amount of time sitting and typing/keyboarding, using a computer (e.g., keyboard, mouse, and monitor), or a mobile device\n\n+ Physical demands with activity or condition may occasionally include walking, bending, reaching, standing, squatting, and stooping\n\n+ May require occasional lifting/lowering, pushing, carrying, or pulling up to 20lbs\n• *EEO Statement**\n\nSouthern Glazer's Wine and Spirits, an Affirmative Action/EEO employer, prohibits discrimination and harassment of any type and provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. SGWS complies with all federal, state and local laws concerning consideration of a qualified applicant's arrest and/or criminal conviction records. Southern Glazer's Wine and Spirits provides competitive compensation based on estimated performance level consistent with the past relevant experience, knowledge, skills, abilities and education of employees. Unless otherwise expressly stated, any pay ranges posted here are estimates from outside of Southern Glazer's Wine and Spirits and do not reflect Southern Glazer's pay bands or ranges.\n\n\\#LI-JL1\n\n_If you have any questions or concerns about whether this posting complies/adheres with local pay transparency requirements, please contact the SGWS talent acquisition team at NationalTA@sgws.com_\n\nSouthern Glazer's Wine and Spirits provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\n• *What You Need To Know**\n\nShape a remarkable future with us. Build a career working for an industry leader that truly invests in their people – and equips them with leading technology, continuous learning, and the ability to bring their best selves to work. As the premier wine and spirits distributor, Southern Glazer’s isn't just one of Forbes’ Top Private Companies; it's a family-owned business with deep roots dating back to 1933.\n\nThe reputation of Southern Glazer’s is well-established, and it's no surprise that we are regularly recognized for our culture. Southern Glazer’s has been recognized by Newsweek as one of America’s Greatest Workplaces for Inclusion and Diversity, as well as for Women and Parents and Families. These accolades speak volumes about our commitment to creating a supportive and inclusive culture of belonging for all employees.\n\nAs a full-time employee, you can choose from a wide-ranging menu of our Top Shelf Benefits, including comprehensive medical and prescription drug coverage, dental and vision plans, tax-saving Flexible Spending Accounts, disability coverage, life insurance plans, and a 401(k) plan. We also offer tuition assistance, a wellness program, parental leave, vacation accrual, paid sick leave, and more.\n\nBy joining Southern Glazer’s, you would be part of a team that values excellence, innovation, and community. This is more than just a job – it's an opportunity to build the future of beverage distribution and grow with a company that truly cares about its people.\n• *Must be eligible to work as a full-time employee in the US without sponsorship.**\n• *Overview**\n\nThe SCM Analytics Developer will partner with functional members of Supply Chain to understand the current and future business requirements. They will be responsible for gathering data across various sources, analyzing it, and providing insights used for informed decision-making. They will ensure the appropriate use of analytical tools so that analysis and reporting are accurate, timely, thorough, and professional. They will also optimize existing data processes and resources, setting clear goals and benchmarks for improvement, development, and effective management of sound business practices.\n• *Primary Responsibilities**\n\n+ Develop reporting on SAP Business Objects, Tableau Dashboards, and create Excel refreshable files through Open Database Connectivity (ODBC) connections and Power Queries\n\n+ Automate processes using Amazon Web Services (AWS), including Step Functions, EventBridge, Simple Storage Service (S3) Buckets, and AWS Glue. Additionally, leveraged SharePoint Site services—such as lists and workflows—integrated through Power Automate\n\n+ Maintain data quality through identifying issues, removing duplicates, data cleansing, and enriching data quality\n\n+ Develop, design, and manage efficient processes, tabular reports, list reports, score cards, dynamic models, and dashboards that effectively monitor various key performance indicators (KPI)s and assist the supply chain business teams\n\n+ Apply the appropriate use of analytical tools to optimize reporting for current business requirements and create new processes and solutions for future business requirements\n\n+ Provide mentoring and support to other analysts to assist in their development surrounding data, processes, reporting, and utilizing self-service tools\n\n+ Assist with timely, accurate, pertinent information and analysis, as well as aid in monitoring, evaluating, and improving performance and related metrics of the Supply Chain\n• *Additional Primary Responsibilities**\n\n+ Support the long-term vision of the supply chain through the effective implementation of data reporting\n\n+ Ability to understand and translate data into business insights\n\n+ Summarize analysis and findings for users\n\n+ Ability to join data from multiple systems and sources through the use of Excel, SQL, Python, AWS services, and other components\n\n+ Ability to mine large sets of data analytics and insights\n\n+ Perform other job-related duties as assigned\n• *Minimum Qualifications**\n\n+ Bachelor’s Degree and three years of experience or equivalent education and related experience\n\n+ Experience in data preparation, blending, discovery, and visualization using modern BI & Analytics tools such as AWS services like Step Functions, Glue, Sage Maker, and other components, SAP Business Objects, Tableau, Alteryx, and Excel\n\n+ Expert knowledge in Excel, including pivot tables, Power Queries, vlookup, and other advanced formulas\n\n+ Intermediate knowledge of SQL (Joins, Stored Procedures, Views, Jobs, and Troubleshooting)\n\n+ Experience developing, improving, and streamlining processes and reporting\n\n+ Thorough analytical, investigative, and problem-solving skills\n\n+ Timeliness, accuracy, and professionalism\n• *Physical Demands**\n\n+ Physical demands include a considerable amount of time sitting and typing/keyboarding, using a computer (e.g., keyboard, mouse, and monitor), or a mobile device\n\n+ Physical demands with activity or condition may occasionally include walking, bending, reaching, standing, squatting, and stooping\n\n+ May require occasional lifting/lowering, pushing, carrying, or pulling up to 20lbs\n• *EEO Statement**\n\nSouthern Glazer's Wine and Spirits, an Affirmative Action/EEO employer, prohibits discrimination and harassment of any type and provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. SGWS complies with all federal, state and local laws concerning consideration of a qualified applicant's arrest and/or criminal conviction records. Southern Glazer's Wine and Spirits provides competitive compensation based on estimated performance level consistent with the past relevant experience, knowledge, skills, abilities and education of employees. Unless otherwise expressly stated, any pay ranges posted here are estimates from outside of Southern Glazer's Wine and Spirits and do not reflect Southern Glazer's pay bands or ranges.\n\n\\#LI-JL1\n\n_If you have any questions or concerns about whether this posting complies/adheres with local pay transparency requirements, please contact the SGWS talent acquisition team at NationalTA@sgws.com_\n\nSouthern Glazer's Wine and Spirits provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",
    "job_is_remote": false,
    "job_posted_at": "4 days ago",
    "job_posted_at_timestamp": 1770854400,
    "job_posted_at_datetime_utc": "2026-02-12T00:00:00.000Z",
    "job_location": "Miramar, FL",
    "job_city": "Miramar",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 25.9860762,
    "job_longitude": -80.30356019999999,
    "job_benefits": [
      "health_insurance",
      "dental_coverage",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DLnGFK8e-I20MJtnHAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Ability to understand and translate data into business insights",
        "Ability to join data from multiple systems and sources through the use of Excel, SQL, Python, AWS services, and other components",
        "Ability to mine large sets of data analytics and insights",
        "Bachelor’s Degree and three years of experience or equivalent education and related experience",
        "Experience in data preparation, blending, discovery, and visualization using modern BI & Analytics tools such as AWS services like Step Functions, Glue, Sage Maker, and other components, SAP Business Objects, Tableau, Alteryx, and Excel",
        "Expert knowledge in Excel, including pivot tables, Power Queries, vlookup, and other advanced formulas",
        "Intermediate knowledge of SQL (Joins, Stored Procedures, Views, Jobs, and Troubleshooting)",
        "Experience developing, improving, and streamlining processes and reporting",
        "Thorough analytical, investigative, and problem-solving skills",
        "Timeliness, accuracy, and professionalism",
        "Physical demands include a considerable amount of time sitting and typing/keyboarding, using a computer (e.g., keyboard, mouse, and monitor), or a mobile device",
        "Physical demands with activity or condition may occasionally include walking, bending, reaching, standing, squatting, and stooping",
        "May require occasional lifting/lowering, pushing, carrying, or pulling up to 20lbs",
        "Ability to understand and translate data into business insights",
        "Summarize analysis and findings for users",
        "Ability to join data from multiple systems and sources through the use of Excel, SQL, Python, AWS services, and other components",
        "Ability to mine large sets of data analytics and insights",
        "Bachelor’s Degree and three years of experience or equivalent education and related experience",
        "Experience in data preparation, blending, discovery, and visualization using modern BI & Analytics tools such as AWS services like Step Functions, Glue, Sage Maker, and other components, SAP Business Objects, Tableau, Alteryx, and Excel",
        "Expert knowledge in Excel, including pivot tables, Power Queries, vlookup, and other advanced formulas",
        "Intermediate knowledge of SQL (Joins, Stored Procedures, Views, Jobs, and Troubleshooting)",
        "Experience developing, improving, and streamlining processes and reporting",
        "Thorough analytical, investigative, and problem-solving skills",
        "Timeliness, accuracy, and professionalism",
        "Physical demands include a considerable amount of time sitting and typing/keyboarding, using a computer (e.g., keyboard, mouse, and monitor), or a mobile device",
        "Physical demands with activity or condition may occasionally include walking, bending, reaching, standing, squatting, and stooping",
        "May require occasional lifting/lowering, pushing, carrying, or pulling up to 20lbs"
      ],
      "Benefits": [
        "As a full-time employee, you can choose from a wide-ranging menu of our Top Shelf Benefits, including comprehensive medical and prescription drug coverage, dental and vision plans, tax-saving Flexible Spending Accounts, disability coverage, life insurance plans, and a 401(k) plan",
        "We also offer tuition assistance, a wellness program, parental leave, vacation accrual, paid sick leave, and more",
        "As a full-time employee, you can choose from a wide-ranging menu of our Top Shelf Benefits, including comprehensive medical and prescription drug coverage, dental and vision plans, tax-saving Flexible Spending Accounts, disability coverage, life insurance plans, and a 401(k) plan",
        "We also offer tuition assistance, a wellness program, parental leave, vacation accrual, paid sick leave, and more",
        "*Must be eligible to work as a full-time employee in the US without sponsorship.**"
      ],
      "Responsibilities": [
        "The SCM Analytics Developer will partner with functional members of Supply Chain to understand the current and future business requirements",
        "They will be responsible for gathering data across various sources, analyzing it, and providing insights used for informed decision-making",
        "They will ensure the appropriate use of analytical tools so that analysis and reporting are accurate, timely, thorough, and professional",
        "They will also optimize existing data processes and resources, setting clear goals and benchmarks for improvement, development, and effective management of sound business practices",
        "Develop reporting on SAP Business Objects, Tableau Dashboards, and create Excel refreshable files through Open Database Connectivity (ODBC) connections and Power Queries",
        "Automate processes using Amazon Web Services (AWS), including Step Functions, EventBridge, Simple Storage Service (S3) Buckets, and AWS Glue",
        "Additionally, leveraged SharePoint Site services—such as lists and workflows—integrated through Power Automate",
        "Maintain data quality through identifying issues, removing duplicates, data cleansing, and enriching data quality",
        "Develop, design, and manage efficient processes, tabular reports, list reports, score cards, dynamic models, and dashboards that effectively monitor various key performance indicators (KPI)s and assist the supply chain business teams",
        "Apply the appropriate use of analytical tools to optimize reporting for current business requirements and create new processes and solutions for future business requirements",
        "Provide mentoring and support to other analysts to assist in their development surrounding data, processes, reporting, and utilizing self-service tools",
        "Assist with timely, accurate, pertinent information and analysis, as well as aid in monitoring, evaluating, and improving performance and related metrics of the Supply Chain",
        "*Additional Primary Responsibilities**",
        "Support the long-term vision of the supply chain through the effective implementation of data reporting",
        "Summarize analysis and findings for users",
        "Perform other job-related duties as assigned",
        "The SCM Analytics Developer will partner with functional members of Supply Chain to understand the current and future business requirements",
        "They will be responsible for gathering data across various sources, analyzing it, and providing insights used for informed decision-making",
        "They will ensure the appropriate use of analytical tools so that analysis and reporting are accurate, timely, thorough, and professional",
        "They will also optimize existing data processes and resources, setting clear goals and benchmarks for improvement, development, and effective management of sound business practices",
        "Develop reporting on SAP Business Objects, Tableau Dashboards, and create Excel refreshable files through Open Database Connectivity (ODBC) connections and Power Queries",
        "Automate processes using Amazon Web Services (AWS), including Step Functions, EventBridge, Simple Storage Service (S3) Buckets, and AWS Glue",
        "Additionally, leveraged SharePoint Site services—such as lists and workflows—integrated through Power Automate",
        "Maintain data quality through identifying issues, removing duplicates, data cleansing, and enriching data quality",
        "Develop, design, and manage efficient processes, tabular reports, list reports, score cards, dynamic models, and dashboards that effectively monitor various key performance indicators (KPI)s and assist the supply chain business teams",
        "Apply the appropriate use of analytical tools to optimize reporting for current business requirements and create new processes and solutions for future business requirements",
        "Provide mentoring and support to other analysts to assist in their development surrounding data, processes, reporting, and utilizing self-service tools",
        "Assist with timely, accurate, pertinent information and analysis, as well as aid in monitoring, evaluating, and improving performance and related metrics of the Supply Chain",
        "*Additional Primary Responsibilities**",
        "Support the long-term vision of the supply chain through the effective implementation of data reporting",
        "Perform other job-related duties as assigned"
      ]
    },
    "job_onet_soc": "13108100",
    "job_onet_job_zone": "4",
    "id": "www-snagajob-com-jobs-1160086327",
    "_source": "new_jobs"
  },
  {
    "job_id": "_rvXxbAeuJ7yr3ORAAAAAA==",
    "job_title": "Staff Analytics Engineer",
    "employer_name": "Coinbase",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ5OL4_4viaeK1GNWKlusWTU0WPLNurfsu9Lsbt&s=0",
    "employer_website": "https://www.coinbase.com",
    "job_publisher": "WhatJobs",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.whatjobs.com/jobs/staff-analytics-engineer?id=2454709003&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "WhatJobs",
        "apply_link": "https://www.whatjobs.com/jobs/staff-analytics-engineer?id=2454709003&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Ready to be pushed beyond what you think you’re capable of?\n\nAt Coinbase, our mission is to increase economic freedom in the world. It’s a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform — and with it, the future global financial system.\n\nTo achieve our mission, we’re seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the company’s hardest problems.\n\nOur work culture is intense and isn’t for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, there’s no better place to be.\n\nWhile many roles at Coinbase are remote-first, we are not remote-only. In-person participation is required throughout the year. Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment. Attendance is expected and fully supported.\n\nThe CX Analytics Engineering team bridges the gap between data engineering, data science, and business analytics by building scalable, impactful data solutions. We transform raw data into actionable insights through robust pipelines, well-designed data models, and tools that empower stakeholders across the organization to make data-driven decisions. As an Analytics Engineer on our team, you will function as a force multiplier, enabling Analytics and Operations to function seamlessly at scale. You’ll have the opportunity to translate complex technical and operational requirements into easily consumable front end data solutions, while also heavily influencing the overarching strategy for CX Analytics and its partners.\n\nOur team combines technical expertise with a deep understanding of the business to unlock the full potential of our data. We prioritize data quality, reliability, and usability, ensuring stakeholders can rely on our data to drive meaningful outcomes.\n\nWhat We Do\n\nTrusted Data Sources : Develop and maintain foundational data models that serve as the single source of truth for analytics across the organization.\n\nActionable Insights : Empower stakeholders by translating business requirements into scalable data models, dashboards, and tools.\n\nCross-Functional Collaboration : Partner with engineering, data science, product, and business teams to ensure alignment on priorities and data solutions.\n\nScalable Data Products : Build frameworks, tools, and workflows that maximize efficiency for data users, while maintaining high standards of data quality and performance.\n\nOutcome-Focused Solutions : Use modern development and analytics tools to deliver value quickly, while ensuring long-term maintainability.\n\nWhat you’ll be doing (ie. job duties):**.\n\nAnalytics engineer is a hybrid Data Engineer/Data Scientist/Business Analyst role that has the expertise to understand data flows end to end, and the engineering toolkit to extract the most value out of it indirectly (building tables) or directly (solving problems, delivering insights).\n\nExpectations\n• Be the expert: *Quickly build subject matter expertise in a specific business area and data domain. Understand the data flows from creation, ingestion, transformation, and delivery.\n\nExamples:\n\nStep into a new line of business and work with Engineering and Product partners to deliver first data pipelines and insights.Communicate with engineering teams to fix data gaps for downstream data users.Take initiative and accountability for fixing issues anywhere in the stack.\n\nGenerate business value: Interface with stakeholders on data and product teams to deliver the most commercial value from data (directly or indirectly).\n\nExamples:\n\nBuild out a new data model allowing multiple downstream DS teams to more easily unlock business value through experimentation and ad hoc analysis.Combine Eng details of the algo engine with stats and data expertise to come up with feasible solutions for Eng to make the algo better.Work with PMs to tie together new x-PG, and x-Product data into one holistic framework to optimize key financing product business metrics.\n\nFocus on outcomes not tools: Use a variety of frameworks and paradigms to identify the best-fit tools to deliver value.\n\nExamples:\n\nDevelop new abstractions (e.g. UDFs, Python packages, dashboards) to support scalable data workflows/infra.Stand up a framework for building data apps internally, enabling other DS teams to quickly add value.Use established tools with mastery (e.g. Google Sheets, SQL) to quickly deliver impact when speed is top priority.**\n\nWhat We Look For in You\n\nIn addition to out of the box thinking, attention to detail, a sense of urgency and a high degree of autonomy and accountability, we expect you to have the following skills:\n• Customer Support Data Experience: *Familiarity with data elements and processes supporting successful Customer Support initiatives, including employee performance monitoring, workforce/staffing inputs, and the handling of sensitive PII across a broad stakeholder base.\n\nData Modeling Expertise : Strong understanding of best practices for designing modular and reusable data models (e.g., star schemas, snowflake schemas).\n• Prompt Design and Engineering: *Expertise in prompt engineering and design for LLMs (e.g., GPT), including creating, refining, and optimizing prompts to improve response accuracy, relevance, and performance for internal tools and use cases.\n\nAdvanced SQL : Proficiency in advanced SQL techniques for data transformation, querying, and optimization.\n\nIntermediate to Advanced Python : Expertise in scripting and automation, with experience in Object-Oriented Programming (OOP) and building scalable frameworks.\n\nCollaboration and Communication : Strong ability to translate technical concepts into business value for cross-functional stakeholders. Proven ability to manage projects and communicate effectively across teams.\n\nData Pipeline Development : Experience building, maintaining, and optimizing ETL/ELT pipelines, using modern tools like dbt, Airflow, or similar.\n\nData Visualization : Proficiency in building polished dashboards using tools like Looker, Tableau, Superset, or Python visualization libraries (Matplotlib, Plotly).\n\nDevelopment Tools : Familiarity with version control (GitHub), CI/CD, and modern development workflows.\n\nData Architecture : Knowledge of modern data lake/warehouse architectures (e.g., Snowflake, Databricks) and transformation frameworks.\n\nBusiness Acumen : Ability to understand and address business challenges through analytics engineering.\n• Data savvy: *Familiarity with statistics and probability.\n\nBonus Skills :\n\nExperience with cloud platforms (e.g., AWS, GCP).\n\nFamiliarity with Docker or Kubernetes.\n\nJob #: P71393\n\nPay Transparency Notice : Depending on your work location, the target annual *base *salary for this position can range as detailed below. Full time offers from Coinbase also include bonus eligibility + equity eligibility + benefits (including medical, dental, vision and 401(k)).\n\nBase salary range shown. Total compensation also includes equity and bonus eligibility and benefits:\n\n$207,485—$244,100 USD\n\nPlease be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.\n\nCommitment to Equal Opportunity\n\nCoinbase is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law. For US applicants, you may view the Employee Rights and the Know Your Rights notices by clicking on their corresponding links. Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law.\n\nCoinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations(at)coinbase.com to let us know the nature of your request and your contact information. For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).\n\nGlobal Data Privacy Notice for Job Candidates and Applicants\n\nDepending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.\n\nAI Disclosure\n\nFor select roles, Coinbase is piloting an AI tool based on machine learning technologies to conduct initial screening interviews to qualified applicants. The tool simulates realistic interview scenarios and engages in dynamic conversation. A human recruiter will review your interview responses, provided in the form of a voice recording and/or transcript, to assess them against the qualifications and characteristics outlined in the job description.\n\nFor select roles, Coinbase is also piloting an AI interview intelligence platform to transcribe and summarize interview notes, allowing our interviewers to fully focus on you as the candidate.\n\nThe above pilots are for testing purposes and Coinbase will not use AI to make decisions impacting employment . To request a reasonable accommodation due to disability, please contact accommodations(at)coinbase.com",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Willow Creek, MT",
    "job_city": "Willow Creek",
    "job_state": "Montana",
    "job_country": "US",
    "job_latitude": 45.825206,
    "job_longitude": -111.64469659999999,
    "job_benefits": [
      "paid_time_off",
      "health_insurance",
      "dental_coverage"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D_rvXxbAeuJ7yr3ORAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up",
        "We want someone who will run towards, not away from, solving the company’s hardest problems",
        "Use established tools with mastery (e.g",
        "Google Sheets, SQL) to quickly deliver impact when speed is top priority.**",
        "In addition to out of the box thinking, attention to detail, a sense of urgency and a high degree of autonomy and accountability, we expect you to have the following skills:",
        "Data Modeling Expertise : Strong understanding of best practices for designing modular and reusable data models (e.g., star schemas, snowflake schemas)",
        "Prompt Design and Engineering: *Expertise in prompt engineering and design for LLMs (e.g., GPT), including creating, refining, and optimizing prompts to improve response accuracy, relevance, and performance for internal tools and use cases",
        "Advanced SQL : Proficiency in advanced SQL techniques for data transformation, querying, and optimization",
        "Intermediate to Advanced Python : Expertise in scripting and automation, with experience in Object-Oriented Programming (OOP) and building scalable frameworks",
        "Collaboration and Communication : Strong ability to translate technical concepts into business value for cross-functional stakeholders",
        "Proven ability to manage projects and communicate effectively across teams",
        "Data Pipeline Development : Experience building, maintaining, and optimizing ETL/ELT pipelines, using modern tools like dbt, Airflow, or similar",
        "Data Visualization : Proficiency in building polished dashboards using tools like Looker, Tableau, Superset, or Python visualization libraries (Matplotlib, Plotly)",
        "Development Tools : Familiarity with version control (GitHub), CI/CD, and modern development workflows",
        "Data Architecture : Knowledge of modern data lake/warehouse architectures (e.g., Snowflake, Databricks) and transformation frameworks",
        "Business Acumen : Ability to understand and address business challenges through analytics engineering",
        "Data savvy: *Familiarity with statistics and probability",
        "Experience with cloud platforms (e.g., AWS, GCP)",
        "Familiarity with Docker or Kubernetes"
      ],
      "Benefits": [
        "Pay Transparency Notice : Depending on your work location, the target annual *base *salary for this position can range as detailed below",
        "Full time offers from Coinbase also include bonus eligibility + equity eligibility + benefits (including medical, dental, vision and 401(k))",
        "Base salary range shown",
        "Total compensation also includes equity and bonus eligibility and benefits:",
        "$207,485—$244,100 USD"
      ],
      "Responsibilities": [
        "In-person participation is required throughout the year",
        "Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment",
        "Attendance is expected and fully supported",
        "We transform raw data into actionable insights through robust pipelines, well-designed data models, and tools that empower stakeholders across the organization to make data-driven decisions",
        "As an Analytics Engineer on our team, you will function as a force multiplier, enabling Analytics and Operations to function seamlessly at scale",
        "You’ll have the opportunity to translate complex technical and operational requirements into easily consumable front end data solutions, while also heavily influencing the overarching strategy for CX Analytics and its partners",
        "Trusted Data Sources : Develop and maintain foundational data models that serve as the single source of truth for analytics across the organization",
        "Actionable Insights : Empower stakeholders by translating business requirements into scalable data models, dashboards, and tools",
        "Cross-Functional Collaboration : Partner with engineering, data science, product, and business teams to ensure alignment on priorities and data solutions",
        "Scalable Data Products : Build frameworks, tools, and workflows that maximize efficiency for data users, while maintaining high standards of data quality and performance",
        "Outcome-Focused Solutions : Use modern development and analytics tools to deliver value quickly, while ensuring long-term maintainability",
        "Analytics engineer is a hybrid Data Engineer/Data Scientist/Business Analyst role that has the expertise to understand data flows end to end, and the engineering toolkit to extract the most value out of it indirectly (building tables) or directly (solving problems, delivering insights)",
        "Be the expert: *Quickly build subject matter expertise in a specific business area and data domain",
        "Understand the data flows from creation, ingestion, transformation, and delivery",
        "Step into a new line of business and work with Engineering and Product partners to deliver first data pipelines and insights",
        "Communicate with engineering teams to fix data gaps for downstream data users",
        "Take initiative and accountability for fixing issues anywhere in the stack",
        "Generate business value: Interface with stakeholders on data and product teams to deliver the most commercial value from data (directly or indirectly)",
        "Build out a new data model allowing multiple downstream DS teams to more easily unlock business value through experimentation and ad hoc analysis",
        "Combine Eng details of the algo engine with stats and data expertise to come up with feasible solutions for Eng to make the algo better",
        "Work with PMs to tie together new x-PG, and x-Product data into one holistic framework to optimize key financing product business metrics",
        "Focus on outcomes not tools: Use a variety of frameworks and paradigms to identify the best-fit tools to deliver value",
        "Develop new abstractions (e.g",
        "UDFs, Python packages, dashboards) to support scalable data workflows/infra.Stand up a framework for building data apps internally, enabling other DS teams to quickly add value",
        "Customer Support Data Experience: *Familiarity with data elements and processes supporting successful Customer Support initiatives, including employee performance monitoring, workforce/staffing inputs, and the handling of sensitive PII across a broad stakeholder base"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-whatjobs-com-jobs-staff-analytics-engineer",
    "_source": "new_jobs"
  },
  {
    "job_id": "DnJQNbAuRHlzHfYrAAAAAA==",
    "job_title": "Software Engineer, Data Analytics",
    "employer_name": "Intelliforce-IT Solutions Group, LLC.",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSztnTy3445oeJJPPShY_ifG8fv49mr8rUJZf4w&s=0",
    "employer_website": "https://intelliforce-itsg.com",
    "job_publisher": "BeBee",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://us.bebee.com/job/24659c2a46e74f6da35287fa63f6dfaf?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/24659c2a46e74f6da35287fa63f6dfaf?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Make an Impact Where It Matters Most\n\nAt Intelliforce, we build mission-focused solutions where engineering excellence directly supports national security outcomes.\n\nIn this role, you will help modernize and extend a critical data analytics user interface, transforming a prototype into a production-ready capability.\n\nYou will work alongside mission partners to enhance how data is explored, visualized, and delivered, ensuring analysts have intuitive, reliable tools that scale beyond the enterprise.\nThis position sits squarely within Intelliforce's core strengths in software engineering, data analytics, and mission delivery.\n\nSchedule and Work Details\n\nLocation:\nOPS 1\n\nSchedule:\nOnsite\n\nTelework:\nNot Available\n\nClearance:\nActive Top Secret Clearance with Full Scope Polygraph required\n\nHere's What Your Day-to-Day Might Include\n\nYou will enhance and mature a Streamlit-based UI prototype into a robust, scalable interface with a forward path to external availability.\nYou will design and implement new features, refine existing workflows, and ensure performance, usability, and data integrity.\n\nYour work will include developing front-end components, integrating back-end services, handling diverse data formats, and collaborating with engineers and stakeholders to translate requirements into clean, functional solutions.\nYou will also contribute to testing, documentation, and continuous improvement of the platform.\n\nMinimum Qualifications\n\nClearance:\nActive Top Secret Clearance with Full Scope Polygraph required\n\nCitizenship:\nMust be a U.S. Citizen\n\nEducation And Experience\n\nBachelor's degree in Computer Science or a related technical discipline with seven years of software engineering experience supporting programs of similar scope, type, and complexity, or a Master's degree with five years of experience, or nine years of relevant experience in lieu of a degree.\nRequired Skills\n\nYou bring strong experience developing software in Linux environments, including use of the Linux command line and Bash scripting to automate manual processes.\nYou have recent hands-on experience with Python and Java, and familiarity building interactive applications using Streamlit.\n\nYou are comfortable developing front-end applications using TypeScript, HTML, and CSS, and have experience with modern JavaScript frameworks such as React, Angular, or Vue.\n\nYou have worked with distributed data processing engines like Apache Spark, use Jupyter Notebooks effectively, and perform data wrangling with tools such as pandas and NumPy.\n\nYou are experienced working with structured, semi-structured, and unstructured data formats including Parquet, JSON, CSV, and XML, and understand data quality, validation, and anomaly detection concepts.\nYou use Git for source control and collaborative development.\n\nDesired Skills\n\nExperience orchestrating workflows with Apache Airflow, including DAG design and scheduling. Experience querying and aggregating data using SQL technologies such as MySQL, MariaDB, or PostgreSQL. Familiarity with HPC job scheduling tools such as Slurm. Experience using the Atlassian tool suite, including Jira and Confluence.\n\nTechnology Stack\n\nThis role operates across Python and Java development, Streamlit for UI construction, TypeScript, HTML, CSS, and modern JavaScript frameworks such as React, Angular, or Vue.\n\nThe environment includes Apache Spark for distributed processing, Jupyter Notebooks for analysis, pandas and NumPy for data preparation, Git for source control, Linux-based systems, and supporting technologies such as SQL databases, Airflow, and HPC scheduling tools.\n\nCompensation Range:\n$179, $237,000.00\n\nThe salary range provided reflects an estimate based on current market trends and may be adjusted based on factors such as the candidate's experience, skills, and qualifications.\nThe final offer will be tailored after a thorough evaluation of the candidate's background and suitability for the role. Please note that this range is intended as a guideline and is subject to flexibility\n\nWhy Intelliforce? Because you matter—your work, your growth, and your well-being.\n\nAt Intelliforce, we don't just push the boundaries of technology—we partner with some of the most mission-driven teams in defense and beyond to solve challenges that truly matter.\nAs a Systems Engineer here, you won't just contribute to projects—you'll help shape outcomes that make a real-world impact.\n\nWe also know that great work starts with a great environment.\n\nThat's why we invest in you:\nAmple PTO to rest and recharge—plus all federal holidays and your birthday off, just because.\nMultiple medical plan options, including ones with zero deductible or premium for employees.\nGenerous 401(k) with immediate vesting—because your future matters now.\nExciting bonus opportunities, from profit sharing to quarterly awards and President's Club recognition.\nA culture of collaboration, connection, and fun, with regular team activities that go beyond the work.\n\nReady to grow with purpose?\n\nAt Intelliforce, your career will flourish in a place where innovation thrives and people come first. Join us—and let's build something meaningful together.\n\nYou can reach us at - or schedule a call with our Director of Recruitment, just visit this link to view their calendar:\n.\n\nEqual Opportunity Matters\n\nIntelliforce-IT Solutions Group, LLC is proud to be an Equal Opportunity/Affirmative Action Employer. U.S. Citizenship is required for most positions.\n\nNeed accommodations during the application process? We're happy to help. Reach out to us at - with your specific request.\n\nPowered by JazzHR\n\nCoIz4oRKgb\n\nSeniority level\nMid-Senior level\nEmployment type\nFull-time\nJob function\nEngineering and Information Technology\nIndustries\nInternet Publishing",
    "job_is_remote": false,
    "job_posted_at": "9 days ago",
    "job_posted_at_timestamp": 1770422400,
    "job_posted_at_datetime_utc": "2026-02-07T00:00:00.000Z",
    "job_location": "Annapolis Junction, MD",
    "job_city": "Annapolis Junction",
    "job_state": "Maryland",
    "job_country": "US",
    "job_latitude": 39.1209588,
    "job_longitude": -76.77564459999999,
    "job_benefits": [
      "health_insurance",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DDnJQNbAuRHlzHfYrAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Active Top Secret Clearance with Full Scope Polygraph required",
        "Active Top Secret Clearance with Full Scope Polygraph required",
        "Must be a U.S. Citizen",
        "Bachelor's degree in Computer Science or a related technical discipline with seven years of software engineering experience supporting programs of similar scope, type, and complexity, or a Master's degree with five years of experience, or nine years of relevant experience in lieu of a degree",
        "You bring strong experience developing software in Linux environments, including use of the Linux command line and Bash scripting to automate manual processes",
        "You have recent hands-on experience with Python and Java, and familiarity building interactive applications using Streamlit",
        "You are comfortable developing front-end applications using TypeScript, HTML, and CSS, and have experience with modern JavaScript frameworks such as React, Angular, or Vue",
        "You have worked with distributed data processing engines like Apache Spark, use Jupyter Notebooks effectively, and perform data wrangling with tools such as pandas and NumPy",
        "You are experienced working with structured, semi-structured, and unstructured data formats including Parquet, JSON, CSV, and XML, and understand data quality, validation, and anomaly detection concepts",
        "You use Git for source control and collaborative development",
        "Experience orchestrating workflows with Apache Airflow, including DAG design and scheduling",
        "Experience querying and aggregating data using SQL technologies such as MySQL, MariaDB, or PostgreSQL",
        "Familiarity with HPC job scheduling tools such as Slurm",
        "Experience using the Atlassian tool suite, including Jira and Confluence",
        "U.S. Citizenship is required for most positions"
      ],
      "Benefits": [
        "Compensation Range:",
        "$179, $237,000.00",
        "The salary range provided reflects an estimate based on current market trends and may be adjusted based on factors such as the candidate's experience, skills, and qualifications",
        "Ample PTO to rest and recharge—plus all federal holidays and your birthday off, just because",
        "Multiple medical plan options, including ones with zero deductible or premium for employees",
        "Generous 401(k) with immediate vesting—because your future matters now",
        "Exciting bonus opportunities, from profit sharing to quarterly awards and President's Club recognition",
        "A culture of collaboration, connection, and fun, with regular team activities that go beyond the work"
      ],
      "Responsibilities": [
        "In this role, you will help modernize and extend a critical data analytics user interface, transforming a prototype into a production-ready capability",
        "You will work alongside mission partners to enhance how data is explored, visualized, and delivered, ensuring analysts have intuitive, reliable tools that scale beyond the enterprise",
        "This position sits squarely within Intelliforce's core strengths in software engineering, data analytics, and mission delivery",
        "You will enhance and mature a Streamlit-based UI prototype into a robust, scalable interface with a forward path to external availability",
        "You will design and implement new features, refine existing workflows, and ensure performance, usability, and data integrity",
        "Your work will include developing front-end components, integrating back-end services, handling diverse data formats, and collaborating with engineers and stakeholders to translate requirements into clean, functional solutions",
        "You will also contribute to testing, documentation, and continuous improvement of the platform",
        "This role operates across Python and Java development, Streamlit for UI construction, TypeScript, HTML, CSS, and modern JavaScript frameworks such as React, Angular, or Vue",
        "The environment includes Apache Spark for distributed processing, Jupyter Notebooks for analysis, pandas and NumPy for data preparation, Git for source control, Linux-based systems, and supporting technologies such as SQL databases, Airflow, and HPC scheduling tools"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "us-bebee-com-job-24659c2a46e74f6da35287fa63f6dfaf",
    "_source": "new_jobs"
  },
  {
    "job_id": "MNfi2T5-f63RyD9hAAAAAA==",
    "job_title": "Platform Intelligence Engineer(Data Engineer) - Innovative Global Technology Leader",
    "employer_name": "Andiamo",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPPuewVyYM1D2v5HZ-VKB7WewXJku1CAZWBC7r&s=0",
    "employer_website": "https://andiamogo.com",
    "job_publisher": "LinkedIn",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.linkedin.com/jobs/view/platform-intelligence-engineer-data-engineer-innovative-global-technology-leader-at-andiamo-4362561414?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/platform-intelligence-engineer-data-engineer-innovative-global-technology-leader-at-andiamo-4362561414?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/f722c7cec5f754036b90fed1c2b9ec9e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobright",
        "apply_link": "https://jobright.ai/jobs/info/6971857b587dfa0bb55f378d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobrapido",
        "apply_link": "https://us.jobrapido.com/jobpreview/8058483939464970240?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Platform Intelligence Engineer\n\nWe are seeking a Platform Intelligence Engineer to join a high impact data organization operating at the intersection of advanced analytics, large scale platforms, and mission critical decision making. This role is ideal for an experienced data engineer who enjoys transforming complex data into actionable insight and driving measurable business outcomes across a sophisticated technology environment.\n\nLocation and Work Model\n• Based in New York City\n• Hybrid schedule with approximately two to three days in the office, with flexibility\n\nCitizenship and Clearance Requirements\n• United States citizenship is required\n• Ability to obtain a top secret security clearance\n• No felony convictions\n\nAbout The Role\n\nThis position has evolved from a traditional data engineering role into a more expansive platform focused function. The Platform Intelligence Engineer partners closely with engineering, finance, and operations teams to uncover inefficiencies, identify cost savings, and turn data into strategic leverage. The work directly influences how large scale technology platforms are built, optimized, and governed.\n\nWhat You Will Do\n• Explore complex datasets to surface opportunities for efficiency, optimization, and financial impact\n• Design, build, and maintain reliable data pipelines that support analytics and decision making at scale\n• Translate ambiguous business problems into structured data solutions\n• Partner with cross functional stakeholders to operationalize insights and drive adoption\n• Present findings and proposals clearly to both technical and non technical audiences\n• Collaborate deeply with platform and infrastructure engineers on data driven initiatives\n\nWhat We Are Looking For\n• A strong foundation in data engineering rather than purely analytical or research focused data science\n• Advanced proficiency in Python and SQL\n• Demonstrated experience architecting and implementing production grade data pipelines\n• Exceptional communication skills with the ability to influence across teams\n• Comfort operating in fast moving, ambiguous environments\n• Curiosity, adaptability, and a desire to continuously learn\n\nInterview Process\n• Online technical assessment focused on Python and SQL\n• Initial conversation with a recruiter\n• One hour technical and behavioral interview with a senior engineer\n• Virtual onsite consisting of three technical sessions covering problem decomposition, analytics, and scripting\n• Final interview with the hiring manager\n\nCompensation\n\nCompensation is determined on an individual basis and is flexible depending on experience and qualifications. Details will be discussed during the interview process.\n\nSecurity Clearance Process\n• The clearance process begins after hire and must be initiated within thirty days of the start date\n• The process typically takes six to twelve months to complete\n• Support and guidance are provided throughout the clearance journey\n• If clearance is ultimately not granted, alternative team placements may be explored unless disqualifying issues arise\n\nThis is a unique opportunity to work on complex, high stakes data challenges within a deeply technical organization where your work directly shapes efficiency, cost structure, and platform intelligence.\n\nAbout Andiamo\n\nTalent Partners for the AI Revolution. As a globally recognized staffing and consulting firm, we specialize in placing the top 2% of technology and go-to-market professionals with the world’s largest and most well-known companies.\n\nFor over 20 years, we've maintained the status of tier-one vendor for firms such as Palantir, Amazon, Fluidstack, Bloomberg, Relativity Space, Firefly, MasterCard, Visa, Two Sigma, Citadel, as well as other major financial services firms, elite hedge funds, Google-backed tech start-ups, and major software firms.\n\nOur talent solutions include Permanent Placement, Contract Staffing, Executive Search, and Dedicated Recruiting Services (RPO). Find out more at www.andiamogo.com",
    "job_is_remote": false,
    "job_posted_at": "4 days ago",
    "job_posted_at_timestamp": 1770854400,
    "job_posted_at_datetime_utc": "2026-02-12T00:00:00.000Z",
    "job_location": "New York, NY",
    "job_city": "New York",
    "job_state": "New York",
    "job_country": "US",
    "job_latitude": 40.7127753,
    "job_longitude": -74.0059728,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DMNfi2T5-f63RyD9hAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "This role is ideal for an experienced data engineer who enjoys transforming complex data into actionable insight and driving measurable business outcomes across a sophisticated technology environment",
        "Citizenship and Clearance Requirements",
        "United States citizenship is required",
        "Ability to obtain a top secret security clearance",
        "No felony convictions",
        "A strong foundation in data engineering rather than purely analytical or research focused data science",
        "Advanced proficiency in Python and SQL",
        "Demonstrated experience architecting and implementing production grade data pipelines",
        "Exceptional communication skills with the ability to influence across teams",
        "Comfort operating in fast moving, ambiguous environments",
        "Curiosity, adaptability, and a desire to continuously learn",
        "Interview Process",
        "Online technical assessment focused on Python and SQL",
        "Initial conversation with a recruiter",
        "One hour technical and behavioral interview with a senior engineer",
        "The clearance process begins after hire and must be initiated within thirty days of the start date",
        "The process typically takes six to twelve months to complete"
      ],
      "Benefits": [
        "Compensation is determined on an individual basis and is flexible depending on experience and qualifications"
      ],
      "Responsibilities": [
        "Hybrid schedule with approximately two to three days in the office, with flexibility",
        "The Platform Intelligence Engineer partners closely with engineering, finance, and operations teams to uncover inefficiencies, identify cost savings, and turn data into strategic leverage",
        "The work directly influences how large scale technology platforms are built, optimized, and governed",
        "Explore complex datasets to surface opportunities for efficiency, optimization, and financial impact",
        "Design, build, and maintain reliable data pipelines that support analytics and decision making at scale",
        "Translate ambiguous business problems into structured data solutions",
        "Partner with cross functional stakeholders to operationalize insights and drive adoption",
        "Present findings and proposals clearly to both technical and non technical audiences",
        "Collaborate deeply with platform and infrastructure engineers on data driven initiatives",
        "Virtual onsite consisting of three technical sessions covering problem decomposition, analytics, and scripting",
        "Support and guidance are provided throughout the clearance journey"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-linkedin-com-jobs-view-platform-intelligence-engineer-data-engineer-innovative-global-technology-leader-at-andiamo-4362561414",
    "_source": "new_jobs"
  },
  {
    "job_id": "aFi9I2wuRtpwexnLAAAAAA==",
    "job_title": "Analytics Engineer Hybrid 43",
    "employer_name": "WeedMaps",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQpHMJ_XBl8h2_45sDfzi3fdrC7sEmmeZlNeXkU&s=0",
    "employer_website": "https://weedmaps.com",
    "job_publisher": "Jobilize",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.jobilize.com/job/us-tn-all-cities-analytics-engineer-hybrid-43-weedmaps-hiring-now?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Jobilize",
        "apply_link": "https://www.jobilize.com/job/us-tn-all-cities-analytics-engineer-hybrid-43-weedmaps-hiring-now?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Analytics Engineer (Hybrid)\n\nOverview:\n\nThe Analytics Engineer at Weedmaps will be a key technical contributor within our Data organization, supporting various aspects of the business. In this role, you will build and maintain data pipelines and analytics frameworks to answer business questions and enable root cause problem solving. You will collaborate extensively with business, engineering, product, and data science teams to drive data-informed decision making across our customer acquisition and retention strategies. The ideal candidate combines strong technical skills with e-commerce domain knowledge and can translate business requirements into scalable data solutions that deliver measurable impact on our growth metrics.\n\nAs part of our Data organization, you will develop robust analytics systems that address unique challenges in our marketplace, including user journey exploration, customer and product analytics. The explosive growth of the cannabis industry requires increasingly sophisticated analytics solutions that can scale with our business and comply with complex regulatory requirements.\n\nThe impact you'll make:\n• Design fault-tolerant dbt models to synthesize data from multiple sources into mart tables\n• Design and implement Sigma dashboards and Streamplit apps to provide clear insights into performance\n• Automate regular reporting workflows to reduce manual effort and increase data consistency\n• Create self-service tools that empower business teams to access insights independently\n• Analyze experiment results to identify opportunities for improving ROI\n• Develop and maintain data pipelines using SQL within modern data stack tools (Snowflake, DBT, Metaplane)\n• Create and document data models that transform raw data into reliable, business-ready datasets with accompanying dictionaries and testing\n• Implement data quality checks and testing frameworks to ensure the accuracy and reliability of analytics\nWhat you've accomplished:\n• 4+ years of experience in data engineering, or similar technical role\n• 2+ years of experience in analytics engineering\n• Experience with modern data warehouse platforms, preferably Snowflake\n• Expertise in SQL and data modeling with dbt\n• Proficiency in Python\nBonus points:\n• Experience with business intelligence tools, preferably Sigma\n• E-commerce or marketplace business experience preferred\n• Regulated industry experience - nice to have\nThe base pay range for this position is $172,000- $193,363 per year\n\n2026 US Benefits for Full Time, Regular Employees:\n• Physical Health (Medical, Dental & Vision)\n• 100% employer-paid premium for employees\n• Up to 80% coverage for dependents\n• Company HSA contribution with the High Deductible Health Plan\n• 401(k) Retirement Plan (employer will match contribution up to 3. 5% of employee contribution)\n• Basic Life, Voluntary Life and AD&D Insurance options\n• Supplemental, voluntary benefits\n• Student Loan Repayment/529 Education Savings with a monthly company contribution\n• FSA (Medical, Dependent, Transit and Parking)\n• Voluntary Life and AD&D Insurance\n• Critical Illness Insurance\n• Accident Insurance\n• Short- and Long-term Disability Insurance\n• Pet Insurance\n• Identity theft protection\n• Legal access to a network of attorneys\n• PTO, paid sick leave, and company holidays (including a 2026 holiday shutdown)\n• Paid parental leave\nWhy Work at Weedmaps?\n\nLife at Weedmaps means innovation and heart. Come join us if you care about the plant, the people who love it, and are ready to let your talent shine. We foster a bustling and collaborative culture that revolves around an environment that focuses on the benefits of weed, and the community that supports it.\n\nYou too can have a hand in shaping the industry's future; ready to roll with us?\n\nSee how we've grown-our journey, leadership team, and what's next at Weedmaps. com/corporate\n\nAbout Weedmaps:\n\nFounded in 2008, we've grown from a small startup to a global leader in the cannabis industry. Our dedication to transparency, education, and community has set us apart, and today, we proudly serve cannabis to consumers and businesses in the U. S. and worldwide.\n\n\"Freedom to choose. Freedom to access. Freedom to enjoy. \"\n\nNotice to prospective Weedmaps job applicants:\n\nOur team has been made aware of incidents involving LinkedIn, Telegram, and Facebook accounts impersonating Weedmaps recruiters. These individuals are attempting to use our company name to solicit payment from prospective candidates interested in applying for jobs at our company. Our team is actively working to combat these attempts, but in the meantime, please be mindful of the following:\n• Our recruiters will always communicate with candidates through an @weedmaps. com email address.\n• CORRECT: . @weedmaps. com\n• INCORRECT: . @gmail. com\n• Our recruiters will NEVER ask for or attempt to solicit payment from applicants in order to apply, interview, or work for Weedmaps.\n• If you are interested in a role at Weedmaps, please apply through our established channels.\n• Weedmaps Careers Page or LinkedIn\n\nIf you are unsure if a communication is legitimate, please contact our recruitment team at . @weedmaps. com and they will happily confirm for you. Thank you for your vigilance and we appreciate your interest in working with us!\n\nWeedmaps is an equal opportunity employer and makes employment decisions on the basis of merit. The Company prohibits unlawful discrimination against employees or applicants based on race (including traits historically associated with race, such as hair texture and protective hairstyles), religion and religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, military status, veteran status, uniformed service member status, sexual orientation, transgender identity, citizenship status, pregnancy, or any other consideration made unlawful by federal, state, or local laws. The Company also prohibits unlawful discrimination based on the perception that anyone has any of those characteristics, or is associated with a person who has or is perceived as having any of those characteristics. Our company uses E-Verify to confirm the employment eligibility of all newly hired employees. To learn more about E-Verify, including your rights and responsibilities, please visit dhs. gov/E-Verify.\n\nApplicants are entitled to reasonable accommodations under the terms of the Americans with Disabilities Act and applicable state/local laws, unless the accommodation presents undue hardship. Please email us at peopleoperations at weedmaps. com if you would like to confidentially discuss a potential accommodation during the interview process.",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Tennessee",
    "job_city": null,
    "job_state": "Tennessee",
    "job_country": "US",
    "job_latitude": 35.517491299999996,
    "job_longitude": -86.5804473,
    "job_benefits": [
      "paid_time_off",
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DaFi9I2wuRtpwexnLAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "The ideal candidate combines strong technical skills with e-commerce domain knowledge and can translate business requirements into scalable data solutions that deliver measurable impact on our growth metrics",
        "4+ years of experience in data engineering, or similar technical role",
        "2+ years of experience in analytics engineering",
        "Experience with modern data warehouse platforms, preferably Snowflake",
        "Expertise in SQL and data modeling with dbt",
        "Proficiency in Python",
        "Experience with business intelligence tools, preferably Sigma",
        "Regulated industry experience - nice to have",
        "Legal access to a network of attorneys"
      ],
      "Benefits": [
        "The base pay range for this position is $172,000- $193,363 per year",
        "2026 US Benefits for Full Time, Regular Employees:",
        "Physical Health (Medical, Dental & Vision)",
        "100% employer-paid premium for employees",
        "Up to 80% coverage for dependents",
        "Company HSA contribution with the High Deductible Health Plan",
        "401(k) Retirement Plan (employer will match contribution up to 3",
        "5% of employee contribution)",
        "Basic Life, Voluntary Life and AD&D Insurance options",
        "Supplemental, voluntary benefits",
        "Student Loan Repayment/529 Education Savings with a monthly company contribution",
        "FSA (Medical, Dependent, Transit and Parking)",
        "Voluntary Life and AD&D Insurance",
        "Critical Illness Insurance",
        "Accident Insurance",
        "Short- and Long-term Disability Insurance",
        "Pet Insurance",
        "PTO, paid sick leave, and company holidays (including a 2026 holiday shutdown)",
        "Paid parental leave",
        "Freedom to access",
        "Freedom to enjoy"
      ],
      "Responsibilities": [
        "The Analytics Engineer at Weedmaps will be a key technical contributor within our Data organization, supporting various aspects of the business",
        "In this role, you will build and maintain data pipelines and analytics frameworks to answer business questions and enable root cause problem solving",
        "You will collaborate extensively with business, engineering, product, and data science teams to drive data-informed decision making across our customer acquisition and retention strategies",
        "Design fault-tolerant dbt models to synthesize data from multiple sources into mart tables",
        "Design and implement Sigma dashboards and Streamplit apps to provide clear insights into performance",
        "Automate regular reporting workflows to reduce manual effort and increase data consistency",
        "Create self-service tools that empower business teams to access insights independently",
        "Analyze experiment results to identify opportunities for improving ROI",
        "Develop and maintain data pipelines using SQL within modern data stack tools (Snowflake, DBT, Metaplane)",
        "Create and document data models that transform raw data into reliable, business-ready datasets with accompanying dictionaries and testing",
        "Implement data quality checks and testing frameworks to ensure the accuracy and reliability of analytics"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-jobilize-com-job-us-tn-all-cities-analytics-engineer-hybrid-43-weedmaps-hiring-now",
    "_source": "new_jobs"
  },
  {
    "job_id": "XAY1ZGCPVXZ2djEhAAAAAA==",
    "job_title": "Senior Analytics Engineer, Revenue Operations",
    "employer_name": "DNSFilter",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSNX15ECaIW708N2bP7xkfHys6oDsq3bdDMp-jE&s=0",
    "employer_website": "https://www.dnsfilter.com",
    "job_publisher": "ZipRecruiter",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.ziprecruiter.com/c/DNSFilter/Job/Senior-Analytics-Engineer,-Revenue-Operations/-in-Tampa,FL?jid=2bd1004a3b8d5fcc&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": true,
    "apply_options": [
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/DNSFilter/Job/Senior-Analytics-Engineer,-Revenue-Operations/-in-Tampa,FL?jid=2bd1004a3b8d5fcc&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Energy Jobline",
        "apply_link": "https://www.energyjobline.com/job/senior-analytics-engineer-revenue-operations-tampa-29339333?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Monster",
        "apply_link": "https://www.monster.com/job-openings/senior-analytics-engineer-revenue-operations-tampa-fl--5b88feb5-7b6b-4dae-88b1-d4fe5bc04a4b?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/b349576177e17bb28ec69bd9b5a00a28?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobright",
        "apply_link": "https://jobright.ai/jobs/info/6983dc5b01214b4cdacbfbfc?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "JobLeads",
        "apply_link": "https://www.jobleads.com/us/job/senior-analytics-engineer-revenue-operations--tampa--e3fcc5e3d10e3b4e113602d5a797a69c3?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Learn4Good",
        "apply_link": "https://www.learn4good.com/jobs/tampa/florida/info_technology/4862446604/e/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "DNSFilter's mission is to protect our customers and partners with products they love to use! We are revolutionizing network security by providing fast, accurate, and reliable threat protection and content filtering. We're a rapidly growing company dedicated to creating a safer internet for businesses and organizations worldwide. Leveraging AI-driven threat intelligence, DNSFilter empowers our customers to proactively block threats before they impact their networks. We foster a collaborative, innovative, and results-oriented culture where every team member contributes to our mission of making the internet safer.\n\nAs we continue our product-fueled growth by adding new features and broadening our solution to meet the needs of the global market, it's clear there's a missing piece. That's where you come in!\n\nWe're seeking a Senior Analytics Engineer, Revenue Operations, to own and scale the RevOps data domain. This role sits on the Revenue Operations team, will report to the Senior Director, RevOps, and partners closely with Sales, Marketing, Customer Support, Customer Success, Finance, Product, and the Data Platform team to deliver trusted, analytics-ready data that powers GTM systems, reporting, and decision-making.\n\nThis is a senior individual contributor role with deep ownership. You'll treat the RevOps data domain as a product, not a collection of dashboards—balancing rigor, scalability, and stakeholder alignment in a fast-moving environment.\n\nEligible candidates have and can work successfully in a small to mid-sized fast-paced, hyper-growth, SaaS start-up or scale-up. This is a full-time role open to candidates in the United States and Canada.\n\nWe recognize that people come with a wealth of experience and talent beyond just the technical requirements of a job. If you feel like this job is for you, please apply. We believe diversity of experience and skills, including transferable skills, combined with passion, is a key to innovation and excellence; therefore, we encourage people from all backgrounds to apply to our positions!\n\nAt DNSFilter, You Will:\n\nOwn the RevOps Data Domain\n• Architect and own the RevOps / BizOps data zone within our Data Mesh, treating it as a product that is high-quality, discoverable, well-documented, and the authoritative source of truth for revenue data\n• Establish clear ownership, documentation, and governance for core RevOps datasets and metrics\n\nBuild & Scale Analytics Foundations\n• Own the end-to-end design, development, and maintenance of analytics solutions that power downstream GTM systems, reporting, and decision-making\n• Partner with the Data Platform (Data Engineering) team to transform data landed from internal databases, third-party APIs, and Airflow-managed pipelines into analytics-ready models\n• Develop, optimize, and maintain ELT pipelines using dbt Cloud, transforming PostgreSQL and other source data into analytics-ready datasets in Amazon Athena\n• Ensure reliable data availability, performance, and quality within our Athena-based analytics data zone\n\nOwn Data State, History, and Performance\n• Lead our approach to capturing data evolution and history, making heavy use of dbt snapshots and incremental models to support point-in-time and trend analysis\n• Write performant, cost-aware SQL optimized for distributed query engines (Amazon Athena), including queries operating over tens of billions of rows\n• Design models with scalability and maintainability in mind, prioritizing long-term clarity over clever but fragile solutions\n\nDefine, Govern & Operationalize Metrics\n• Design, implement, and maintain a semantic layer (e.g., dbt semantic models/metrics) that serves as the authoritative source for business definitions and revenue metrics\n• Introduce and steward a centralized data dictionary and metric catalog, ensuring consistent definitions across dashboards, reports, and GTM systems\n• Partner closely with RevOps, Finance, Product, and GTM stakeholders to define, govern, and evolve shared metrics—aligning on \"what is what\" as the business grows\n• Act as a trusted arbiter for metric definitions, managing versioning, documentation, and change communication\n\nModel Revenue Data for Downstream GTM Systems\n• Design data models that are consumable by the GTM Systems team for use in downstream operational tools such as Salesforce, Hubspot, and Zendesk\n• Expose clean, well-documented datasets and metrics that can be reliably reused across reporting, automation, and operational workflows\n• Partner with the GTM Systems team to ensure data models meet operational needs, performance requirements, and system constraints\n• Ensure consistency between analytical models and operational system logic, minimizing metric drift between analytics and GTM tooling\n\nOwn BI Reporting & Visualization\n• Own the design, development, and ongoing maintenance of RevOps dashboards, reports, and visualizations in our BI tool\n• Ensure all reporting is powered by governed, well-modeled, and tested datasets—avoiding one-off queries and metric drift\n• Partner with GTM, RevOps, and executive stakeholders to translate business needs into scalable, self-service dashboards\n• Continuously audit and improve existing dashboards for accuracy, performance, usability, and clarity\n• Define standards and best practices for dashboard design, metric presentation, and reporting governance\n\nDrive Accuracy, Simplicity & Trust\n• Get \"down in the weeds\" to validate data end-to-end, using SQL, spreadsheets, and source-system analysis to trace and resolve discrepancies\n• Uphold a \"simplicity at scale\" philosophy—choosing readable, maintainable SQL over over-engineered abstractions that accrue technical debt\n• Maintain logic at the appropriate layer: when metrics require new or corrected product data, partner with upstream owners rather than introducing brittle downstream workarounds\n• Review, audit, and refactor existing dbt models, ELT jobs, and dashboards to improve accuracy, performance, and maintainability\n\nEnable the Business & Look Forward\n• Design, build, and maintain dashboards and reports powered by well-modeled, tested data—avoiding one-off queries and metric drift\n• Support the GTM Systems team by ensuring analytics and reporting dependencies are reliable and well-documented\n• Leverage AI-assisted development tools to accelerate SQL development, dbt modeling, testing, documentation, and refactoring\n• Explore and pilot AI-enabled approaches to improve data quality, observability, and operational efficiency with sound judgment around accuracy and governance\n• Establish and promote best practices for data modeling, testing, documentation, and dashboard governance\n\nTo Qualify for this Role, You Have:\n• 5+ years of experience in analytics engineering or data engineering, specifically supporting GTM, RevOps, or BizOps functions\n• Expert dbt knowledge, including advanced use of incremental strategies, snapshotting, and modular project structure—you know when to use a macro and when not to\n• Deep proficiency in SQL with experience optimizing queries for modern distributed warehouses (e.g., Amazon Athena, BigQuery, Snowflake), including partitioning and cost optimization\n• Hands-on experience designing and maintaining analytics-ready data models and ELT pipelines from application and operational data sources\n• Experience implementing or working with semantic layers or governed metrics frameworks (e.g., dbt semantic layer or equivalent)\n• A meticulous, almost obsessive approach to data accuracy—you aren't satisfied until the numbers tie out 1:1 and you can prove it\n• Demonstrated ability to reconcile complex datasets across systems and identify root causes of discrepancies\n• A strong \"do it right\" mindset, including the ability to push back on unscalable requests and prioritize durable solutions over short-term fixes\n• Understanding of data mesh principles, domain ownership, and the discipline required to maintain a standalone analytics data zone\n• Strong communication skills and comfort level in influencing both technical and non-technical stakeholders\n\nBonus points for:\n• Direct experience working on a Revenue Operations team\n• Experience supporting Sales, Marketing, Customer Support, and Customer Success analytics\n• Experience introducing or maturing a centralized data dictionary and driving organizational adoption of governed metrics\n• Exposure to data mesh or domain-oriented data ownership models in production environments\n• Experience applying AI-assisted development tools to analytics engineering workflows (SQL, dbt, testing, documentation, refactoring)\n• Familiarity with revenue lifecycle metrics (pipeline, conversion rates, ARR/MRR, churn, expansion, forecasting)\n\nWe Offer:\n• Pathway to promotion to additional organizational positions and responsibilities based upon results and performance, not just time in the chair. You help us grow, and we will help you grow.\n• Passionate and intelligent colleagues who work hard and have a good time doing it\n• Paid company-wide week off at the end of each year\n• Flexible Vacation Policy\n• Awesome company swag\n• Full medical, dental, and vision benefits for US, UK, and Canada-based employees\n• Full short-term disability and life benefits; available long-term disability\n• Retirement savings account options with vested company matching for qualifying employees\n• In-person annual gatherings. Last time we all spent a week on a beach in Cancun!\n\nDNSFilter is a pay-for-performance organization, which means there is an opportunity to advance your compensation based on performance over time. The hiring base pay is dependent on several factors, including level, function, training, transferable skills, work experience, business needs, and geographic location. As a hybrid company, our compensation reflects the cost of labor across several U.S. and global geographic markets. We pay differently based on those defined markets. Our Talent Team can share more about the specific salary range for the job location during the hiring process.\n\nDNSFilter participates in the E-Verify program.\n\nAt DNSFilter, we utilize sophisticated software and tools to identify and eliminate Deepfake candidates. This approach helps us maintain the integrity of our hiring process, ensuring that we select the most qualified and genuine individuals to join our team.\nU.S. hiring salary range\n$130,000—$170,000 USD",
    "job_is_remote": false,
    "job_posted_at": "11 days ago",
    "job_posted_at_timestamp": 1770249600,
    "job_posted_at_datetime_utc": "2026-02-05T00:00:00.000Z",
    "job_location": "Tampa, FL",
    "job_city": "Tampa",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 27.951689599999998,
    "job_longitude": -82.45875269999999,
    "job_benefits": [
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DXAY1ZGCPVXZ2djEhAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Eligible candidates have and can work successfully in a small to mid-sized fast-paced, hyper-growth, SaaS start-up or scale-up",
        "Drive Accuracy, Simplicity & Trust",
        "Get \"down in the weeds\" to validate data end-to-end, using SQL, spreadsheets, and source-system analysis to trace and resolve discrepancies",
        "5+ years of experience in analytics engineering or data engineering, specifically supporting GTM, RevOps, or BizOps functions",
        "Expert dbt knowledge, including advanced use of incremental strategies, snapshotting, and modular project structure—you know when to use a macro and when not to",
        "Deep proficiency in SQL with experience optimizing queries for modern distributed warehouses (e.g., Amazon Athena, BigQuery, Snowflake), including partitioning and cost optimization",
        "Hands-on experience designing and maintaining analytics-ready data models and ELT pipelines from application and operational data sources",
        "Experience implementing or working with semantic layers or governed metrics frameworks (e.g., dbt semantic layer or equivalent)",
        "A meticulous, almost obsessive approach to data accuracy—you aren't satisfied until the numbers tie out 1:1 and you can prove it",
        "Demonstrated ability to reconcile complex datasets across systems and identify root causes of discrepancies",
        "A strong \"do it right\" mindset, including the ability to push back on unscalable requests and prioritize durable solutions over short-term fixes",
        "Understanding of data mesh principles, domain ownership, and the discipline required to maintain a standalone analytics data zone",
        "Strong communication skills and comfort level in influencing both technical and non-technical stakeholders",
        "Direct experience working on a Revenue Operations team",
        "Experience supporting Sales, Marketing, Customer Support, and Customer Success analytics",
        "Experience introducing or maturing a centralized data dictionary and driving organizational adoption of governed metrics",
        "Exposure to data mesh or domain-oriented data ownership models in production environments",
        "Experience applying AI-assisted development tools to analytics engineering workflows (SQL, dbt, testing, documentation, refactoring)",
        "Familiarity with revenue lifecycle metrics (pipeline, conversion rates, ARR/MRR, churn, expansion, forecasting)"
      ],
      "Benefits": [
        "Pathway to promotion to additional organizational positions and responsibilities based upon results and performance, not just time in the chair",
        "Passionate and intelligent colleagues who work hard and have a good time doing it",
        "Paid company-wide week off at the end of each year",
        "Flexible Vacation Policy",
        "Awesome company swag",
        "Full medical, dental, and vision benefits for US, UK, and Canada-based employees",
        "Full short-term disability and life benefits; available long-term disability",
        "Retirement savings account options with vested company matching for qualifying employees",
        "In-person annual gatherings",
        "DNSFilter is a pay-for-performance organization, which means there is an opportunity to advance your compensation based on performance over time",
        "The hiring base pay is dependent on several factors, including level, function, training, transferable skills, work experience, business needs, and geographic location",
        "$130,000—$170,000 USD"
      ],
      "Responsibilities": [
        "We're seeking a Senior Analytics Engineer, Revenue Operations, to own and scale the RevOps data domain",
        "This role sits on the Revenue Operations team, will report to the Senior Director, RevOps, and partners closely with Sales, Marketing, Customer Support, Customer Success, Finance, Product, and the Data Platform team to deliver trusted, analytics-ready data that powers GTM systems, reporting, and decision-making",
        "This is a senior individual contributor role with deep ownership",
        "You'll treat the RevOps data domain as a product, not a collection of dashboards—balancing rigor, scalability, and stakeholder alignment in a fast-moving environment",
        "Architect and own the RevOps / BizOps data zone within our Data Mesh, treating it as a product that is high-quality, discoverable, well-documented, and the authoritative source of truth for revenue data",
        "Establish clear ownership, documentation, and governance for core RevOps datasets and metrics",
        "Build & Scale Analytics Foundations",
        "Own the end-to-end design, development, and maintenance of analytics solutions that power downstream GTM systems, reporting, and decision-making",
        "Partner with the Data Platform (Data Engineering) team to transform data landed from internal databases, third-party APIs, and Airflow-managed pipelines into analytics-ready models",
        "Develop, optimize, and maintain ELT pipelines using dbt Cloud, transforming PostgreSQL and other source data into analytics-ready datasets in Amazon Athena",
        "Ensure reliable data availability, performance, and quality within our Athena-based analytics data zone",
        "Own Data State, History, and Performance",
        "Lead our approach to capturing data evolution and history, making heavy use of dbt snapshots and incremental models to support point-in-time and trend analysis",
        "Write performant, cost-aware SQL optimized for distributed query engines (Amazon Athena), including queries operating over tens of billions of rows",
        "Design models with scalability and maintainability in mind, prioritizing long-term clarity over clever but fragile solutions",
        "Design, implement, and maintain a semantic layer (e.g., dbt semantic models/metrics) that serves as the authoritative source for business definitions and revenue metrics",
        "Introduce and steward a centralized data dictionary and metric catalog, ensuring consistent definitions across dashboards, reports, and GTM systems",
        "Partner closely with RevOps, Finance, Product, and GTM stakeholders to define, govern, and evolve shared metrics—aligning on \"what is what\" as the business grows",
        "Act as a trusted arbiter for metric definitions, managing versioning, documentation, and change communication",
        "Model Revenue Data for Downstream GTM Systems",
        "Design data models that are consumable by the GTM Systems team for use in downstream operational tools such as Salesforce, Hubspot, and Zendesk",
        "Expose clean, well-documented datasets and metrics that can be reliably reused across reporting, automation, and operational workflows",
        "Partner with the GTM Systems team to ensure data models meet operational needs, performance requirements, and system constraints",
        "Ensure consistency between analytical models and operational system logic, minimizing metric drift between analytics and GTM tooling",
        "Own BI Reporting & Visualization",
        "Own the design, development, and ongoing maintenance of RevOps dashboards, reports, and visualizations in our BI tool",
        "Ensure all reporting is powered by governed, well-modeled, and tested datasets—avoiding one-off queries and metric drift",
        "Partner with GTM, RevOps, and executive stakeholders to translate business needs into scalable, self-service dashboards",
        "Continuously audit and improve existing dashboards for accuracy, performance, usability, and clarity",
        "Define standards and best practices for dashboard design, metric presentation, and reporting governance",
        "Uphold a \"simplicity at scale\" philosophy—choosing readable, maintainable SQL over over-engineered abstractions that accrue technical debt",
        "Maintain logic at the appropriate layer: when metrics require new or corrected product data, partner with upstream owners rather than introducing brittle downstream workarounds",
        "Review, audit, and refactor existing dbt models, ELT jobs, and dashboards to improve accuracy, performance, and maintainability",
        "Enable the Business & Look Forward",
        "Design, build, and maintain dashboards and reports powered by well-modeled, tested data—avoiding one-off queries and metric drift",
        "Support the GTM Systems team by ensuring analytics and reporting dependencies are reliable and well-documented",
        "Leverage AI-assisted development tools to accelerate SQL development, dbt modeling, testing, documentation, and refactoring",
        "Explore and pilot AI-enabled approaches to improve data quality, observability, and operational efficiency with sound judgment around accuracy and governance",
        "Establish and promote best practices for data modeling, testing, documentation, and dashboard governance"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-ziprecruiter-com-c-dnsfilter-job-senior-analytics-engineer-revenue-operations-in-tampa-fl",
    "_source": "new_jobs"
  },
  {
    "job_id": "4PMXCF0Zj3csVibCAAAAAA==",
    "job_title": "Data Engineering Manager - Advanced Analytics",
    "employer_name": "Niagara Bottling",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQD1lp7Y_nPmktOrGBYuyI9Zyj9tBqyLbRlieZB&s=0",
    "employer_website": "https://www.niagarawater.com",
    "job_publisher": "Niagara Bottling LLC Careers",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.niagarawater.com/us/en/job/R45735/Data-Engineering-Manager-Advanced-Analytics?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Niagara Bottling LLC Careers",
        "apply_link": "https://careers.niagarawater.com/us/en/job/R45735/Data-Engineering-Manager-Advanced-Analytics?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=b3a692c155871761&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Career.io",
        "apply_link": "https://career.io/job/advanced-analytics-manager-data-engineering-diamond-bar-niagara-bottling-f8a97cc14e8a3b1597c041e2c1db509c?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Built In Los Angeles",
        "apply_link": "https://www.builtinla.com/job/lead-power-bi-developer/4193106?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Tech Jobs Personalized",
        "apply_link": "https://builtin.com/job/lead-power-bi-developer/4193106?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/data-engineering-manager-advanced-analytics_7ea1afe75026a4bcd9f82ae335cbe32f2704f?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/data-engineering-manager-advanced-analytics-at-niagara-bottling-4354561864?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Milwaukee Jobs",
        "apply_link": "https://www.milwaukeejobs.com/j/t-Lead-Power-BI-Developer-e-Niagara-Bottling-LLC-l-Diamond-Bar,-CA-jobs-j81200452.html?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "At Niagara, we’re looking for Team Members who want to be part of achieving our mission to provide our customers the highest quality most affordable bottled water.\n\nConsider applying here, if you want to:\n• Work in an entrepreneurial and dynamic environment with a chance to make an impact.\n• Develop lasting relationships with great people.\n• Have the opportunity to build a satisfying career.\n\nWe offer competitive compensation and benefits packages for our Team Members.\n\nData Engineering Manager - Advanced Analytics\n\nAs a key people leader within our data and analytics function, the Advanced Analytics Manager plays a critical role in architecting and maintaining the data infrastructure that underpins enterprise analytics. This role leads a team of data engineers and analytics professionals, focusing on the design, implementation, and optimization of scalable, reliable, and secure data pipelines, especially for complex, high-volume sources such as IoT and sensor-based systems. Working cross-functionally with operations, IT, and business stakeholders, the Advanced Analytics Manager ensures that data from diverse sources, including real-time telemetry, manufacturing systems, and traditional enterprise platforms are efficiently ingested, transformed, and made accessible for analytical consumption. In addition, the role includes light but growing exposure to Generative AI use cases, such as document summarization, chat interfaces for data access, and large language model (LLM) integration—especially in scenarios that augment data accessibility and user experience across the organization. This position requires not only technical expertise but also strategic thinking and leadership skills to evolve data infrastructure, support analytics scalability, and drive a data-first culture. A proven ability to lead high-performing teams and deliver impactful solutions in dynamic, data-rich environments is essential for success.\n• Lead and manage a team of data engineers and analytics professionals, providing strategic direction, mentorship, train, coach, performance reviews, and hands-on support to foster a collaborative, high-performing team environment focused on delivering impactful data solutions.\n• Establish clear objectives and key results (OKRs) for the team that align with the enterprise analytics and data strategy, ensuring close coordination with business goals and evolving priorities.\n• Conduct regular performance reviews, deliver constructive feedback, and champion continuous learning by identifying training, upskilling, and development opportunities for team members.\n• Partner with cross-functional teams, including business analysts, data scientists, IT, and key business stakeholders, to understand data requirements and deliver solutions that support business intelligence, operational reporting, and advanced analytics use cases.\n• Define and implement best practices in data engineering, covering data modeling, pipeline orchestration (ETL/ELT), data integration, and data quality, while ensuring reliable access to data from diverse sources such as databases, APIs, cloud platforms, and IoT systems.\n• Drive continuous improvement and innovation in data architecture and engineering techniques, with a focus on increasing scalability, performance, and reusability across the analytics ecosystem.\n• Oversee project planning and execution, balancing team capacity with priority management, delivery timelines, and quality standards to ensure successful outcomes for strategic and operational analytics initiatives.\n• Collaborate with cross-functional business and IT stakeholders to define and implement data and analytics strategies that support enterprise decision-making, ensuring data integrity, security, and governance across all analytical initiatives.\n• Provide technical leadership in data engineering and analytics infrastructure, leveraging modern cloud-native tools to enable high-performance data platforms that support BI, reporting, and advanced analytics.\n• Champion a culture of data innovation and continuous learning, encouraging the team to explore new data patterns, tooling, and architectural practices that improve scalability, reliability, and time-to-insight.\n• Oversee resource planning, vendor coordination, and budget management for the analytics engineering function, ensuring alignment with strategic priorities and operational efficiency.\n• Lead the design and implementation of high-volume, scalable data pipelines, models, and data marts across Data Lakes and Data Warehouses to support reporting, dashboarding, and analytics workloads.\n• Translate technical and project outcomes into business context through executive-ready presentations and analytics steering committee briefings, facilitating alignment and decision-making.\n• Demonstrate proficiency in Microsoft Azure Cloud (preferred) and/or Amazon Web Services, particularly within data engineering and analytics service ecosystems (e.g., Azure Data Factory, Synapse, Databricks, Redshift).\n• Build and manage DevOps pipelines for CI/CD and analytics solution deployment, ensuring consistency, automation, and compliance with change control standards.\n• Serve as a proactive leader who delivers on commitments and identifies opportunities for process improvement, team development, and organizational data literacy.\n• Coordinate and collaborate with onsite and offshore consultants to support scalable delivery and knowledge transfer across global analytics initiatives.\n• Maintain flexibility and responsiveness to evolving business needs; this job description may be adjusted to reflect emerging priorities or strategic direction.\n\nPlease note that this job description is not designed to contain a comprehensive list of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without prior notice.\n\nAdditionally, the Advanced Analytics Manager is expected to demonstrate:\n• Excellent communication, leadership and collaboration skills\n• Possesses solid project management skills\n• Advanced decision making and problem-solving skills\n• Ability to guide technical projects successfully from inception to completion\n• Experienced with Microsoft Word, Excel, PowerPoint, Visio and Outlook\n• Team Work - balances team and individual responsibilities; gives and welcomes feedback; contributes to building a positive team spirit; puts success of team above own interests; able to build morale and group commitments to goals and objectives\n• Adaptability - adapts to changes in the work environment; able to deal with frequent change, delays, or unexpected events\n• Planning/Organizing - uses time efficiently; plans for additional resources; sets goals and objectives; organizes or schedules other people and their tasks\n• Project Management - coordinates projects; communicates changes and progress; completes projects on time; budget management; manages project team activities\n• Oral Communication - speaks clearly and persuasively in positive or negative situations; listens and gets clarification; responds well to questions\n• Excellent team player\n\nWork Experience\n• Required:\n• 8-10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities\n• 8-10 years – Experience in data modeling, ETL processes, and data warehousing\n• 8-10 years – Experience in building and managing enterprise scale data pipelines\n• 8-10 years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)\n• 8-10 years – Experience in DevOps, CI/CD pipelines\n• 8-10 years – Experience in Python/R, Spark/Kafka\n• 8-10 years – Experience with Azure Databricks/Data Factory or similar technology\n• 8-10 years – Experience in Project management\n• Preferred:\n• 10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities\n• 10+ years – Experience in data modeling, ETL processes, and data warehousing\n• 10+ years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)\n• 10+ years – Experience in DevOps, CI/CD pipelines\n• 10+ years – Experience in Python/R, Spark/Kafka\n• 10+ years – Experience with Azure Databricks/Data Factory or similar technology\n• 10+ years – Experience in Project management\n• 2 years – Experience with Large language Models and building Gen AI applications\n\nEducation\n• Minimum Required:\n• Bachelor's Degree in Computer Science or Engineering\n• Preferred:\n• Master's Degree in Computer Science or Engineering\n\nCertification/License:\n• Required: None Required\n• Preferred: Data Engineering/Cloud certifications/Gen AI\n\nTypical Compensation Range\nPay Rate Type: Salary\n\n$136,778.46 - $198,328.77 / Yearly\n\nBonus Target: 10% Annual\n\nBenefits\n\nhttps://careers.niagarawater.com/us/en/benefits\n\nAny employment agency, person or entity that submits a résumé into this career site or to a hiring manager does so with the understanding that the applicant's résumé will become the property of Niagara Bottling, LLC. Niagara Bottling, LLC will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person or entity.\n\nEmployment agencies that have fee agreements with Niagara Bottling, LLC and have been engaged on a search shall submit résumé to the designated Niagara Bottling, LLC recruiter or, upon authorization, submit résumé into this career site to be eligible for placement fees.\nNiagara Plant Name\nCORP-MAIN",
    "job_is_remote": false,
    "job_posted_at": "1 day ago",
    "job_posted_at_timestamp": 1771113600,
    "job_posted_at_datetime_utc": "2026-02-15T00:00:00.000Z",
    "job_location": "Diamond Bar, CA",
    "job_city": "Diamond Bar",
    "job_state": "California",
    "job_country": "US",
    "job_latitude": 34.0009951,
    "job_longitude": -117.8112041,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D4PMXCF0Zj3csVibCAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "This position requires not only technical expertise but also strategic thinking and leadership skills to evolve data infrastructure, support analytics scalability, and drive a data-first culture",
        "Possesses solid project management skills",
        "Advanced decision making and problem-solving skills",
        "Ability to guide technical projects successfully from inception to completion",
        "Experienced with Microsoft Word, Excel, PowerPoint, Visio and Outlook",
        "Team Work - balances team and individual responsibilities; gives and welcomes feedback; contributes to building a positive team spirit; puts success of team above own interests; able to build morale and group commitments to goals and objectives",
        "Excellent team player",
        "8-10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities",
        "8-10 years – Experience in data modeling, ETL processes, and data warehousing",
        "8-10 years – Experience in building and managing enterprise scale data pipelines",
        "8-10 years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)",
        "8-10 years – Experience in DevOps, CI/CD pipelines",
        "8-10 years – Experience in Python/R, Spark/Kafka",
        "8-10 years – Experience with Azure Databricks/Data Factory or similar technology",
        "8-10 years – Experience in Project management",
        "10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities",
        "10+ years – Experience in data modeling, ETL processes, and data warehousing",
        "10+ years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)",
        "10+ years – Experience in DevOps, CI/CD pipelines",
        "10+ years – Experience in Python/R, Spark/Kafka",
        "10+ years – Experience with Azure Databricks/Data Factory or similar technology",
        "10+ years – Experience in Project management",
        "2 years – Experience with Large language Models and building Gen AI applications",
        "Bachelor's Degree in Computer Science or Engineering",
        "Master's Degree in Computer Science or Engineering",
        "Required: None Required"
      ],
      "Benefits": [
        "Work in an entrepreneurial and dynamic environment with a chance to make an impact",
        "Develop lasting relationships with great people",
        "Have the opportunity to build a satisfying career",
        "We offer competitive compensation and benefits packages for our Team Members",
        "Typical Compensation Range",
        "Pay Rate Type: Salary",
        "$136,778.46 - $198,328.77 / Yearly",
        "Bonus Target: 10% Annual"
      ],
      "Responsibilities": [
        "This role leads a team of data engineers and analytics professionals, focusing on the design, implementation, and optimization of scalable, reliable, and secure data pipelines, especially for complex, high-volume sources such as IoT and sensor-based systems",
        "Working cross-functionally with operations, IT, and business stakeholders, the Advanced Analytics Manager ensures that data from diverse sources, including real-time telemetry, manufacturing systems, and traditional enterprise platforms are efficiently ingested, transformed, and made accessible for analytical consumption",
        "In addition, the role includes light but growing exposure to Generative AI use cases, such as document summarization, chat interfaces for data access, and large language model (LLM) integration—especially in scenarios that augment data accessibility and user experience across the organization",
        "A proven ability to lead high-performing teams and deliver impactful solutions in dynamic, data-rich environments is essential for success",
        "Lead and manage a team of data engineers and analytics professionals, providing strategic direction, mentorship, train, coach, performance reviews, and hands-on support to foster a collaborative, high-performing team environment focused on delivering impactful data solutions",
        "Establish clear objectives and key results (OKRs) for the team that align with the enterprise analytics and data strategy, ensuring close coordination with business goals and evolving priorities",
        "Conduct regular performance reviews, deliver constructive feedback, and champion continuous learning by identifying training, upskilling, and development opportunities for team members",
        "Partner with cross-functional teams, including business analysts, data scientists, IT, and key business stakeholders, to understand data requirements and deliver solutions that support business intelligence, operational reporting, and advanced analytics use cases",
        "Define and implement best practices in data engineering, covering data modeling, pipeline orchestration (ETL/ELT), data integration, and data quality, while ensuring reliable access to data from diverse sources such as databases, APIs, cloud platforms, and IoT systems",
        "Drive continuous improvement and innovation in data architecture and engineering techniques, with a focus on increasing scalability, performance, and reusability across the analytics ecosystem",
        "Oversee project planning and execution, balancing team capacity with priority management, delivery timelines, and quality standards to ensure successful outcomes for strategic and operational analytics initiatives",
        "Collaborate with cross-functional business and IT stakeholders to define and implement data and analytics strategies that support enterprise decision-making, ensuring data integrity, security, and governance across all analytical initiatives",
        "Provide technical leadership in data engineering and analytics infrastructure, leveraging modern cloud-native tools to enable high-performance data platforms that support BI, reporting, and advanced analytics",
        "Champion a culture of data innovation and continuous learning, encouraging the team to explore new data patterns, tooling, and architectural practices that improve scalability, reliability, and time-to-insight",
        "Oversee resource planning, vendor coordination, and budget management for the analytics engineering function, ensuring alignment with strategic priorities and operational efficiency",
        "Lead the design and implementation of high-volume, scalable data pipelines, models, and data marts across Data Lakes and Data Warehouses to support reporting, dashboarding, and analytics workloads",
        "Translate technical and project outcomes into business context through executive-ready presentations and analytics steering committee briefings, facilitating alignment and decision-making",
        "Build and manage DevOps pipelines for CI/CD and analytics solution deployment, ensuring consistency, automation, and compliance with change control standards",
        "Serve as a proactive leader who delivers on commitments and identifies opportunities for process improvement, team development, and organizational data literacy",
        "Coordinate and collaborate with onsite and offshore consultants to support scalable delivery and knowledge transfer across global analytics initiatives",
        "Maintain flexibility and responsiveness to evolving business needs; this job description may be adjusted to reflect emerging priorities or strategic direction",
        "Duties, responsibilities and activities may change at any time with or without prior notice",
        "Additionally, the Advanced Analytics Manager is expected to demonstrate:",
        "Excellent communication, leadership and collaboration skills",
        "Adaptability - adapts to changes in the work environment; able to deal with frequent change, delays, or unexpected events",
        "Planning/Organizing - uses time efficiently; plans for additional resources; sets goals and objectives; organizes or schedules other people and their tasks",
        "Project Management - coordinates projects; communicates changes and progress; completes projects on time; budget management; manages project team activities",
        "Oral Communication - speaks clearly and persuasively in positive or negative situations; listens and gets clarification; responds well to questions"
      ]
    },
    "job_onet_soc": "11302100",
    "job_onet_job_zone": "4",
    "id": "careers-niagarawater-com-us-en-job-r45735-data-engineering-manager-advanced-analytics",
    "_source": "new_jobs"
  },
  {
    "job_id": "5FJGrJp-KLWXkkHBAAAAAA==",
    "job_title": "Staff Analytics Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=0df90abea72f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=0df90abea72f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobilize",
        "apply_link": "https://www.jobilize.com/job/us-ny-syracuse-staff-analytics-engineer-nitrogen-hiring-now-job-immediately?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Staff Analytics Engineer to transform raw data into trusted business insights.\n\nKey Responsibilities\n\nArchitect the complete data lifecycle and own the gold layer, designing the semantic layer and optimizing data tables\n\nTranslate complex business questions into technical definitions and build consensus on enterprise-wide metric definitions\n\nChampion a product-oriented mindset by establishing standards for documentation, testing, and data model design\n\nRequired Qualifications\n\n10+ years of experience in Analytics Engineering, Software Engineering, or Data Engineering, with 4 years in large-scale data environments\n\nExpertise in dimensional modeling best practices and designing reusable data models\n\nProficiency in advanced SQL techniques and performance tuning\n\nStrong expertise in Python for scripting and data manipulation\n\nBachelor's degree in Computer Science, Software Engineering, Data Engineering, or a related field",
    "job_is_remote": false,
    "job_posted_at": "2 days ago",
    "job_posted_at_timestamp": 1771027200,
    "job_posted_at_datetime_utc": "2026-02-14T00:00:00.000Z",
    "job_location": "Syracuse, NY",
    "job_city": "Syracuse",
    "job_state": "New York",
    "job_country": "US",
    "job_latitude": 43.0494832,
    "job_longitude": -76.1473977,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D5FJGrJp-KLWXkkHBAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "10+ years of experience in Analytics Engineering, Software Engineering, or Data Engineering, with 4 years in large-scale data environments",
        "Expertise in dimensional modeling best practices and designing reusable data models",
        "Proficiency in advanced SQL techniques and performance tuning",
        "Strong expertise in Python for scripting and data manipulation",
        "Bachelor's degree in Computer Science, Software Engineering, Data Engineering, or a related field"
      ],
      "Responsibilities": [
        "Architect the complete data lifecycle and own the gold layer, designing the semantic layer and optimizing data tables",
        "Translate complex business questions into technical definitions and build consensus on enterprise-wide metric definitions",
        "Champion a product-oriented mindset by establishing standards for documentation, testing, and data model design"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "GJe7t_NJZN-bb34PAAAAAA==",
    "job_title": "GTM Engineer (Clay & Cold Email Experience)",
    "employer_name": "Pump",
    "employer_logo": null,
    "employer_website": "https://www.pump.co",
    "job_publisher": "WhatJobs",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.whatjobs.com/jobs/analytics-engineer?id=2454857449&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "WhatJobs",
        "apply_link": "https://www.whatjobs.com/jobs/analytics-engineer?id=2454857449&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "California Careers",
        "apply_link": "https://california.topstatecareers.com/jobs/gtm-engineer-clay-cold-email-experience-san-francisco-california/2608924333-2/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Overview\n\nJoin to apply for the GTM Engineer (Clay & Cold Email Experience) role at Pump.co .\n\nThis range is provided by Pump.co. Your actual pay will be based on your skills and experience — talk with your recruiter to learn more.\nBase pay range\n\n$80,000.00/yr - $120,000.00/yr\n\nThis role is based in our San Francisco office 5 days a week. Through commission and our highly valuable equity, OTE will be around $300K.\n\nWe’re growing fast and looking for a scrappy GTM Engineer to supercharge our outbound motion and fuel sales growth. This is an onsite role that blends technical chops with go-to-market instinct—perfect for someone who thrives at the intersection of code and hustle.\n\nDeep familiarity with Clay is a must. You should know how to build, automate, and scale workflows in Clay without hand-holding. We’re looking for someone who can push the limits of what Clay can do and turn it into a competitive advantage across our outbound strategy.\nResponsibilities Partner with sales and marketing to accelerate outbound efforts. Build scrappy tools, scripts, and automations that improve how we find, convert, and support customers. Create and maintain demo setups, sales enablement docs, and outbound playbooks. Enrich lead data and contribute to outreach strategies using Clay , LinkedIn, and scraping utilities. Troubleshoot blockers during handoff or onboarding and relay insights to the GTM team. Continuously test new outbound approaches and find creative ways to scale what works. Qualifications Must have hands-on experience using Clay for outbound workflows. Bachelor’s in STEM (Computer Science, Engineering, Data Science, or similar). Strong technical foundation—comfortable with APIs, no-code tools, and writing lightweight scripts. Fast learner who enjoys diving into new tools, problems, and workflows. Excellent communicator—able to explain technical ideas in simple terms. Excited to work cross-functionally with sales & marketing. Bonus: Internship at a startup or B2B SaaS company. Bonus: Side projects, hackathons, or real-world builds that show initiative and follow-through. Ability to work 5 days a week in office. Competitive salary and equity. Full benefits package, including premium healthcare coverage. Professional development and learning reimbursements. 3–4x/year company-paid team retreats. A smart, kind, and high-performing team that loves building together. Compensation\n\n$80,000 USD - $120,000 USD\nEmployment details Seniority level: Entry level Employment type: Full-time Job function: Engineering and Information Technology Industries: Technology, Information and Internet\n\nSan Francisco, CA and related compensation ranges were provided within the posting. We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.\n#J-18808-Ljbffr",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "San Francisco, CA",
    "job_city": "San Francisco",
    "job_state": "California",
    "job_country": "US",
    "job_latitude": 37.7749295,
    "job_longitude": -122.4194155,
    "job_benefits": [
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DGJe7t_NJZN-bb34PAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Deep familiarity with Clay is a must",
        "You should know how to build, automate, and scale workflows in Clay without hand-holding",
        "We’re looking for someone who can push the limits of what Clay can do and turn it into a competitive advantage across our outbound strategy",
        "Qualifications Must have hands-on experience using Clay for outbound workflows",
        "Bachelor’s in STEM (Computer Science, Engineering, Data Science, or similar)",
        "Strong technical foundation—comfortable with APIs, no-code tools, and writing lightweight scripts",
        "Fast learner who enjoys diving into new tools, problems, and workflows",
        "Excellent communicator—able to explain technical ideas in simple terms",
        "Bonus: Side projects, hackathons, or real-world builds that show initiative and follow-through",
        "Ability to work 5 days a week in office"
      ],
      "Benefits": [
        "Your actual pay will be based on your skills and experience — talk with your recruiter to learn more",
        "Base pay range",
        "$80,000.00/yr - $120,000.00/yr",
        "Through commission and our highly valuable equity, OTE will be around $300K",
        "Bonus: Internship at a startup or B2B SaaS company",
        "Competitive salary and equity",
        "Full benefits package, including premium healthcare coverage",
        "Professional development and learning reimbursements",
        "3–4x/year company-paid team retreats",
        "$80,000 USD - $120,000 USD"
      ],
      "Responsibilities": [
        "Responsibilities Partner with sales and marketing to accelerate outbound efforts",
        "Build scrappy tools, scripts, and automations that improve how we find, convert, and support customers",
        "Create and maintain demo setups, sales enablement docs, and outbound playbooks",
        "Enrich lead data and contribute to outreach strategies using Clay , LinkedIn, and scraping utilities",
        "Troubleshoot blockers during handoff or onboarding and relay insights to the GTM team",
        "Continuously test new outbound approaches and find creative ways to scale what works"
      ]
    },
    "job_onet_soc": "41903100",
    "job_onet_job_zone": "4",
    "id": "www-whatjobs-com-jobs-analytics-engineer",
    "_source": "new_jobs"
  },
  {
    "job_id": "4GHeUqb67eilko0QAAAAAA==",
    "job_title": "Simulation Engineer- Supply Chain",
    "employer_name": "Cencora",
    "employer_logo": null,
    "employer_website": "https://www.cencora.com",
    "job_publisher": "Cencora Careers",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.cencora.com/us/en/job/R2523242/Simulation-Engineer-Supply-Chain?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Cencora Careers",
        "apply_link": "https://careers.cencora.com/us/en/job/R2523242/Simulation-Engineer-Supply-Chain?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/cCMwXHk6HcfhsFhWMSOkJvsMbRYzJa1VoQehAqbdWDeno7Y_Oz0JNQ?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/8a691ec6b6682787516e82bdcee83da8?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Our team members are at the heart of everything we do. At Cencora, we are united in our responsibility to create healthier futures, and every person here is essential to us being able to deliver on that purpose. If you want to make a difference at the center of health, come join our innovative company and help us improve the lives of people and animals everywhere. Apply today!\n\nJob Details\n\nWe are seeking a talented and experienced Supply Chain Simulation Engineer to lead and collaborate on the design, development, and deployment of tools and strategies that will enable more effective data-driven decision making.\n\nThis individual will provide guidance through advanced analytics modeling and optimizing facilities within the Supply Chain.\n\nThe Simulation Engineer should have a firm understanding of distribution operational and automation processes.\n\nThe ideal candidate will be a skilled communicator with experience telling compelling stories through data-driven insights.\n\nRoles and Responsibilities:\n• Create simulation models of our distribution centers that will help determine efficiency opportunities.\n• Understand and have experience with design and / or implementation of automation solutions such as conveyors, sorters, high speed picking and packaging lines, robotic work cells.\n• Work closely with other teams, such as Engineering and Operations, in the validation of the models and in the design of potential scenarios that will improve the total outcome.\n• Collaborate in developing a cost to serve model.\n• Implement and support the new inhouse simulation capabilities – process, tools, training.\n• Collaborate in the creation of business cases to close gaps and define capex requirements.\n• Provide advice and insights on improving existing simulation capabilities.\n• Design interactive business intelligence dashboards to share input and outputs.\n• Develop and train team to utilize self-service modeling functionality.\n• Stay up to date with modeling and simulations trends.\n• Perform other duties as assigned.\n\nEducation:\n• A Bachelors degree in Industrial Engineering, Operations Research, Quantitative Methods, Data Science or related field or equivalent professional qualification/workplace skills.\n• Master’s degree preferred.\n\nExperience:\n• Requires five (5) to seven (7) years of directly related and progressively responsible experience.\n• Hands-on experience using simulation and analytical tools to solve operational problems.\n• Practical experience with Simulation frameworks (discrete-event, agent-based) and technologies such as AnyLogic/Arena/EnterpriseDynamics/FlexSim/etc\n• Project Management / Agile hands-on experience.\n• Experience working in an Operations environment.\n• Experience with business intelligence tools (PowerBI, Tableau, Qlik).\n• Experience pulling and cleaning data from Cloud Platforms (Google, Azure), or Supply Chain Tools (including ERP, WMS, TMS, Inventory & Forecasting Tools).\n• Experience programming with data analytic tools such as SQL, Python, DataBricks, etc.\n• Experience transforming CAD data into simulation tools.\n• Experience building business cases and cost/benefit analysis to support strategic decision making.\n\nSkills and Abilities:\n• Strong analytical and critical thinking skills, with the ability to identify and resolve complex issues quickly and innovative. Experience leveraging analytic based approaches to problem solving, such as Statistical Process Control, Design of Experiments, Six Sigma, or other statistical analysis frameworks.\n• Team oriented and collaborative working style.\n• Growth mindset, positive attitude and strong interest in solving business challenges and adapting to a changing work environment.\n• Ability to communicate effectively both orally and in writing; ability to communicate (and work) effectively with people from different technical and business backgrounds, acting as a liaison, understanding, and appreciating different perspectives and translating into terms necessary for any group or individual to understand.\n• Presentation skills: ability to present and discuss technical information in a manner that establishes rapport, persuades others, and establishes understanding for technical and non-technical audiences.\n• Strong organizational skills; attention to detail.\n• Must be able to interact well with others both directly (face-to-face) and remotely within a multi-discipline shared work environment.\n• Ability to influence through the use of data and insights while showing tactful discretion with difficult/sensitive information.\n• Travel required per project, estimated at 2 weeks per quarter.\n• Ability to manage multiple projects\n\nWhat Cencora offers\n\nWe provide compensation, benefits, and resources that enable a highly inclusive culture and support our team members’ ability to live with purpose every day. In addition to traditional offerings like medical, dental, and vision care, we also provide a comprehensive suite of benefits that focus on the physical, emotional, financial, and social aspects of wellness. This encompasses support for working families, which may include backup dependent care, adoption assistance, infertility coverage, family building support, behavioral health solutions, paid parental leave, and paid caregiver leave. To encourage your personal growth, we also offer a variety of training programs, professional development resources, and opportunities to participate in mentorship programs, employee resource groups, volunteer activities, and much more. For details, visit https://www.virtualfairhub.com/cencora\n\nFull time\n\nSalary Range*\n\n$88,700 - 126,940\n• This Salary Range reflects a National Average for this job. The actual range may vary based on your locale. Ranges in Colorado/California/Washington/New York/Hawaii/Vermont/Minnesota/Massachusetts/Illinois State-specific locations may be up to 10% lower than the minimum salary range, and 12% higher than the maximum salary range.\n\nEqual Employment Opportunity\n\nCencora is committed to providing equal employment opportunity without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, disability, veteran status or membership in any other class protected by federal, state or local law.\n\nThe company’s continued success depends on the full and effective utilization of qualified individuals. Therefore, harassment is prohibited and all matters related to recruiting, training, compensation, benefits, promotions and transfers comply with equal opportunity principles and are non-discriminatory.\n\nCencora is committed to providing reasonable accommodations to individuals with disabilities during the employment process which are consistent with legal requirements. If you wish to request an accommodation while seeking employment, please call 888.692.2272 or email hrsc@cencora.com. We will make accommodation determinations on a request-by-request basis. Messages and emails regarding anything other than accommodations requests will not be returned\n\n.\nAffiliated Companies:\nAffiliated Companies: AmerisourceBergen Drug Corporation",
    "job_is_remote": false,
    "job_posted_at": "11 days ago",
    "job_posted_at_timestamp": 1770249600,
    "job_posted_at_datetime_utc": "2026-02-05T00:00:00.000Z",
    "job_location": "W CNSHOHOCKEN, PA",
    "job_city": "West Conshohocken",
    "job_state": "Pennsylvania",
    "job_country": "US",
    "job_latitude": 40.0698321,
    "job_longitude": -75.31629509999999,
    "job_benefits": [
      "health_insurance",
      "dental_coverage"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D4GHeUqb67eilko0QAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "The ideal candidate will be a skilled communicator with experience telling compelling stories through data-driven insights",
        "A Bachelors degree in Industrial Engineering, Operations Research, Quantitative Methods, Data Science or related field or equivalent professional qualification/workplace skills",
        "Requires five (5) to seven (7) years of directly related and progressively responsible experience",
        "Hands-on experience using simulation and analytical tools to solve operational problems",
        "Practical experience with Simulation frameworks (discrete-event, agent-based) and technologies such as AnyLogic/Arena/EnterpriseDynamics/FlexSim/etc",
        "Project Management / Agile hands-on experience",
        "Experience working in an Operations environment",
        "Experience with business intelligence tools (PowerBI, Tableau, Qlik)",
        "Experience pulling and cleaning data from Cloud Platforms (Google, Azure), or Supply Chain Tools (including ERP, WMS, TMS, Inventory & Forecasting Tools)",
        "Experience programming with data analytic tools such as SQL, Python, DataBricks, etc",
        "Experience transforming CAD data into simulation tools",
        "Experience building business cases and cost/benefit analysis to support strategic decision making",
        "Strong analytical and critical thinking skills, with the ability to identify and resolve complex issues quickly and innovative",
        "Experience leveraging analytic based approaches to problem solving, such as Statistical Process Control, Design of Experiments, Six Sigma, or other statistical analysis frameworks",
        "Growth mindset, positive attitude and strong interest in solving business challenges and adapting to a changing work environment",
        "Ability to communicate effectively both orally and in writing; ability to communicate (and work) effectively with people from different technical and business backgrounds, acting as a liaison, understanding, and appreciating different perspectives and translating into terms necessary for any group or individual to understand",
        "Presentation skills: ability to present and discuss technical information in a manner that establishes rapport, persuades others, and establishes understanding for technical and non-technical audiences",
        "Strong organizational skills; attention to detail",
        "Must be able to interact well with others both directly (face-to-face) and remotely within a multi-discipline shared work environment"
      ],
      "Benefits": [
        "We provide compensation, benefits, and resources that enable a highly inclusive culture and support our team members’ ability to live with purpose every day",
        "In addition to traditional offerings like medical, dental, and vision care, we also provide a comprehensive suite of benefits that focus on the physical, emotional, financial, and social aspects of wellness",
        "This encompasses support for working families, which may include backup dependent care, adoption assistance, infertility coverage, family building support, behavioral health solutions, paid parental leave, and paid caregiver leave",
        "To encourage your personal growth, we also offer a variety of training programs, professional development resources, and opportunities to participate in mentorship programs, employee resource groups, volunteer activities, and much more",
        "Salary Range*",
        "$88,700 - 126,940",
        "This Salary Range reflects a National Average for this job"
      ],
      "Responsibilities": [
        "This individual will provide guidance through advanced analytics modeling and optimizing facilities within the Supply Chain",
        "The Simulation Engineer should have a firm understanding of distribution operational and automation processes",
        "Create simulation models of our distribution centers that will help determine efficiency opportunities",
        "Understand and have experience with design and / or implementation of automation solutions such as conveyors, sorters, high speed picking and packaging lines, robotic work cells",
        "Work closely with other teams, such as Engineering and Operations, in the validation of the models and in the design of potential scenarios that will improve the total outcome",
        "Collaborate in developing a cost to serve model",
        "Implement and support the new inhouse simulation capabilities – process, tools, training",
        "Collaborate in the creation of business cases to close gaps and define capex requirements",
        "Provide advice and insights on improving existing simulation capabilities",
        "Design interactive business intelligence dashboards to share input and outputs",
        "Develop and train team to utilize self-service modeling functionality",
        "Stay up to date with modeling and simulations trends",
        "Perform other duties as assigned",
        "Team oriented and collaborative working style",
        "Ability to influence through the use of data and insights while showing tactful discretion with difficult/sensitive information",
        "Travel required per project, estimated at 2 weeks per quarter",
        "Ability to manage multiple projects"
      ]
    },
    "job_onet_soc": "13108100",
    "job_onet_job_zone": "4",
    "id": "careers-cencora-com-us-en-job-r2523242-simulation-engineer-supply-chain",
    "_source": "new_jobs"
  },
  {
    "job_id": "QMFI59Aeon5OiMxQAAAAAA==",
    "job_title": "Data Solutions Engineer",
    "employer_name": "Early Career",
    "employer_logo": null,
    "employer_website": null,
    "job_publisher": "Citi Careers",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://jobs.citi.com/job/irving/data-solutions-engineer/287/91594717280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Citi Careers",
        "apply_link": "https://jobs.citi.com/job/irving/data-solutions-engineer/287/91594717280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=12272bb5413dda94&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/data-solutions-engineer-citi-JV_IC1140006_KO0,23_KE24,28.htm?jl=1010030029481&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/data-solutions-engineer-at-citi-4370775693?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Experteer",
        "apply_link": "https://us.experteer.com/career/view-jobs/data-solutions-engineer-irving-tx-usa-56103968?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/18342d1b3a5230bb8ebc6b74cb10e255?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "PowerToFly",
        "apply_link": "https://powertofly.com/jobs/detail/2498189?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/data-solutions-engineer_7ea1adfb6462bb256686e6a2ee741ff3fd39e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "This Data Solutions Engineer (Applications Development Senior Programmer Analyst - C12) is responsible for building next-generation Data Engineering solutions. This intermediate-level position involves active participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. A key aspect of this role is liaising between business users and technologists to facilitate the exchange of information regarding solutions, including requirements and usage.\n\nResponsibilities:\n• Serve as an integral team member of our Data Engineering team, responsible for the design and development of Big Data solutions.\n• Partner with domain experts, product managers, analysts, and data scientists to develop robust Big Data pipelines in Hadoop or Snowflake environments.\n• Responsible for delivering a data-as-a-service framework.\n• Responsible for moving all legacy workloads to cloud platform.\n• Lead the migration of all legacy workloads to cloud platforms.\n• Engage with key stakeholders to elicit and document requirements, including detailed data flow specifications.\n• Assess appropriate solutions and collaborate with relevant teams to drive optimal implementations.\n• Work with data scientists to build client pipelines using heterogeneous sources and provide essential engineering services for data science applications.\n• Research and evaluate open-source technologies and components, recommending and integrating them into design and implementation efforts.\n• Act as a technical expert, mentoring other team members on Big Data and Cloud technology stacks.\n• Define comprehensive requirements for maintainability, testability, performance, security, quality, and usability across the data platform.\n• Drive the implementation of consistent patterns, reusable components, and coding standards for all data engineering processes.\n• Convert SAS-based pipelines into modern languages like PySpark and Scala for execution on Hadoop and non-Hadoop ecosystems.\n• Optimize Big Data applications on both Hadoop and non-Hadoop platforms for peak performance.\n• Evaluate new IT developments and evolving business requirements, recommending appropriate system alternatives and/or enhancements to current systems through analysis of business processes, systems, and industry standards.\n• Appropriately assess risk when making business decisions, demonstrating consideration for the firm's reputation and safeguarding Citigroup, its clients, and assets. This includes driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct, and business practices, and escalating, managing, and reporting control issues with transparency.\n\nRequired Qualifications:\n• 5+ years of experience with Hadoop and Big Data technologies\n• Demonstrated proficiency in Python, PySpark, and Scala, including practical experience with fundamental machine learning libraries\n• Experience in developing robust data solutions leveraging Google Cloud or AWS platforms; relevant certifications are preferred\n• Experience with SAS\n• Experience with containerization and related technologies (e.g., Docker, Kubernetes)\n• Comprehensive understanding of software engineering and data analytics\n• In-depth knowledge and hands-on experience with the Hadoop ecosystem and Big Data technologies (e.g., HDFS, MapReduce, Hive, Pig, Impala, Kafka, Kudu, Solr)\n• Knowledge of Agile (Scrum) development methodologies.\n• Strong development and automation skills.\n• System-level understanding of data structures, algorithms, distributed storage, and compute.\n• A proactive approach to solving complex business problems, complemented by strong interpersonal and teamwork skills.\n\nDesired Qualifications\n• Familiarity with Hadoop administration and Snowflake.\n• Proficiency in Java or additional experience with Apache Beam.\n\nEducation:\n• Bachelor’s degree/University degree or equivalent experience\n\nApplicants must be authorized to work in the U.S for this position; Citi will not sponsor applicants for U.S. work authorization for this role. Candidate must be located within commuting distance or be willing to relocate to the area.\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nPrimary Location:\nIrving Texas United States\n\n------------------------------------------------------\n\nPrimary Location Full Time Salary Range:\n$107,120.00 - $160,680.00\n\nIn addition to salary, Citi’s offerings may also include, for eligible employees, discretionary and formulaic incentive and retention awards. Citi offers competitive employee benefits, including: medical, dental & vision coverage; 401(k); life, accident, and disability insurance; and wellness programs. Citi also offers paid time off packages, including planned time off (vacation), unplanned time off (sick leave), and paid holidays. For additional information regarding Citi employee benefits, please visit citibenefits.com. Available offerings may vary by jurisdiction, job level, and date of hire.\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nFor complementary skills, please see above and/or contact the recruiter.\n\n------------------------------------------------------\n\nAnticipated Posting Close Date:\nFeb 24, 2026\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi’s EEO Policy Statement and the Know Your Rights poster.",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Jacksonville, FL",
    "job_city": "Jacksonville",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 30.3297566,
    "job_longitude": -81.6591529,
    "job_benefits": [
      "paid_time_off",
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DQMFI59Aeon5OiMxQAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "5+ years of experience with Hadoop and Big Data technologies",
        "Demonstrated proficiency in Python, PySpark, and Scala, including practical experience with fundamental machine learning libraries",
        "Experience with SAS",
        "Experience with containerization and related technologies (e.g., Docker, Kubernetes)",
        "Comprehensive understanding of software engineering and data analytics",
        "In-depth knowledge and hands-on experience with the Hadoop ecosystem and Big Data technologies (e.g., HDFS, MapReduce, Hive, Pig, Impala, Kafka, Kudu, Solr)",
        "Knowledge of Agile (Scrum) development methodologies",
        "Strong development and automation skills",
        "System-level understanding of data structures, algorithms, distributed storage, and compute",
        "A proactive approach to solving complex business problems, complemented by strong interpersonal and teamwork skills",
        "Bachelor’s degree/University degree or equivalent experience",
        "Applicants must be authorized to work in the U.S for this position; Citi will not sponsor applicants for U.S. work authorization for this role",
        "Candidate must be located within commuting distance or be willing to relocate to the area",
        "Please see the requirements listed above",
        "For complementary skills, please see above and/or contact the recruiter"
      ],
      "Benefits": [
        "$107,120.00 - $160,680.00",
        "In addition to salary, Citi’s offerings may also include, for eligible employees, discretionary and formulaic incentive and retention awards",
        "Citi offers competitive employee benefits, including: medical, dental & vision coverage; 401(k); life, accident, and disability insurance; and wellness programs",
        "Citi also offers paid time off packages, including planned time off (vacation), unplanned time off (sick leave), and paid holidays"
      ],
      "Responsibilities": [
        "This intermediate-level position involves active participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team",
        "A key aspect of this role is liaising between business users and technologists to facilitate the exchange of information regarding solutions, including requirements and usage",
        "Serve as an integral team member of our Data Engineering team, responsible for the design and development of Big Data solutions",
        "Partner with domain experts, product managers, analysts, and data scientists to develop robust Big Data pipelines in Hadoop or Snowflake environments",
        "Responsible for delivering a data-as-a-service framework",
        "Responsible for moving all legacy workloads to cloud platform",
        "Lead the migration of all legacy workloads to cloud platforms",
        "Engage with key stakeholders to elicit and document requirements, including detailed data flow specifications",
        "Assess appropriate solutions and collaborate with relevant teams to drive optimal implementations",
        "Work with data scientists to build client pipelines using heterogeneous sources and provide essential engineering services for data science applications",
        "Research and evaluate open-source technologies and components, recommending and integrating them into design and implementation efforts",
        "Act as a technical expert, mentoring other team members on Big Data and Cloud technology stacks",
        "Define comprehensive requirements for maintainability, testability, performance, security, quality, and usability across the data platform",
        "Drive the implementation of consistent patterns, reusable components, and coding standards for all data engineering processes",
        "Convert SAS-based pipelines into modern languages like PySpark and Scala for execution on Hadoop and non-Hadoop ecosystems",
        "Optimize Big Data applications on both Hadoop and non-Hadoop platforms for peak performance",
        "Evaluate new IT developments and evolving business requirements, recommending appropriate system alternatives and/or enhancements to current systems through analysis of business processes, systems, and industry standards",
        "Appropriately assess risk when making business decisions, demonstrating consideration for the firm's reputation and safeguarding Citigroup, its clients, and assets",
        "This includes driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct, and business practices, and escalating, managing, and reporting control issues with transparency",
        "This job description provides a high-level review of the types of work performed"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "jobs-citi-com-job-irving-data-solutions-engineer-287-91594717280",
    "_source": "new_jobs"
  },
  {
    "job_id": "6fRKlkpblZ3M064nAAAAAA==",
    "job_title": "Staff Software Engineer, Data Platform",
    "employer_name": "Circle",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcREwaqjwdFFUeAPrw22pQIgjuO0Rm1gqtjzhB3v&s=0",
    "employer_website": "https://www.circle.com",
    "job_publisher": "Circle",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.circle.com/us/en/job/CIICIRUSJR100826EXTERNALENUS/Staff-Software-Engineer-Data-Platform?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Circle",
        "apply_link": "https://careers.circle.com/us/en/job/CIICIRUSJR100826EXTERNALENUS/Staff-Software-Engineer-Data-Platform?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Circle/Job/Staff-Software-Engineer,-Data-Platform/-in-Salt-Lake-City,UT?jid=ba5bde77d2dbe7d5&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/8cc400d0c11615f647cb9ab3cb57e70e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "JobLeads",
        "apply_link": "https://www.jobleads.com/us/job/staff-software-engineer-data-platform--salt-lake-city--e10ee40eaf72cf92a0d704070c0ff44de?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Circle (NYSE: CRCL) is one of the world’s leading internet financial platform companies, building the foundation of a more open, global economy through digital assets, payment applications, and programmable blockchain infrastructure. Circle’s platform includes the world’s largest regulated stablecoin network anchored by USDC, Circle Payments Network for global money movement, and Arc, an enterprise-grade blockchain designed to become the Economic OS for the internet. Enterprises, financial institutions, and developers use Circle to power trusted, internet-scale financial innovation. Learn more at circle.com.\n\nWhat you’ll be part of:\n\nCircle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: High Integrity, Future Forward, Multistakeholder, Mindful, and Driven by Excellence. We have built a flexible work environment where new ideas are encouraged and everyone is a stakeholder.\n\nHere is our team hierarchy for individual contributors:\n\nSenior Software Engineer (III)\n\nStaff Software Engineer (IV)\n\nYour team is responsible for:\n\nAs a member of the Data Platform Engineering team, you own the core Data warehouse platform, data ingestion and processing, ETL/ELT pipelines orchestration platform, data cataloging, data governance. These components power our Product, Engineering, Analytics, and Data Science teams by enabling experimentation, operational excellence, and actionable insights to accelerate business growth.\n\nYou'll work on:\n• Design, build, and operate data platform services (warehousing, orchestration, and catalogs). Continuously enhance platform operations by improving monitoring, performance, reliability, and resource optimization.\n• Design, build and maintain batch and streaming data ingestion framework to source the required data for analytical and operational needs, which include onchain data, internal system data, and partner data.\n• Be a domain expert in streaming processing, data pipelines, data warehousing and quality. Work closely across multiple stakeholders–including Product, Engineering, Data Science, Security and Compliance teams–on data contract modeling, data lifecycle management, governance and regulatory/legal compliance.\n• Provide ML data platform capabilities for AI/Data Science teams to perform data preparation, model preparation and serving, and performance monitoring.\n• Develop and maintain core services and libraries to enhance critical platform functionalities, such as cataloging data assets and lineage, tracking data versioning and quality, managing auto-backfilling, implementing access controls on data assets.\n\nYou'll bring to Circle:\n\nSenior Software Engineer (III):\n• 4+ years of software engineering experience building data-intensive systems\n• Hands-on experience designing and operating scalable batch, micro-batch, or streaming data pipelines\n• Experience in business domains such as payment systems, credit cards, bank transfers, or blockchains.\n• Familiarity with data governance, lineage, and provenance concepts\n• Strong understanding of open-source data technologies and cloud-native data platforms\n• Ability to tackle complex and ambiguous problems.\n• Self-starter who takes ownership and enjoys moving at a fast pace.\n• Excellent communication skills, with the ability to collaborate across multiple remote teams, share ideas and present concepts effectively.\n\nNice to have:\n• Experience with with streaming frameworks such as Apache Flink or Google Cloud Dataflow\n• Experience with NoSQL databases such as Bigtable, Cassandra\n\n​\n\nStaff Software Engineer (IV):\n\nIncludes all the requirements of a Senior Software Engineer, and:\n• 7+ years in software engineering experience for large-scale and complex data systems\n• Proven technical leadership in architecture and system design, influencing designs across multiple teams\n• Deep expertise in one or more of: streaming systems, data warehousing, data modeling, or large-scale ingestion platforms\n• Ability to identify high-impact technical opportunities independently and drive them from concept to production\n• Strong experience in:\n• Data platforms integrated with downstream consumers, tools, and services\n• Data quality, validation, and observability mechanisms across pipelines\n• Comfortable making and defending long-term architectural tradeoffs in ambiguous environments\n\nNice to have:\n• Hands-on Experience taking an operational, data-intensive application from initial design to production (0→1), or scaling and operating it at production scale.\n• Experience developing real-time analytics or near-real-time decisioning systems\n\nCircle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages.\n\nStarting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations.\n\nBase Pay Range: $195,000 - $257,500\n\nWe are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status, or any other protected status required by the laws in the locations where we hire. Additionally, Circle participates in the E-Verify Program in certain locations, as required by law.\n\nShould you require accommodations or assistance in our interview process because of a disability, please reach out to accommodations@circle.com for support. We respect your privacy and will connect with you separately from our interview process to accommodate your needs.\n\n#LI-Remote",
    "job_is_remote": false,
    "job_posted_at": "13 days ago",
    "job_posted_at_timestamp": 1770076800,
    "job_posted_at_datetime_utc": "2026-02-03T00:00:00.000Z",
    "job_location": "Washington, DC",
    "job_city": "Washington",
    "job_state": "District of Columbia",
    "job_country": "US",
    "job_latitude": 38.9072873,
    "job_longitude": -77.0369274,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D6fRKlkpblZ3M064nAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "4+ years of software engineering experience building data-intensive systems",
        "Hands-on experience designing and operating scalable batch, micro-batch, or streaming data pipelines",
        "Experience in business domains such as payment systems, credit cards, bank transfers, or blockchains",
        "Familiarity with data governance, lineage, and provenance concepts",
        "Strong understanding of open-source data technologies and cloud-native data platforms",
        "Ability to tackle complex and ambiguous problems",
        "Self-starter who takes ownership and enjoys moving at a fast pace",
        "Excellent communication skills, with the ability to collaborate across multiple remote teams, share ideas and present concepts effectively",
        "Experience with with streaming frameworks such as Apache Flink or Google Cloud Dataflow",
        "Experience with NoSQL databases such as Bigtable, Cassandra",
        "Includes all the requirements of a Senior Software Engineer, and:",
        "7+ years in software engineering experience for large-scale and complex data systems",
        "Proven technical leadership in architecture and system design, influencing designs across multiple teams",
        "Deep expertise in one or more of: streaming systems, data warehousing, data modeling, or large-scale ingestion platforms",
        "Ability to identify high-impact technical opportunities independently and drive them from concept to production",
        "Data platforms integrated with downstream consumers, tools, and services",
        "Data quality, validation, and observability mechanisms across pipelines",
        "Comfortable making and defending long-term architectural tradeoffs in ambiguous environments",
        "Hands-on Experience taking an operational, data-intensive application from initial design to production (0→1), or scaling and operating it at production scale",
        "Experience developing real-time analytics or near-real-time decisioning systems"
      ],
      "Benefits": [
        "We consider a wide variety of elements when crafting our compensation ranges and total compensation packages",
        "Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs",
        "Base Pay Range: $195,000 - $257,500"
      ],
      "Responsibilities": [
        "As a member of the Data Platform Engineering team, you own the core Data warehouse platform, data ingestion and processing, ETL/ELT pipelines orchestration platform, data cataloging, data governance",
        "Design, build, and operate data platform services (warehousing, orchestration, and catalogs)",
        "Continuously enhance platform operations by improving monitoring, performance, reliability, and resource optimization",
        "Design, build and maintain batch and streaming data ingestion framework to source the required data for analytical and operational needs, which include onchain data, internal system data, and partner data",
        "Be a domain expert in streaming processing, data pipelines, data warehousing and quality",
        "Work closely across multiple stakeholders–including Product, Engineering, Data Science, Security and Compliance teams–on data contract modeling, data lifecycle management, governance and regulatory/legal compliance",
        "Provide ML data platform capabilities for AI/Data Science teams to perform data preparation, model preparation and serving, and performance monitoring",
        "Develop and maintain core services and libraries to enhance critical platform functionalities, such as cataloging data assets and lineage, tracking data versioning and quality, managing auto-backfilling, implementing access controls on data assets",
        "You'll bring to Circle:"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "careers-circle-com-us-en-job-ciicirusjr100826externalenus-staff-software-engineer-data-platform",
    "_source": "new_jobs"
  },
  {
    "job_id": "8ojyM0IL2Dgweb6mAAAAAA==",
    "job_title": "Lead Data Engineer",
    "employer_name": "Guardianlife",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTEHyPUSx8in9lbGwtt3n-urbaK-a93llGwRZYg&s=0",
    "employer_website": "https://www.guardianlife.com",
    "job_publisher": "ZipRecruiter",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.ziprecruiter.com/c/Guardian-Life/Job/Lead-Data-Engineer/-in-Holmdel,NJ?jid=5ff92b3cfbdbb9fa&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": true,
    "apply_options": [
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Guardian-Life/Job/Lead-Data-Engineer/-in-Holmdel,NJ?jid=5ff92b3cfbdbb9fa&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Jobright",
        "apply_link": "https://jobright.ai/jobs/info/6984c41c0f6f7e7a2cdf36a2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Lensa",
        "apply_link": "https://lensa.com/job-v1/guardian-life/holmdel-nj/lead-data-engineer/448a3771cda355807800f3a245f659f2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Adzuna",
        "apply_link": "https://www.adzuna.com/details/5618263952?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Talentify",
        "apply_link": "https://www.talentify.io/job/lead-data-engineer-holmdel-new-jersey-us-guardian-life-r000108510?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "JobLeads",
        "apply_link": "https://www.jobleads.com/us/job/lead-data-engineer--holmdel-township--e33d7f694afe11a60b979debb2c4bd89a?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/40aefed101891767dbcd5f364e470e55?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Learn4Good",
        "apply_link": "https://www.learn4good.com/jobs/holmdel-township/new-jersey/software_development/4858586430/e/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Guardian is seeking a highly skilled and motivated Lead Data Engineer to join the FPRS&CSWM Data Engineering team. In this role, you will play a crucial part in designing, building, and maintaining the data pipelines that power our Operational ,reporting, ML & AI use cases. Your expertise will help us transform raw data into actionable insights via data products, ensuring that our data solutions are robust, scalable and efficient. The ideal candidate will have a passion for data engineering, thrive in a collaborative environment and are excited about leveraging cutting-edge technologies to drive business success.\n\nYour contributions will go beyond hands-on engineering, as you help bring life to innovative ideas and mentor other engineers. You'll thrive in a fast-paced, collaborative environment, balancing technical execution with a deep understanding of business needs. We value curiosity, creativity, and continuous learning. If you're passionate about solving meaningful problems and creating value through data-driven innovation, we look forward to welcoming you to our team.\n\nYou will\n• Lead technical design and implementation of data engineering solutions, ensuring best practices and high-quality deliverables.\n• Mentor and guide junior engineers, conducting code reviews and technical sessions to foster team growth.\n• Perform detailed analysis of raw data sources by applying business context and collaborate with cross-functional teams to transform raw data into data products\n• Create scalable and trusted data pipelines which generate curated data assets in centralized data lake/data warehouse ecosystems.\n• Monitor and troubleshoot data pipeline performance, identifying and resolving bottlenecks and issues.\n• Construct meaningful data assets sourced from structured, semi structured, and unstructured data.\n• Develop real-time data solutions by creating new API endpoints or streaming frameworks.\n• Develop, test, and maintain robust tools, frameworks, and libraries that standardize and streamline the data lifecycle.\n• Collaborate with cross-functional teams of Data Science, Data Engineering, business units, and other IT teams.\n• Create and maintain effective documentation for projects and practices, ensuring transparency and effective team communication.\n• Provide technical leadership and mentorship on continuous improvement in building reusable and scalable solutions.\n• Contribute to enhancing strategy for advanced data engineering practices and lead execution of key initiatives.\n• Stay up-to-date with the latest trends in modern data engineering, machine learning & AI.\n\nYou have\n• Bachelor's or Master's degree with 8+ years of experience in Computer Science, Engineering, or a related field.\n• 5+ years of experience working with Python, SQL, PySpark, and bash scripts. Proficient in software development lifecycle and software engineering practices.\n• 4+ years of experience developing and maintaining robust data pipelines for both structured and unstructured data for advanced analytical and reporting use cases.\n• 3+ years of experience working with Cloud Data Warehousing (Redshift, Snowflake, Databricks SQL or equivalent) platforms and distributed frameworks like Spark.\n• 2+ years of experience leading a team of engineers and a track record of delivering robust and scalable data solutions with highest quality.\n• Solid understanding of data modeling and warehousing techniques. Experience working in a data warehouse is a plus.\n• Proficiency in understanding REST APIs, experience using different types of APIs to extract data or perform functionalities.\n• Hands-on experience building and maintaining tools and libraries used by multiple teams across the organization (e.g., Data Engineering utility libraries, DQ Libraries).\n• Proficient in understanding and incorporating software engineering principles in design & development process.\n• Hands-on experience with CI/CD tools (e.g., Jenkins or equivalent), version control (Github, Bitbucket), orchestration (Airflow, Prefect or equivalent).\n• Excellent communication skills and ability to work and collaborate with cross-functional teams across technology and business.\n\nLocation\n• Three days a week at a Guardian office in Bethlehem, PA, New York, NY. Pittsfield, MA or Holmdel, NJ.\n\nSalary Range:\n\n$99,150.00 - $162,885.00\n\nThe salary range reflected above is a good faith estimate of base pay for the primary location of the position. The salary for this position ultimately will be determined based on the education, experience, knowledge, and abilities of the successful candidate. In addition to salary, this role may also be eligible for annual, sales, or other incentive compensation.\n\nOur Promise\n\nAt Guardian, you'll have the support and flexibility to achieve your professional and personal goals. Through skill-building, leadership development and philanthropic opportunities, we provide opportunities to build communities and grow your career, surrounded by diverse colleagues with high ethical standards.\n\nInspire Well-Being\n\nAs part of Guardian's Purpose - to inspire well-being - we are committed to offering contemporary, supportive, flexible, and inclusive benefits and resources to our colleagues. Explore our company benefits at www.guardianlife.com/careers/corporate/benefits.Benefits apply to full-time eligible employees. Interns are not eligible for most Company benefits.\n\nEqual Employment Opportunity\n\nGuardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law.\n\nAccommodations\n\nGuardian is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities.Guardian also provides reasonable accommodations to qualified job applicants (and employees) to accommodate the individual's known limitations related to pregnancy, childbirth, or related medical conditions, unless doing so would create an undue hardship. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact MyHR@glic.com. Please note: this resource is for accommodation requests only. For all other inquires related to your application and careers at Guardian, refer to the Guardian Careers site.\n\nVisa Sponsorship\n\nGuardian is not currently or in the foreseeable future sponsoring employment visas. In order to be a successful applicant. you must be legally authorized to work in the United States, without the need for employer sponsorship.\n\nCurrent Guardian Colleagues: Please apply through the internal Jobs Hub in Workday.",
    "job_is_remote": false,
    "job_posted_at": "11 days ago",
    "job_posted_at_timestamp": 1770249600,
    "job_posted_at_datetime_utc": "2026-02-05T00:00:00.000Z",
    "job_location": "Holmdel, NJ",
    "job_city": "Holmdel",
    "job_state": "New Jersey",
    "job_country": "US",
    "job_latitude": 40.3848944,
    "job_longitude": -74.18900599999999,
    "job_benefits": [
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D8ojyM0IL2Dgweb6mAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_min_salary": 99150,
    "job_max_salary": 162885,
    "job_salary_period": "YEAR",
    "job_highlights": {
      "Qualifications": [
        "We value curiosity, creativity, and continuous learning",
        "Bachelor's or Master's degree with 8+ years of experience in Computer Science, Engineering, or a related field",
        "5+ years of experience working with Python, SQL, PySpark, and bash scripts",
        "Proficient in software development lifecycle and software engineering practices",
        "4+ years of experience developing and maintaining robust data pipelines for both structured and unstructured data for advanced analytical and reporting use cases",
        "3+ years of experience working with Cloud Data Warehousing (Redshift, Snowflake, Databricks SQL or equivalent) platforms and distributed frameworks like Spark",
        "2+ years of experience leading a team of engineers and a track record of delivering robust and scalable data solutions with highest quality",
        "Solid understanding of data modeling and warehousing techniques",
        "Proficiency in understanding REST APIs, experience using different types of APIs to extract data or perform functionalities",
        "Hands-on experience building and maintaining tools and libraries used by multiple teams across the organization (e.g., Data Engineering utility libraries, DQ Libraries)",
        "Proficient in understanding and incorporating software engineering principles in design & development process",
        "Hands-on experience with CI/CD tools (e.g., Jenkins or equivalent), version control (Github, Bitbucket), orchestration (Airflow, Prefect or equivalent)",
        "Excellent communication skills and ability to work and collaborate with cross-functional teams across technology and business",
        "you must be legally authorized to work in the United States, without the need for employer sponsorship"
      ],
      "Benefits": [
        "$99,150.00 - $162,885.00",
        "The salary range reflected above is a good faith estimate of base pay for the primary location of the position",
        "The salary for this position ultimately will be determined based on the education, experience, knowledge, and abilities of the successful candidate",
        "In addition to salary, this role may also be eligible for annual, sales, or other incentive compensation",
        "Interns are not eligible for most Company benefits"
      ],
      "Responsibilities": [
        "In this role, you will play a crucial part in designing, building, and maintaining the data pipelines that power our Operational ,reporting, ML & AI use cases",
        "Your expertise will help us transform raw data into actionable insights via data products, ensuring that our data solutions are robust, scalable and efficient",
        "Your contributions will go beyond hands-on engineering, as you help bring life to innovative ideas and mentor other engineers",
        "You'll thrive in a fast-paced, collaborative environment, balancing technical execution with a deep understanding of business needs",
        "Lead technical design and implementation of data engineering solutions, ensuring best practices and high-quality deliverables",
        "Mentor and guide junior engineers, conducting code reviews and technical sessions to foster team growth",
        "Perform detailed analysis of raw data sources by applying business context and collaborate with cross-functional teams to transform raw data into data products",
        "Create scalable and trusted data pipelines which generate curated data assets in centralized data lake/data warehouse ecosystems",
        "Monitor and troubleshoot data pipeline performance, identifying and resolving bottlenecks and issues",
        "Construct meaningful data assets sourced from structured, semi structured, and unstructured data",
        "Develop real-time data solutions by creating new API endpoints or streaming frameworks",
        "Develop, test, and maintain robust tools, frameworks, and libraries that standardize and streamline the data lifecycle",
        "Collaborate with cross-functional teams of Data Science, Data Engineering, business units, and other IT teams",
        "Create and maintain effective documentation for projects and practices, ensuring transparency and effective team communication",
        "Provide technical leadership and mentorship on continuous improvement in building reusable and scalable solutions",
        "Contribute to enhancing strategy for advanced data engineering practices and lead execution of key initiatives",
        "Stay up-to-date with the latest trends in modern data engineering, machine learning & AI"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-ziprecruiter-com-c-guardian-life-job-lead-data-engineer-in-holmdel-nj",
    "_source": "new_jobs"
  },
  {
    "job_id": "zwAG5QQq-v9l2VvrAAAAAA==",
    "job_title": "Data Analytics Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=23eaffa71bc9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=23eaffa71bc9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Data / Analytics Engineer to support the VHA Veteran Family Member Program Modernization initiative.\n\nKey Responsibilities\n\nBuild and maintain data pipelines and workflows\n\nSupport analytics, modeling, and visualization efforts\n\nEnsure data integrity, security, and alignment with VA architecture standards\n\nRequired Qualifications\n\nBachelor's degree\n\n5+ years in analytics, data engineering, and visualization tools such as Azure and Databricks\n\nAbility to work without sponsorship in the US indefinitely",
    "job_is_remote": false,
    "job_posted_at": "4 days ago",
    "job_posted_at_timestamp": 1770854400,
    "job_posted_at_datetime_utc": "2026-02-12T00:00:00.000Z",
    "job_location": "Lake Charles, LA",
    "job_city": "Lake Charles",
    "job_state": "Louisiana",
    "job_country": "US",
    "job_latitude": 30.2265949,
    "job_longitude": -93.2173758,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DzwAG5QQq-v9l2VvrAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's degree",
        "5+ years in analytics, data engineering, and visualization tools such as Azure and Databricks",
        "Ability to work without sponsorship in the US indefinitely"
      ],
      "Responsibilities": [
        "Build and maintain data pipelines and workflows",
        "Support analytics, modeling, and visualization efforts",
        "Ensure data integrity, security, and alignment with VA architecture standards"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "uuiihkAJSRtJByehAAAAAA==",
    "job_title": "Senior Data Analytics Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=04813c62bcb3&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=04813c62bcb3&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Senior Data Analytics Engineer to join their Data Solutions team.\n\nKey Responsibilities\n\nLead data analytics projects to build innovative solutions while ensuring adherence to budget, schedule, and scope\n\nMentor members in the Analytics Center of Excellence and assist with data catalog and visualization software oversight\n\nDrive data and analytics solutions from conception to deployment with clear ROI impact\n\nRequired Qualifications\n\nBachelor's degree in computer or information science preferred or relevant experience\n\n5+ years of relevant experience in a data-driven professional setting\n\nStrong command of databases and SQL, with proficiency in Python or R for data manipulation and analysis\n\nThorough understanding of project management principles and information technology practices\n\nStrong data analytics background, including experience with SQL, Snowflake Database, Azure cloud, and data visualization tools",
    "job_is_remote": false,
    "job_posted_at": "3 days ago",
    "job_posted_at_timestamp": 1770940800,
    "job_posted_at_datetime_utc": "2026-02-13T00:00:00.000Z",
    "job_location": "Southport, IN",
    "job_city": "Southport",
    "job_state": "Indiana",
    "job_country": "US",
    "job_latitude": 39.6618814,
    "job_longitude": -86.1166506,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DuuiihkAJSRtJByehAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "5+ years of relevant experience in a data-driven professional setting",
        "Strong command of databases and SQL, with proficiency in Python or R for data manipulation and analysis",
        "Thorough understanding of project management principles and information technology practices",
        "Strong data analytics background, including experience with SQL, Snowflake Database, Azure cloud, and data visualization tools"
      ],
      "Responsibilities": [
        "Lead data analytics projects to build innovative solutions while ensuring adherence to budget, schedule, and scope",
        "Mentor members in the Analytics Center of Excellence and assist with data catalog and visualization software oversight",
        "Drive data and analytics solutions from conception to deployment with clear ROI impact"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "oaZhJr3jQehnUEK1AAAAAA==",
    "job_title": "Lead Analytics Engineer",
    "employer_name": "Parachute Health",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT-x7abOmgSrsz70dDf516m2TPyYDzTJhGwyrMo&s=0",
    "employer_website": "https://www.parachutehealth.com",
    "job_publisher": "Jobilize",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.jobilize.com/job/us-ca-bakersfield-lead-analytics-engineer-parachute-health-hiring?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Jobilize",
        "apply_link": "https://www.jobilize.com/job/us-ca-bakersfield-lead-analytics-engineer-parachute-health-hiring?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Lead Analytics Engineer\n\nNearly half of patients needing medical equipment at discharge don't get it in time. The ordering process is too convoluted and is still primarily handled by fax. These inefficiencies lead to higher cost of care and poorer patient outcomes. In the most extreme cases, this equipment means life or death. At Parachute Health, it is our mission to make sure that every patient gets what they need, when they need it. We achieve this by driving efficiency through digital connectivity into every aspect of the ordering process, making it delightfully simple.\n\nWe're leading the charge with a platform that is 10 times faster than the status quo. We connect with major hospitals, payors, and suppliers of life-saving products. Our vision of a \"delightfully simple\" digital ordering experience for clinicians pushes us forward to transforming the world of post-acute care.\n\nWe've built a strong network of clinicians, suppliers, health plans, and patients that we serve every daybut we're ready to amplify our story in a bigger, more systematic way. That's where you come in.\nResponsibilities\n\nTechnical Leadership\n• Design, optimize, and scale end-to-end data pipelines and cloud-based infrastructure for analytics, reporting, and machine learning.\n• Own data integration, transformation, and modeling processes, ensuring accuracy, accessibility, and analytical readiness.\n• Lead implementation of dbt, Looker, and other modern analytics tools to deliver scalable, maintainable solutions.\n• Define and enforce standards for data modeling, data governance, lineage, monitoring, and compliance.\n• Evaluate emerging technologies and drive architecture decisions to future-proof the platform.\n\nProject & Team Leadership\n• Lead complex initiatives spanning multiple teams and business domains.\n• Set project direction, ensure timely delivery, and maintain high-quality standards.\n• Translate business requirements into robust technical solutions.\n• Mentor data analysts and analytics engineers on technical challenges, best practices, and career growth.\n\nStrategic Contribution\n• Collaborate with leadership to ensure the data platform aligns with business objectives.\n• Identify opportunities to improve efficiency, scalability, and business impact through data.\n• Facilitate alignment across technical and non-technical stakeholders, promoting a culture of data-driven decision-making.\n• Foster knowledge sharing, continuous feedback, and cross-team collaboration.\nQualifications\n\nExperience & Education\n• Bachelor's degree in Computer Science, Data Science, related field, or equivalent experience.\n• 7+ years in data engineering or analytics engineering delivering scalable, high-impact solutions.\n• 1+ years in senior-level roles with leadership and cross-team responsibilities.\n• Experience in cloud-native environments (BigQuery, Snowflake, Redshift, or similar).\n\nTechnical Skills\n• Expert in SQL, Python, and modern analytics tools (dbt, Fivetran, Airflow, or equivalents).\n• Strong experience in data modeling, ELT/ETL pipelines, and cloud data warehouses.\n• Advanced proficiency with Looker or similar BI tools (LookML, dashboards, visualization).\n• Knowledge of data governance, quality frameworks, and testing methodologies.\n• Familiarity with machine learning pipelines, predictive modeling, or AutoML is a plus.\n\nLeadership & Soft Skills\n• Proven ability to lead technical initiatives and mentor team members.\n• Strong problem-solving skills, designing scalable, maintainable architectures.\n• Excellent communication with technical and non-technical audiences.\n• Comfortable navigating ambiguity and driving decisions in fast-paced environments.\n• Experience in influencing senior stakeholders without direct authority.\nBenefits\n• Medical, Dental, and Vision Coverage\n• 401(k) Retirement Plan\n• Remote-First Company with the option to work at our New York City office\n• Equity Incentive Plan\n• Annual Company-Wide Bonus (up to 15%)\n• Flexible Vacation Policy\n• Summer Fridays - 5 Fridays Off During Summer (Separate From PTO)\n• Monthly Internet Stipend\n• Annual Home Office Stipend\n• Co-Working Space Reimbursement\n• Annual stipend for education and development\nBase Salary Bands (based on experience and level)\n\nAnalytics Engineer III: $130,000 - $180,000\n\nAnalytics Engineer IV: $170,000 - $210,000",
    "job_is_remote": false,
    "job_posted_at": "1 day ago",
    "job_posted_at_timestamp": 1771113600,
    "job_posted_at_datetime_utc": "2026-02-15T00:00:00.000Z",
    "job_location": "Bakersfield, CA",
    "job_city": "Bakersfield",
    "job_state": "California",
    "job_country": "US",
    "job_latitude": 35.373511199999996,
    "job_longitude": -119.02047069999999,
    "job_benefits": [
      "paid_time_off",
      "health_insurance",
      "dental_coverage"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DoaZhJr3jQehnUEK1AAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's degree in Computer Science, Data Science, related field, or equivalent experience",
        "7+ years in data engineering or analytics engineering delivering scalable, high-impact solutions",
        "1+ years in senior-level roles with leadership and cross-team responsibilities",
        "Experience in cloud-native environments (BigQuery, Snowflake, Redshift, or similar)",
        "Expert in SQL, Python, and modern analytics tools (dbt, Fivetran, Airflow, or equivalents)",
        "Strong experience in data modeling, ELT/ETL pipelines, and cloud data warehouses",
        "Advanced proficiency with Looker or similar BI tools (LookML, dashboards, visualization)",
        "Knowledge of data governance, quality frameworks, and testing methodologies",
        "Leadership & Soft Skills",
        "Proven ability to lead technical initiatives and mentor team members",
        "Strong problem-solving skills, designing scalable, maintainable architectures",
        "Excellent communication with technical and non-technical audiences",
        "Comfortable navigating ambiguity and driving decisions in fast-paced environments",
        "Experience in influencing senior stakeholders without direct authority"
      ],
      "Benefits": [
        "Medical, Dental, and Vision Coverage",
        "401(k) Retirement Plan",
        "Remote-First Company with the option to work at our New York City office",
        "Equity Incentive Plan",
        "Annual Company-Wide Bonus (up to 15%)",
        "Flexible Vacation Policy",
        "Summer Fridays - 5 Fridays Off During Summer (Separate From PTO)",
        "Monthly Internet Stipend",
        "Annual Home Office Stipend",
        "Co-Working Space Reimbursement",
        "Annual stipend for education and development",
        "Base Salary Bands (based on experience and level)",
        "Analytics Engineer III: $130,000 - $180,000",
        "Analytics Engineer IV: $170,000 - $210,000"
      ],
      "Responsibilities": [
        "Design, optimize, and scale end-to-end data pipelines and cloud-based infrastructure for analytics, reporting, and machine learning",
        "Own data integration, transformation, and modeling processes, ensuring accuracy, accessibility, and analytical readiness",
        "Lead implementation of dbt, Looker, and other modern analytics tools to deliver scalable, maintainable solutions",
        "Define and enforce standards for data modeling, data governance, lineage, monitoring, and compliance",
        "Evaluate emerging technologies and drive architecture decisions to future-proof the platform",
        "Project & Team Leadership",
        "Lead complex initiatives spanning multiple teams and business domains",
        "Set project direction, ensure timely delivery, and maintain high-quality standards",
        "Translate business requirements into robust technical solutions",
        "Mentor data analysts and analytics engineers on technical challenges, best practices, and career growth",
        "Strategic Contribution",
        "Collaborate with leadership to ensure the data platform aligns with business objectives",
        "Identify opportunities to improve efficiency, scalability, and business impact through data",
        "Facilitate alignment across technical and non-technical stakeholders, promoting a culture of data-driven decision-making",
        "Foster knowledge sharing, continuous feedback, and cross-team collaboration"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-jobilize-com-job-us-ca-bakersfield-lead-analytics-engineer-parachute-health-hiring",
    "_source": "new_jobs"
  },
  {
    "job_id": "8JZA4-i-u69bI9q_AAAAAA==",
    "job_title": "Senior Analytics Developer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=e89889122b9c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=e89889122b9c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Senior Analytics Developer, Brokerage & Ledger Product Data Science.\n\nKey Responsibilities\n\nDesign, build, and maintain high-quality analytical data models for brokerage and ledger workflows\n\nOwn critical datasets that support client-facing metrics, operational decision-making, and regulatory reporting\n\nCollaborate with cross-functional teams to translate stakeholder needs into durable data solutions\n\nRequired Qualifications\n\nExperience working with large, complex analytical datasets in a production environment\n\nStrong SQL skills and experience building analytical models or data marts\n\nProduct-oriented mindset focused on data usability and long-term ownership\n\nFamiliarity with modern analytics tooling such as dbt, Airflow, Python, and cloud data warehouses\n\nExperience in financial services, trading, or accounting is a plus",
    "job_is_remote": false,
    "job_posted_at": "5 days ago",
    "job_posted_at_timestamp": 1770768000,
    "job_posted_at_datetime_utc": "2026-02-11T00:00:00.000Z",
    "job_location": "Davie, FL",
    "job_city": "Davie",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 26.076478299999998,
    "job_longitude": -80.25211569999999,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D8JZA4-i-u69bI9q_AAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Experience working with large, complex analytical datasets in a production environment",
        "Strong SQL skills and experience building analytical models or data marts",
        "Product-oriented mindset focused on data usability and long-term ownership",
        "Familiarity with modern analytics tooling such as dbt, Airflow, Python, and cloud data warehouses"
      ],
      "Responsibilities": [
        "Design, build, and maintain high-quality analytical data models for brokerage and ledger workflows",
        "Own critical datasets that support client-facing metrics, operational decision-making, and regulatory reporting",
        "Collaborate with cross-functional teams to translate stakeholder needs into durable data solutions"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "dr4deofs-aDqrKQDAAAAAA==",
    "job_title": "Thermal Analysis Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=8252427480ad&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=8252427480ad&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Thermal Analysis Engineer for a fully remote contract position.\n\nKey Responsibilities\n\nDevelop and modify thermal models for reactor structures and evaluate thermal profiles\n\nAssess specific areas of challenge in configurations and provide recommendations for modifications\n\nCollaborate with design leads and analysis engineers to address component issues and provide feedback\n\nRequired Qualifications\n\nBachelor's degree in mechanical engineering or a relevant equivalent program\n\n5-10 years of relevant experience, with a preference for candidates with a PE license\n\nExperience in ASME BPVC Section III, Division 1, and high temperature applications\n\nQualification indoctrination to the client's quality program\n\nStrong integrity and teamwork orientation",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Mission Viejo, CA",
    "job_city": "Mission Viejo",
    "job_state": "California",
    "job_country": "US",
    "job_latitude": 33.596891299999996,
    "job_longitude": -117.6581562,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3Ddr4deofs-aDqrKQDAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's degree in mechanical engineering or a relevant equivalent program",
        "5-10 years of relevant experience, with a preference for candidates with a PE license",
        "Experience in ASME BPVC Section III, Division 1, and high temperature applications",
        "Qualification indoctrination to the client's quality program",
        "Strong integrity and teamwork orientation"
      ],
      "Responsibilities": [
        "Develop and modify thermal models for reactor structures and evaluate thermal profiles",
        "Assess specific areas of challenge in configurations and provide recommendations for modifications",
        "Collaborate with design leads and analysis engineers to address component issues and provide feedback"
      ]
    },
    "job_onet_soc": "17214100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "xIy-w4lp_7eHIBzJAAAAAA==",
    "job_title": "CTIO-AI Engineer-Sr Associate",
    "employer_name": "Line of Service:Internal Firm Services",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQbISADYwodxUByAAwOWWSxMKSDRSb_NgVyIy99&s=0",
    "employer_website": null,
    "job_publisher": "PwC | US Careers",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://jobs.us.pwc.com/job/new-york/ctio-ai-engineer-sr-associate/932/91339725632?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "PwC | US Careers",
        "apply_link": "https://jobs.us.pwc.com/job/new-york/ctio-ai-engineer-sr-associate/932/91339725632?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/PwC/Job/CTIO-AI-Engineer-Sr-Associate/-in-Saint-Louis,MO?jid=4b5d8fcf834930b0&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=9eecfea443c4a281&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/ctio-ai-engineer-sr-associate-at-pwc-4368756425?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/ctio-ai-engineer-sr-associate-pwc-JV_IC1131270_KO0,29_KE30,33.htm?jl=1010022854043&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Career.io",
        "apply_link": "https://career.io/job/ctio-ai-engineer-sr-associate-st-louis-pwc-8edb9e3828997f3663ef9ecfdaed92ff?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/pRVYXuDZYs6LRg5SJPdUOa1MCpmR7cH-WINKhFaqPqNX14FEKBcrCw?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Talentify",
        "apply_link": "https://www.talentify.io/job/ctio-ai-engineer-sr-associate-st-louis-missouri-us-pwc-702342wd?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making. You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems.\n\nFocused on relationships, you are building meaningful client connections, and learning how to manage and inspire others. Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths. You are expected to anticipate the needs of your teams and clients, and to deliver quality. Embracing increased ambiguity, you are comfortable when the path forward isn’t clear, you ask questions, and you use these moments as opportunities to grow.\n\nExamples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to:\n• Respond effectively to the diverse perspectives, needs, and feelings of others.\n• Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems.\n• Use critical thinking to break down complex concepts.\n• Understand the broader objectives of your project or role and how your work fits into the overall strategy.\n• Develop a deeper understanding of the business context and how it is changing.\n• Use reflection to develop self awareness, enhance strengths and address development areas.\n• Interpret data to inform insights and recommendations.\n• Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements.\n\nThe Opportunity\n\nAs part of the Data and Analytics Engineering team you will develop and implement AI solutions that enhance product offerings. As a Senior Associate, you will analyze complex problems, mentor junior team members, and maintain elevated professional standards while building meaningful client relationships.\n\nResponsibilities\n\n- Build and nurture meaningful relationships with clients\n\n- Utilize advanced analytical techniques to drive innovation\n\n- Work with cross-functional teams to achieve project goals\n\n- Uphold the firm's ethical standards and recommended practices\n\nWhat You Must Have\n\n- Bachelor's Degree in Computer Science, Data Processing/Analytics/Science, Artificial Intelligence and Robotics\n\n- 3 years of professional experience developing AI/ML systems or integrating AI into products\n\nWhat Sets You Apart\n\n- Master's Degree preferred\n\n- Possessing advanced proficiency in prompt engineering\n\n- Demonstrating experience deploying LLMs into production\n\n- Designing and optimizing RAG pipelines\n\n- Leading technical discovery in fast-paced environments\n\n- Collaborating effectively with cross-functional leaders\n\n- Advocating for responsible AI principles\n\n- Contributing to AI research or open-source communities\n\n- Demonstrating knowledge of orchestration tools such as LangChain, LlamaIndex, and experience with agent-based systems\n\nLearn more about how we work: https://pwc.to/how-we-work\n\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n\nAs PwC is an equal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law. \n\nFor only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.\n\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines\n\nThe salary range for this position is: $55,000 - $151,470. For residents of Washington state the salary range for this position is: $55,000 - $187,000. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. All hired individuals are eligible for an annual discretionary bonus. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",
    "job_is_remote": false,
    "job_posted_at": "13 days ago",
    "job_posted_at_timestamp": 1770076800,
    "job_posted_at_datetime_utc": "2026-02-03T00:00:00.000Z",
    "job_location": "Washington, DC",
    "job_city": "Washington",
    "job_state": "District of Columbia",
    "job_country": "US",
    "job_latitude": 38.9072873,
    "job_longitude": -77.0369274,
    "job_benefits": [
      "health_insurance",
      "dental_coverage",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DxIy-w4lp_7eHIBzJAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's Degree in Computer Science, Data Processing/Analytics/Science, Artificial Intelligence and Robotics",
        "3 years of professional experience developing AI/ML systems or integrating AI into products",
        "Possessing advanced proficiency in prompt engineering",
        "Demonstrating experience deploying LLMs into production",
        "Designing and optimizing RAG pipelines",
        "Leading technical discovery in fast-paced environments",
        "Collaborating effectively with cross-functional leaders",
        "Advocating for responsible AI principles",
        "Contributing to AI research or open-source communities",
        "Demonstrating knowledge of orchestration tools such as LangChain, LlamaIndex, and experience with agent-based systems"
      ],
      "Benefits": [
        "The salary range for this position is: $55,000 - $151,470",
        "For residents of Washington state the salary range for this position is: $55,000 - $187,000",
        "All hired individuals are eligible for an annual discretionary bonus",
        "PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more"
      ],
      "Responsibilities": [
        "They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth",
        "Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making",
        "You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems",
        "Focused on relationships, you are building meaningful client connections, and learning how to manage and inspire others",
        "Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths",
        "You are expected to anticipate the needs of your teams and clients, and to deliver quality",
        "Respond effectively to the diverse perspectives, needs, and feelings of others",
        "Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems",
        "Use critical thinking to break down complex concepts",
        "Understand the broader objectives of your project or role and how your work fits into the overall strategy",
        "Develop a deeper understanding of the business context and how it is changing",
        "Use reflection to develop self awareness, enhance strengths and address development areas",
        "Interpret data to inform insights and recommendations",
        "Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements",
        "As part of the Data and Analytics Engineering team you will develop and implement AI solutions that enhance product offerings",
        "As a Senior Associate, you will analyze complex problems, mentor junior team members, and maintain elevated professional standards while building meaningful client relationships",
        "Build and nurture meaningful relationships with clients",
        "Utilize advanced analytical techniques to drive innovation",
        "Work with cross-functional teams to achieve project goals",
        "Uphold the firm's ethical standards and recommended practices"
      ]
    },
    "job_onet_soc": "15111100",
    "job_onet_job_zone": "5",
    "id": "jobs-us-pwc-com-job-new-york-ctio-ai-engineer-sr-associate-932-91339725632",
    "_source": "new_jobs"
  }
]