[
  {
    "job_id": "T9iATWXFpDt6gkCWAAAAAA==",
    "job_title": "Data Analytics Engineer Level 3/4",
    "employer_name": "Northrop Grumman",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT0guZ8n1kKZ_nu4eaicJ4PROiwjA-BfwwxOY7w&s=0",
    "employer_website": "https://www.northropgrumman.com",
    "job_publisher": "Jobs At Northrop Grumman",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://jobs.northropgrumman.com/careers/job/1340069874797-data-analytics-engineer-level-3-4-united-states-california-sunnyvale?domain=ngc.com&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Jobs At Northrop Grumman",
        "apply_link": "https://jobs.northropgrumman.com/careers/job/1340069874797-data-analytics-engineer-level-3-4-united-states-california-sunnyvale?domain=ngc.com&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobs | Northrop Grumman",
        "apply_link": "https://northropgrumman.jobs/sunnyvale-ca/data-analytics-engineer-level-34/A65F6AF4F8A94823B83D6AB088A30371/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=9a28c7a6de84fae3&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "JSfirm.com",
        "apply_link": "https://www.jsfirm.com/Engineering/Data+Analytics+Engineer+Level+3/4/Sunnyvale-California/jobID_1850672?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Northrop-Grumman/Job/Data-Analytics-Engineer-Level-5/-in-Sunnyvale,CA?jid=9675d9d66bab3f26&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Hire Heroes USA Job Board",
        "apply_link": "https://jobs.hireheroesusa.org/jobs/497361476-data-analytics-engineer-level-3-4-at-northrop-grumman?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LocalJobs.com",
        "apply_link": "https://www.localjobs.com/job/sunnyvale-ca-data-analytics-engineer-level-3-4?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Build Submarines",
        "apply_link": "https://jobs.buildsubmarines.com/jobs/497290697-data-analytics-engineer-level-3-4-at-northrop-grumman?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "RELOCATION ASSISTANCE: Relocation assistance may be available\n\nCLEARANCE TYPE: Secret\n\nTRAVEL: Yes, 10% of the Time\n\nDescription\n\nAt Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.\n\nNorthrop Grumman Mission Systems is a trusted provider of mission-enabling solutions for global security. Our Engineering and Sciences (E&S) organization pushes the boundaries of innovation, redefines engineering capabilities, and drives advances in various sciences. Our team is chartered with providing the skills, innovative technologies to develop, design, produce and sustain optimized product lines across the sector while providing a decisive advantage to the warfighter. Come be a part of our mission!\n\nNorthrop Grumman Mission Systems is seeking a Data Analytics Engineer Level 3 or 4 to support the development and ongoing support of world-class US Navy machinery (turbines, generators, motors, and other system components based out of Sunnyvale, CA. In this role, you will leverage data to drive decision-making within engineering, and production processes. Your work will involve analyzing complex data sets, developing insights to improve manufacturing efficiency and quality, and collaborating with cross-functional teams to enhance production and design capabilities. If you are passionate about using data to improve manufacturing processes and enhance engineering outcomes, join our team and contribute to critical national defense projects.\n\nWhat You’ll get to Do:\n• Use classical analysis techniques to establish an understanding of machinery acoustic performance and resolve issues.\n• Develop a variety of component and system level predictive / simulation models.\n• Perform modal, vibration, modal, direct frequency response, and sound transmission analyses to predict performance and resolve issues.\n• Gather data from tests, and analyze the results.\n• Correlate model predictions to test data to validate the approach / model.\n• Work closely with cross-function internal and customer teams.\n• Prepare technical reports and presentations summarizing findings and recommendations for internal and external stakeholders.\n\nBasic Qualifications for Data Analytics Engineer level 3:\n• Bachelor's Degree in STEM (Science, Technology, Engineering or Math) discipline with 5 years relevant work experience; or Master’s Degree in STEM (Science, Technology, Engineering or Math) with 3 years of relevant experience; or Ph.D in STEM (Science, Technology, Engineering or Math) with no relevant work experience.\n• Experience with simulation software tools: Hypermesh, Nastran, Abaqus, MATLAB (or similar)\n• Must be a US citizen.\n• Ability to obtain and maintain a Secret Clearance.\n\nBasic Qualifications for Data Analytics Engineer level 4:\n• Bachelor’s Degree in STEM (Science, Technology, Engineering or Math) discipline with 8 years relevant work experience; or Master’s Degree in STEM (Science, Technology, Engineering or Math) discipline with 6 years relevant work experience; or Ph.D in STEM (Science, Technology, Engineering or Math) with 3 years of relevant work experience.\n• Experience with simulation software tools: Hypermesh, Nastran, Abaqus, MATLAB (or similar)\n• Must be a US citizen.\n• Ability to obtain and maintain a Secret Clearance.\n\nPreferred Qualifications:\n• Experience in developing system-level finite element models.\n• Experience in performing a classical and finite element analysis solution types.\n• Experience collecting and analyzing large data sets.\n\nPrimary Level Salary Range: $114,000.00 - $171,000.00\n\nSecondary Level Salary Range: $142,200.00 - $213,400.00\n\nThe above salary range represents a general guideline; however, Northrop Grumman considers a number of factors when determining base salary offers such as the scope and responsibilities of the position and the candidate's experience, education, skills and current market conditions.\n\nDepending on the position, employees may be eligible for overtime, shift differential, and a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.\n\nThe application period for the job is estimated to be 20 days from the job posting date. However, this timeline may be shortened or extended depending on business needs and the availability of qualified candidates.\n\nNorthrop Grumman is an Equal Opportunity Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO and pay transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for all positions with a government clearance and certain other restricted positions.",
    "job_is_remote": false,
    "job_posted_at": "11 days ago",
    "job_posted_at_timestamp": 1770336000,
    "job_posted_at_datetime_utc": "2026-02-06T00:00:00.000Z",
    "job_location": "Sunnyvale, CA",
    "job_city": "Sunnyvale",
    "job_state": "California",
    "job_country": "US",
    "job_latitude": 37.368829999999996,
    "job_longitude": -122.0363496,
    "job_benefits": [
      "health_insurance",
      "dental_coverage",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DT9iATWXFpDt6gkCWAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's Degree in STEM (Science, Technology, Engineering or Math) discipline with 5 years relevant work experience; or Master’s Degree in STEM (Science, Technology, Engineering or Math) with 3 years of relevant experience; or Ph.D in STEM (Science, Technology, Engineering or Math) with no relevant work experience",
        "Experience with simulation software tools: Hypermesh, Nastran, Abaqus, MATLAB (or similar)",
        "Must be a US citizen",
        "Ability to obtain and maintain a Secret Clearance",
        "Bachelor’s Degree in STEM (Science, Technology, Engineering or Math) discipline with 8 years relevant work experience; or Master’s Degree in STEM (Science, Technology, Engineering or Math) discipline with 6 years relevant work experience; or Ph.D in STEM (Science, Technology, Engineering or Math) with 3 years of relevant work experience",
        "Experience with simulation software tools: Hypermesh, Nastran, Abaqus, MATLAB (or similar)",
        "Must be a US citizen",
        "Ability to obtain and maintain a Secret Clearance"
      ],
      "Benefits": [
        "Primary Level Salary Range: $114,000.00 - $171,000.00",
        "Secondary Level Salary Range: $142,200.00 - $213,400.00",
        "The above salary range represents a general guideline; however, Northrop Grumman considers a number of factors when determining base salary offers such as the scope and responsibilities of the position and the candidate's experience, education, skills and current market conditions",
        "Depending on the position, employees may be eligible for overtime, shift differential, and a discretionary bonus in addition to base pay",
        "Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results",
        "Employees in Vice President or Director positions may be eligible for Long Term Incentives",
        "In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business"
      ],
      "Responsibilities": [
        "TRAVEL: Yes, 10% of the Time",
        "In this role, you will leverage data to drive decision-making within engineering, and production processes",
        "Your work will involve analyzing complex data sets, developing insights to improve manufacturing efficiency and quality, and collaborating with cross-functional teams to enhance production and design capabilities",
        "If you are passionate about using data to improve manufacturing processes and enhance engineering outcomes, join our team and contribute to critical national defense projects",
        "Use classical analysis techniques to establish an understanding of machinery acoustic performance and resolve issues",
        "Develop a variety of component and system level predictive / simulation models",
        "Perform modal, vibration, modal, direct frequency response, and sound transmission analyses to predict performance and resolve issues",
        "Gather data from tests, and analyze the results",
        "Correlate model predictions to test data to validate the approach / model",
        "Work closely with cross-function internal and customer teams",
        "Prepare technical reports and presentations summarizing findings and recommendations for internal and external stakeholders"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "jobs-northropgrumman-com-careers-job-1340069874797-data-analytics-engineer-level-3-4-united-states-california-sunnyvale",
    "_source": "new_jobs"
  },
  {
    "job_id": "VtUm40K6nxadOu5rAAAAAA==",
    "job_title": "Analytic Data Engineer",
    "employer_name": "CVS Health",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQudUQ7bAJjtUW_FO_Jjs6PIFXc_7l7lfcD4fbb&s=0",
    "employer_website": "https://www.cvshealth.com",
    "job_publisher": "National Society Of Black Engineers - NSBE",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.nsbe.org/job/analytic-data-engineer/82482430/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "National Society Of Black Engineers - NSBE",
        "apply_link": "https://careers.nsbe.org/job/analytic-data-engineer/82482430/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/neurgoSDnK6c7VwuAq7-SEqW1cJsf6di4c7bACSYU50Ym-QZwxz4Ww?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "WhatJobs",
        "apply_link": "https://www.whatjobs.com/jobs/analytic-data-engineer?id=2449626286&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "We're building a world of health around every individual - shaping a more connected, convenient and compassionate health experience. At CVS Health®, you'll be surrounded by passionate colleagues who care deeply, innovate with purpose, hold ourselves accountable and prioritize safety and quality in everything we do. Join us and be part of something bigger - helping to simplify health care one person, one family and one community at a time.\n\nPosition Summary\n\nWe're seeking a Data Engineer to design and implement data pipelines that power analytical capabilities. This hands-on role requires an understanding of data engineering best practices and the ability to translate business requirements into technical solutions.\n\nYou will be part of a dedicated team creating datasets for analytic and data science workloads. You will work with other Data Engineers and Sr. Data Engineers on designing, implementing, and testing data pipelines. Your key responsibilities are:\n• Data Pipeline Development: Design and build ETL/ELT data pipelines to ingest, process, and transform datasets from multiple sources.\n• Performance Optimization: Implement best practices for performance tuning, partitioning, and clustering to optimize data queries.\n• Data Quality & Governance: follow data quality standards, data governance frameworks, and security policies for data storage and access.\n• Data Modeling & Architecture: Develop and optimize data models and schemas to support analytics, reporting, and machine learning requirements.\n• Data Integration & Transformation: Collaborate with data scientists and analysts to design data solutions that integrate with BI tools and machine learning models\n• Documentation & Knowledge Sharing: Create comprehensive documentation for data pipelines, workflows, and processes.\n\nRequired Qualifications\n• 2+ years of applicable work experience\n• Proficiency in Python, specifically with ETL pipelines\n• Strong proficiency in SQL and experience in developing complex queries\n• Experience deploying data pipelines in a cloud environment (any of Azure, AWS, GCP)\n• Excellent communication and interpersonal skills, with the ability to collaborate effectively with data scientists and analysts.\n\nPreferred Qualifications\n• Experience working with healthcare data, especially Epic.\n• Experience using GCP's BigQuery\n• Knowledge of data governance best practices in a cloud environment.\n• Experience working with Machine Learning processes.\n\nEducation\nCollege degree or certification in related fields\n\nAnticipated Weekly Hours\n40\n\nTime Type\nFull time\n\nPay Range\n\nThe typical pay range for this role is:\n\n$64,890.00 - $173,040.00\n\nThis pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.\n\nOur people fuel our future. Our teams reflect the customers, patients, members and communities we serve and we are committed to fostering a workplace where every colleague feels valued and that they belong.\n\nGreat benefits for great people\n\nWe take pride in our comprehensive and competitive mix of pay and benefits - investing in the physical, emotional and financial wellness of our colleagues and their families to help them be the healthiest they can be. In addition to our competitive wages, our great benefits include:\n• Affordable medical plan options, a 401(k) plan (including matching company contributions), and an employee stock purchase plan.\n• No-cost programs for all colleagues including wellness screenings, tobacco cessation and weight management programs, confidential counseling and financial coaching.\n• Benefit solutions that address the different needs and preferences of our colleagues including paid time off, flexible work schedules, family leave, dependent care resources, colleague assistance programs, tuition assistance, retiree medical access and many other benefits depending on eligibility.\n\nFor more information, visit https://jobs.cvshealth.com/us/en/benefits\n\nWe anticipate the application window for this opening will close on: 02/20/2026\n\nQualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state and local laws.",
    "job_is_remote": false,
    "job_posted_at": "3 days ago",
    "job_posted_at_timestamp": 1771027200,
    "job_posted_at_datetime_utc": "2026-02-14T00:00:00.000Z",
    "job_location": "Minnesota",
    "job_city": null,
    "job_state": "Minnesota",
    "job_country": "US",
    "job_latitude": 46.729552999999996,
    "job_longitude": -94.6858998,
    "job_benefits": [
      "paid_time_off",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DVtUm40K6nxadOu5rAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "This hands-on role requires an understanding of data engineering best practices and the ability to translate business requirements into technical solutions",
        "2+ years of applicable work experience",
        "Proficiency in Python, specifically with ETL pipelines",
        "Strong proficiency in SQL and experience in developing complex queries",
        "Experience deploying data pipelines in a cloud environment (any of Azure, AWS, GCP)",
        "Excellent communication and interpersonal skills, with the ability to collaborate effectively with data scientists and analysts",
        "College degree or certification in related fields"
      ],
      "Benefits": [
        "Pay Range",
        "$64,890.00 - $173,040.00",
        "This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls",
        "The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors",
        "This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above",
        "We take pride in our comprehensive and competitive mix of pay and benefits - investing in the physical, emotional and financial wellness of our colleagues and their families to help them be the healthiest they can be",
        "In addition to our competitive wages, our great benefits include:",
        "Affordable medical plan options, a 401(k) plan (including matching company contributions), and an employee stock purchase plan",
        "No-cost programs for all colleagues including wellness screenings, tobacco cessation and weight management programs, confidential counseling and financial coaching",
        "Benefit solutions that address the different needs and preferences of our colleagues including paid time off, flexible work schedules, family leave, dependent care resources, colleague assistance programs, tuition assistance, retiree medical access and many other benefits depending on eligibility"
      ],
      "Responsibilities": [
        "We're seeking a Data Engineer to design and implement data pipelines that power analytical capabilities",
        "You will be part of a dedicated team creating datasets for analytic and data science workloads",
        "You will work with other Data Engineers and Sr",
        "Data Engineers on designing, implementing, and testing data pipelines",
        "Data Pipeline Development: Design and build ETL/ELT data pipelines to ingest, process, and transform datasets from multiple sources",
        "Performance Optimization: Implement best practices for performance tuning, partitioning, and clustering to optimize data queries",
        "Data Quality & Governance: follow data quality standards, data governance frameworks, and security policies for data storage and access",
        "Data Modeling & Architecture: Develop and optimize data models and schemas to support analytics, reporting, and machine learning requirements",
        "Data Integration & Transformation: Collaborate with data scientists and analysts to design data solutions that integrate with BI tools and machine learning models",
        "Documentation & Knowledge Sharing: Create comprehensive documentation for data pipelines, workflows, and processes"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "careers-nsbe-org-job-analytic-data-engineer-82482430",
    "_source": "new_jobs"
  },
  {
    "job_id": "C-jX8U0HtfP_C52zAAAAAA==",
    "job_title": "Senior Data & Analytics Platform Engineer (ETL & OLAP Focus)",
    "employer_name": "Netbuilder",
    "employer_logo": null,
    "employer_website": "https://www.netbuilder.com",
    "job_publisher": "WhatJobs",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.whatjobs.com/jobs/analytics-engineer?id=2459734245&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "WhatJobs",
        "apply_link": "https://www.whatjobs.com/jobs/analytics-engineer?id=2459734245&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Candidates ideally reside near Plano, TX or Long Island, NY , though remote applicants within the U.S. are welcome if they can work Central Time Zone hours . This is a full-time position anticipated to run for at least 12 months , with potential to continue beyond. Role Summary\n\nThe Senior Data & Analytics Platform Engineer is responsible for the design, implementation, and operation of the enterprise data ingestion and analytical platforms. This role provides hands-on technical leadership across ETL and OLAP capabilities, ensuring reliable data pipelines, performant analytical models, and high-quality datasets that power reporting, dashboards, and downstream AI and observability use cases.\n\nThe role combines solution design, implementation, and team leadership, guiding junior ETL and OLAP engineers while remaining deeply involved in delivery.\nKey Responsibilities Design end-to-end data ingestion and analytics architectures covering batch, streaming, and near-real-time pipelines Define OLAP data models, semantic layers, aggregation strategies, and query optimization patterns Establish integration patterns between ETL pipelines and analytical/observability platforms Ensure scalability, performance, cost efficiency, and data quality across the analytics stack Strong Business Analysis skills (gathering project requirements) Project planning abilities Hands-on Engineering Build and review complex ETL pipelines and analytical data models Lead development of reusable transformation logic, data quality frameworks, and monitoring Troubleshoot performance bottlenecks, data inconsistencies, and pipeline failures Contribute production-grade code, configurations, and documentation Provide technical guidance and mentorship to ETL and OLAP junior engineers Conduct code reviews, design reviews, and technical walkthroughs Break down designs into executable tasks and guide implementation sequencing Raise engineering standards and consistency across the data team Delivery & Stakeholder Ownership Own delivery outcomes for data ingestion and analytics workstreams Collaborate with Observability and AI Ops counterparts on shared data needs Communicate progress, risks, and trade-offs to customer stakeholders Support operational handover, runbooks, and ongoing platform evolution Required Qualifications 5+ years of experience in data engineering or analytics platforms Strong hands-on experience with ETL/ELT pipelines and OLAP systems Deep expertise in SQL, data modeling, and analytical query optimization Experience operating production data platforms with SLAs Strong business analysis and project planning abilities, including translating business requirements into technical solutions and executable delivery plans Preferred Qualifications Experience with time-series or operational data Exposure to observability-driven analytics or AI feature pipelines About NETbuilder\n\nFounded 26 years ago, NETbuilder is a trusted partner to leading global software vendors, delivering enterprise-scale technology and cybersecurity solutions. We are known for our reliability, expertise, and strategic insight, helping clients strengthen resilience, improve visibility, and drive operational excellence.\n\nAs we continue to grow, 2026 marks the start of an ambitious new phase focused on scaling our capabilities, deepening strategic partnerships, and delivering high-impact enterprise solutions. Our collaborative culture empowers experienced professionals to shape strategy and make a lasting impact.\n\nNETbuilder is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n#J-18808-Ljbffr",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770768000,
    "job_posted_at_datetime_utc": "2026-02-11T00:00:00.000Z",
    "job_location": "Fairview, TX",
    "job_city": "Fairview",
    "job_state": "Texas",
    "job_country": "US",
    "job_latitude": 33.1578952,
    "job_longitude": -96.6316593,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DC-jX8U0HtfP_C52zAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {},
    "job_onet_soc": "15113300",
    "job_onet_job_zone": "4",
    "id": "www-whatjobs-com-jobs-analytics-engineer",
    "_source": "new_jobs"
  },
  {
    "job_id": "zfD8D0M8uxVfRNpfAAAAAA==",
    "job_title": "Analytics Engineer",
    "employer_name": "Hearst",
    "employer_logo": null,
    "employer_website": "https://www.hearst.com",
    "job_publisher": "Sign In",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://eevd.fa.us6.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/requisitions/preview/2026058?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Sign In",
        "apply_link": "https://eevd.fa.us6.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/requisitions/preview/2026058?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Hearst/Job/Analytics-Engineer/-in-Charlotte,NC?jid=c7558868074bbdef&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Career.io",
        "apply_link": "https://career.io/job/analytics-engineer-charlotte-hearst-communications-b17bfbb0a880de508a0d7afa6d4c3e88?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/analytics-engineer-at-hearst-television-charlotte-4364464181?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/f8d07f12457608b4310958373c78053f?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/analytics-engineer_7ea1ad5d85d0b8433e7b78b8b3e3cb87e37fc?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Broadcast Career Link",
        "apply_link": "https://jobs.broadcastcareerlink.com/job/analytics-engineer/82498609/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Experteer",
        "apply_link": "https://us.experteer.com/career/view-jobs/analytics-engineer-charlotte-nc-usa-56181061?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Hearst Television (HTV) is hiring an Analytics Engineer. The ideal candidate will act as the vital bridge between raw data and executive insights. You will take \"Bronze\" data and transform it into high-value Silver (Cleansed) and Gold (Aggregated) layers. Your primary goal is to codify complex media sales logic such as Revenue Pacing, Share of Wallet, and Yield into high-performance Semantic Models that power our Power BI dashboards and AI Data Agents. This role ensures our data is not just accessible, but actionable and intelligent.\n\nWhat You’ll Do\n\n· Medallion Transformation: Use Spark and SQL to architect the Silver and Gold layers of our Lakehouse, ensuring all data is rigorously tested, clean, and documented.\n\n· Semantic Modeling: Design and maintain the Microsoft Fabric Semantic Model (Direct Lake mode) to provide a \"Single Source of Truth\" across the entire organization.\n\n· Business Logic Codification: Partner closely with Sales and Finance stakeholders to translate \"What\" and \"Why\" business questions into precise technical data definitions.\n\n· AI Data Readiness: Structure data specifically for LLM consumption, enabling our AI Data Agents to accurately navigate complex hierarchies of stations, advertisers, and categories.\n\n· Data Governance & Security: Implement Row-Level Security (RLS) and maintain data lineage to ensure compliance with Hearst’s unified data strategy.\n\n· Technical Leadership: Lead the design of project-specific data models, prepare design specifications, and conduct feature estimations in collaboration with cross-functional teams.\n\n· Optimization & RCA: Perform root cause analysis on anomalies and implement solutions to minimize points of failure and optimize data pipeline performance.\n\nRequirements\n\n· Experience: 7+ years in business analytics, data modeling, or data engineering (or a Master’s degree with 5+ years of experience).\n\n· Modeling Expertise: 5+ years of deep experience with relational modeling concepts and Microsoft tabular semantic models.\n\n· Technical Proficiency: Expert-level SQL skills and 5+ years of experience with Power BI, DAX, and Spark (Spark SQL/PySpark/Scala).\n\n· Platform Knowledge: Strong hands-on experience with Microsoft Fabric tools and the Delta Lake format.\n\n· Logic & Design: Demonstrated experience translating complex business requirements into technical requirements using Star Schema/Dimensional modeling.\n\n· DevOps: Familiarity with Git, CI/CD, and modern development workflows.\n\n· Communication: Proven ability to collaborate with stakeholders and escalate data requirements or constraints effectively.\n\nPreferred Qualifications\n\n· Familiarity with governance, security best practices, and performance tuning in a cloud environment.\n\n· Experience in the media or broadcasting industry is a plus.\n\n· Knowledge of serverless architectures and containerized deployment.\n\nValues in Action\n\nAt Hearst Television we tell stories every day. Stories about people of all backgrounds, perspectives, and identities. That’s why, behind the scenes, we believe in being an organization that fosters collaboration and open communication, ensuring that the content we create is authentic, accurate, and connected to the communities we serve.\n\nBenefits\n\nHearst's benefit programs are modern, flexible and designed to focus on you. As a Hearst employee, you and your spouse or partner or dependents would have access to the following benefits:\n\n· Medical | Dental | Vision\n\n· 401(k) matching\n\n· Emotional Wellness Support\n\n· Paid Time Off & Parental Leave\n\n· LGBTQ+ Health Services",
    "job_is_remote": false,
    "job_posted_at": "4 days ago",
    "job_posted_at_timestamp": 1770940800,
    "job_posted_at_datetime_utc": "2026-02-13T00:00:00.000Z",
    "job_location": "Charlotte, NC",
    "job_city": "Charlotte",
    "job_state": "North Carolina",
    "job_country": "US",
    "job_latitude": 35.2270768,
    "job_longitude": -80.84089329999999,
    "job_benefits": [
      "health_insurance",
      "paid_time_off",
      "dental_coverage"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DzfD8D0M8uxVfRNpfAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Experience: 7+ years in business analytics, data modeling, or data engineering (or a Master’s degree with 5+ years of experience)",
        "Modeling Expertise: 5+ years of deep experience with relational modeling concepts and Microsoft tabular semantic models",
        "Technical Proficiency: Expert-level SQL skills and 5+ years of experience with Power BI, DAX, and Spark (Spark SQL/PySpark/Scala)",
        "Platform Knowledge: Strong hands-on experience with Microsoft Fabric tools and the Delta Lake format",
        "Logic & Design: Demonstrated experience translating complex business requirements into technical requirements using Star Schema/Dimensional modeling",
        "DevOps: Familiarity with Git, CI/CD, and modern development workflows",
        "Communication: Proven ability to collaborate with stakeholders and escalate data requirements or constraints effectively"
      ],
      "Benefits": [
        "Hearst's benefit programs are modern, flexible and designed to focus on you",
        "Medical | Dental | Vision",
        "401(k) matching",
        "Emotional Wellness Support",
        "Paid Time Off & Parental Leave",
        "LGBTQ+ Health Services"
      ],
      "Responsibilities": [
        "The ideal candidate will act as the vital bridge between raw data and executive insights",
        "You will take \"Bronze\" data and transform it into high-value Silver (Cleansed) and Gold (Aggregated) layers",
        "Your primary goal is to codify complex media sales logic such as Revenue Pacing, Share of Wallet, and Yield into high-performance Semantic Models that power our Power BI dashboards and AI Data Agents",
        "Medallion Transformation: Use Spark and SQL to architect the Silver and Gold layers of our Lakehouse, ensuring all data is rigorously tested, clean, and documented",
        "Semantic Modeling: Design and maintain the Microsoft Fabric Semantic Model (Direct Lake mode) to provide a \"Single Source of Truth\" across the entire organization",
        "Business Logic Codification: Partner closely with Sales and Finance stakeholders to translate \"What\" and \"Why\" business questions into precise technical data definitions",
        "AI Data Readiness: Structure data specifically for LLM consumption, enabling our AI Data Agents to accurately navigate complex hierarchies of stations, advertisers, and categories",
        "Data Governance & Security: Implement Row-Level Security (RLS) and maintain data lineage to ensure compliance with Hearst’s unified data strategy",
        "Technical Leadership: Lead the design of project-specific data models, prepare design specifications, and conduct feature estimations in collaboration with cross-functional teams",
        "Optimization & RCA: Perform root cause analysis on anomalies and implement solutions to minimize points of failure and optimize data pipeline performance"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "eevd-fa-us6-oraclecloud-com-hcmui-candidateexperience-en-sites-cx_1-requisitions-preview-2026058",
    "_source": "new_jobs"
  },
  {
    "job_id": "tYKJ_R_W-BuLd6exAAAAAA==",
    "job_title": "Digital – Manager, Data and Analytics Engineer",
    "employer_name": "140 Pfizer Inc",
    "employer_logo": null,
    "employer_website": null,
    "job_publisher": "Workday",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://pfizer.wd1.myworkdayjobs.com/en-US/PfizerCareers/job/Manager---HR---Corporate-Functions-Data---Analytics-Engineering_4939096-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Workday",
        "apply_link": "https://pfizer.wd1.myworkdayjobs.com/en-US/PfizerCareers/job/Manager---HR---Corporate-Functions-Data---Analytics-Engineering_4939096-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=1ed9c59354463a7a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/digital-manager-data-and-analytics-engineer-pfizer-JV_IC1154429_KO0,43_KE44,50.htm?jl=1009944999383&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Xtalks",
        "apply_link": "https://xtalks.com/job/digital-manager-data-and-analytics-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/3XGeL-WXgBE-FTdj_osHbQ6EYiGJAyBKM4Z-3WaPWjRpllde0xE8PA?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/621f15d6bda660c2123665511b18f9a7?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/digital-%E2%80%93-manager-data-and-analytics-engineer-at-pfizer-4369276254?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "FactoryFix",
        "apply_link": "https://jobs.factoryfix.com/jobs/digital-manager-data-and-analytics-engineer--tampa--fl--4254991986--V2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Use Your Power for Purpose At Pfizer, our purpose—Breakthroughs that change patients’ lives—drives every decision we make. Digital & Technology accelerates this mission by turning data into insights that power smarter science, stronger operations, and an exceptional colleague experience. Within this organization, the Enabling Functions Creation Center (EFCC) supports HR, Finance, Global Business Services, and Legal with the digital capabilities they need to operate effectively and unlock value. As a hands‑on Manager - Data & Analytics Engineer, you will lead and build innovative data solutions that strengthen our enterprise data foundation, empower our enabling function partners, and help unleash the power of our people—ultimately supporting the breakthroughs that matter most to patients. What You Will Achieve As a hands-on engineer, you will build scalable data pipelines to provide accurate and impactful business analytics and insights Design and implementation of data architecture and infrastructure. Lead the development of data management strategies and policies. Manage a team of project data engineers and analysts, providing guidance and mentorship. Ensure data quality and integrity across all data platforms. Collaborate with cross-functional teams to align data initiatives with business goals. Develop and maintain data governance frameworks. Oversee the integration of new data technologies and tools. Ensure compliance with data privacy regulations and standards. Drive the optimization of data processing workflows and pipelines. Lead the development of analytics solutions to support business decision-making. Manage relationships with external data vendors and partners. Oversee the creation and maintenance of data documentation and metadata. Develop and monitor key performance indicators for data initiatives. Ensure the scalability and performance of data systems. Basic Qualifications: Candidates should possess a BA/BS with at least 4 years of experience, an MBA/MS with at least 2 years of experience, a PhD/JD with any years of experience, an associate's degree with at least 8 years of experience, or a high school diploma (or equivalent) with at least 10 years of relevant experience. Data Architecture Design: Designing and structuring modern databases and modern data systems: Expert Data Warehousing: Building and managing data warehouses (Preferably Snowflake): Expert SQL: Advanced querying and database management: Expert Data pipelines / ETL Processes: Designing and managing modern ETL (Extract, Transform, Load) processes and data engineering pipelines: Expert Data Integration: Combining and transforming data from different sources: Expert Cloud Platforms (e.g., AWS, Azure, Google Cloud): Managing data infrastructure on cloud platforms: Advanced Big Data Technologies (e.g., SnowFlake, Data Bricks, Spark): Handling and processing large datasets: Advanced Data Modeling: Creating data models to support analytics: Advanced Visual Analytics and Business Intelligence Tools: Using BI tools to derive insights from data: Advanced Data Governance: Implementing policies and procedures for data management: Advanced Data Visualization Tools (e.g., Tableau, Power BI): Creating visual representations of data and data story telling: Advanced Programming Languages (e.g., Python, R): Writing code for data manipulation and analysis: Expert Data Security: Implementing security measures to protect data: Intermediate Data Quality Management: Ensuring accuracy and consistency of data: Advanced Statistical Analysis: Applying statistical methods to analyze data: Intermediate Leadership: Guiding and motivating a team to achieve goals: Expert Strategic Thinking: Planning and executing long-term data strategies: Expert Communication: Clearly conveying complex data concepts to stakeholders: Advanced Problem Solving: Identifying and resolving data-related issues: Advanced Collaboration: Working effectively with cross-functional teams: Advanced Hands on experience with vibe coding and Generative AI based data pipeline and analytics solutions development to increase efficiency, reduce overall delivery cost and reduce time to market. Emerging skills Machine Learning: Applying machine learning techniques for data analysis: Intermediate Adaptability: Adjusting to new technologies and methodologies: Intermediate Critical Thinking: Analyzing data critically to derive insights: Advanced Time Management: Prioritizing tasks to meet deadlines: Advanced Decision Making: Making informed decisions based on data insights: Advanced Preferred Qualifications: People Analytics experience using SaaS tools such as Visier, One Model, Perceptyx, Workday Prism Analytics, Workday People Analytics, SAP Success Factors Workforce Analytics is a big plus. Familiarity with cloud/SaaS-based Human Capital Management (HCM) systems such as Workday is a big plus. Experience with Global HR data integration and prior experience with Mergers, Acquisitions, and Divestitures is a plus. Familiarity with EU Global Data Privacy Regulations (GDPR) and other related international regulations is nice to have. Prior experience with data architecture designs and data engineering development related to the GDPR and data privacy guiding principles such as data minimization, right to be forgotten, etc is nice to have. · Experience with Global HR data integration and prior experience with Mergers, Acquisitions, and Divestitures is a plus. Experience with Software engineering best practices, including but not limited to version control (Git/GitHub, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops is highly beneficial but not required. Experience with sourcing and modeling data from application APIs and publishing data and analytics services via APIs / Data Services is highly beneficial but not required · Experience deploying through an agile methodology and working in a SCRUM or SAFe team is highly beneficial but not required. 5 or more years of experience with one or more general-purpose data processing programming languages, including but not limited to: SQL, Scala, Python, Java, etc Architected end-to-end data pipelines with a major cloud stack is a plus · Experience in Cloud computing, machine learning, text analysis, NLP, and developing and deploying data and analytics services such as recommendation engines experience is a plus Domain experience in the Human Resources field Work Location Assignment: Hybrid The annual base salary for this position ranges from $99,200.00 to $160,500.00. In addition, this position is eligible for participation in Pfizer’s Global Performance Plan with a bonus target of 12.5% of the base salary and eligibility to participate in our share based long term incentive program. We offer comprehensive and generous benefits and programs to help our colleagues lead healthy lives and to support each of life’s moments. Benefits offered include a 401(k) plan with Pfizer Matching Contributions and an additional Pfizer Retirement Savings Contribution, paid vacation, holiday and personal days, paid caregiver/parental and medical leave, and health benefits to include medical, prescription drug, dental and vision coverage. Learn more at Pfizer Candidate Site – U.S. Benefits | (uscandidates.mypfizerbenefits.com). Pfizer compensation structures and benefit packages are aligned based on the location of hire. The United States salary range provided applies to the Tampa, FL location only. The salary range provided does not apply to any other United States location or locations outside of the United States. Relocation assistance may be available based on business needs and/or eligibility. Sunshine Act Pfizer reports payments and other transfers of value to health care providers as required by federal and state transparency laws and implementing regulations. These laws and regulations require Pfizer to provide government agencies with information such as a health care provider’s name, address and the type of payments or other value received, generally for public disclosure. Subject to further legal review and statutory or regulatory clarification, which Pfizer intends to pursue, reimbursement of recruiting expenses for licensed physicians may constitute a reportable transfer of value under the federal transparency law commonly known as the Sunshine Act. Therefore, if you are a licensed physician who incurs recruiting expenses as a result of interviewing with Pfizer that we pay or reimburse, your name, address and the amount of payments made currently will be reported to the government. If you have questions regarding this matter, please do not hesitate to contact your Talent Acquisition representative. EEO & Employment Eligibility Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. Pfizer also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as work authorization and employment eligibility verification requirements of the Immigration and Nationality Act and IRCA. Pfizer is an E-Verify employer. This position requires permanent work authorization in the United States. Pfizer endeavors to make www.pfizer.com/careers accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process and/or interviewing, please email disabilityrecruitment@pfizer.com. This is to be used solely for accommodation requests with respect to the accessibility of our website, online application process and/or interviewing. Requests for any other reason will not be returned. Information & Business Tech Pfizer careers are like no other. In our culture of individual ownership, we believe in our ability to improve future healthcare, and potential to transform millions of lives. We’re looking for new talent to join our global community, to unearth new innovative therapies that make the world a healthier place.",
    "job_is_remote": false,
    "job_posted_at": "13 days ago",
    "job_posted_at_timestamp": 1770163200,
    "job_posted_at_datetime_utc": "2026-02-04T00:00:00.000Z",
    "job_location": "Tampa, FL",
    "job_city": "Tampa",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 27.951689599999998,
    "job_longitude": -82.45875269999999,
    "job_benefits": [
      "paid_time_off",
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DtYKJ_R_W-BuLd6exAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {},
    "job_onet_soc": "11302100",
    "job_onet_job_zone": "4",
    "id": "pfizer-wd1-myworkdayjobs-com-en-us-pfizercareers-job-manager-hr-corporate-functions-data-analytics-engineering_4939096-2",
    "_source": "new_jobs"
  },
  {
    "job_id": "J3qD7yLhFTV7L6odAAAAAA==",
    "job_title": "Data Engineer",
    "employer_name": "Slalom",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTz83P7TkZM86wEdE65TUA9A-yqu267uumzStA3&s=0",
    "employer_website": "https://www.slalom.com",
    "job_publisher": "LinkedIn",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.linkedin.com/jobs/view/data-engineer-at-slalom-4369144916?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/data-engineer-at-slalom-4369144916?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "WhatJobs",
        "apply_link": "https://www.whatjobs.com/jobs/data-engineer?id=2439287257&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Web Hosting Services",
        "apply_link": "https://perris.id.au/.career/job/data-engineer-at-procore-technologies-oregon-T2VtelRkR25vSlpRc1c4b1hhMVIxdz09?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Role: Data Engineer\n\nWho You’ll Work With\n\nAt Slalom we co-create custom software, data and cloud products with clients who are ready to accelerate their digital transformation. We're passionate about technology, compelled by its potential as we help create the digital products, experiences, and technology-driven organizations that drive true change. We’re thrilled by the opportunity to build the future we want to see, with anyone willing to join us.\n\nSlalom's Data Engineering Discipline Is Focused On Injecting Intelligence Into Products, Engineering Systems That Support Learning And Insight And Creating Innovative Data Products. Within Data Engineering We Help Customers Build World-class Products Through Effective Use Of\n• Data engineering consisting of streaming / real-time data solutions, modern data platforms and data systems within products (i.e., database systems, graph databases, key-value stores, document databases and transactional systems)\n• Enhancing Machine Learning and Artificial Intelligence capabilities\n• You will work collaboratively with teams in a hybrid environment, with expectation to be in-person with Slalom team members and clients as needed.\n• You also must be within commutable distance to one of the listed Slalom office locations for this role.\n\nWhat You’ll Do\n\nSlalom Data Engineering discipline is comprised of passionate, flexible technologists who love to practice and hone their craft. As tools evolve and technologies emerge, we work to stay in front of innovations in data platform development and delivery.\n\nAs a Data Engineer for Slalom, you will work in collaborative teams to deliver innovative solutions on Amazon Web Services, Microsoft Azure, and Google Cloud Platform using core cloud data warehouse tools, distributed processing engines, event streaming platforms, and other modern data technologies. In addition to building the next generation of data platforms, you will be working with some of the most forward-thinking organizations in data and analytics.\n\nYou will be engaged to participate in design sessions and be responsible for the timely completion of development items assigned to you in a project backlog.\n\nWhat You’ll Bring\n\nYou will have an interest to become the best at what you do and will have many opportunities to gain hands-on experience with new data platforms and programming languages as you explore the range of technologies that we help our clients with including:\n• Big Data Platforms (Apache Spark, Presto, Amazon EMR)\n• Cloud Data Warehouses (Amazon Redshift, Snowflake, Google BigQuery)\n• Object Oriented Coding (Java, Python)\n• NoSQL Databases (DynamoDB, Cosmos DB, MongoDB)\n• Container Management Systems (Kubernetes, Amazon ECS)\n• Artificial Intelligence / Machine Learning (Amazon Sagemaker, Azure ML Studio)\n• Streaming Data Ingestion and Analytics (Amazon Kinesis, Apache Kafka)\n• Visual Analytics (Tableau, PowerBI)\n• Modern Data Workflows (Apache Airflow, dbt, Dagster)\n\nAbout Us\n\nSlalom is a fiercely human business and technology consulting company that leads with outcomes to bring more value, in all ways, always. From strategy through delivery, our agile teams across 52 offices in 12 countries collaborate with clients to bring powerful customer experiences, innovative ways of working, and new products and services to life. We are trusted by leaders across the Global 1000, many successful enterprise and mid-market companies, and 500+ public sector organizations to improve operations, drive growth, and create value. At Slalom, we believe that together, we can move faster, dream bigger, and build better tomorrows for all.\n\nCompensation And Benefits\n\nSlalom prides itself on helping team members thrive in their work and life. As a result, Slalom is proud to invest in benefits that include meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability. We also offer yearly $350 reimbursement account for any well-being-related expenses, as well as discounted home, auto, and pet insurance.\n\nSlalom is committed to fair and equitable compensation practices. For this role, we are hiring at the following levels and targeted base pay salary ranges outlined below. In addition, individuals may be eligible for an annual discretionary bonus. Actual compensation will depend upon an individual’s skills, experience, qualifications, location, and other relevant factors. The salary pay range is subject to change and may be modified at any time.\n• Denver, Portland\n• Consultant: $91,000 - $122,000\n• Seattle\n• Consultant: $99,000 - $133,000\n\nWe will accept applicants until April 5th, 2026, or until the position is filled.\n\nWe are committed to pay transparency and compliance with applicable laws. If you have questions or concerns about the pay range or other compensation information in this posting, please contact us at: peopleone@slalom.com.\n\nEEO and Accommodations\n\nSlalom is an equal opportunity employer and is committed to attracting, developing and retaining highly qualified talent who empower our innovative teams through unique perspectives and experiences. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veterans’ status, or any other characteristic protected by federal, state, or local laws. Slalom will also consider qualified applications with criminal histories, consistent with legal requirements. Slalom welcomes and encourages applications from individuals with disabilities. Reasonable accommodations are available for candidates during all aspects of the selection process. Please advise the talent acquisition team or contact accomodationrequest@slalom.com if you require accommodations during the interview process.",
    "job_is_remote": false,
    "job_posted_at": "12 days ago",
    "job_posted_at_timestamp": 1770249600,
    "job_posted_at_datetime_utc": "2026-02-05T00:00:00.000Z",
    "job_location": "Oregon City, OR",
    "job_city": "Oregon City",
    "job_state": "Oregon",
    "job_country": "US",
    "job_latitude": 45.3556099,
    "job_longitude": -122.605853,
    "job_benefits": [
      "health_insurance",
      "dental_coverage",
      "paid_time_off"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DJ3qD7yLhFTV7L6odAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Big Data Platforms (Apache Spark, Presto, Amazon EMR)",
        "NoSQL Databases (DynamoDB, Cosmos DB, MongoDB)",
        "Modern Data Workflows (Apache Airflow, dbt, Dagster)",
        "Slalom will also consider qualified applications with criminal histories, consistent with legal requirements"
      ],
      "Benefits": [
        "Compensation And Benefits",
        "Slalom prides itself on helping team members thrive in their work and life",
        "As a result, Slalom is proud to invest in benefits that include meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability",
        "We also offer yearly $350 reimbursement account for any well-being-related expenses, as well as discounted home, auto, and pet insurance",
        "Slalom is committed to fair and equitable compensation practices",
        "For this role, we are hiring at the following levels and targeted base pay salary ranges outlined below",
        "In addition, individuals may be eligible for an annual discretionary bonus",
        "Actual compensation will depend upon an individual’s skills, experience, qualifications, location, and other relevant factors",
        "The salary pay range is subject to change and may be modified at any time",
        "Consultant: $99,000 - $133,000"
      ],
      "Responsibilities": [
        "Data engineering consisting of streaming / real-time data solutions, modern data platforms and data systems within products (i.e., database systems, graph databases, key-value stores, document databases and transactional systems)",
        "Enhancing Machine Learning and Artificial Intelligence capabilities",
        "You will work collaboratively with teams in a hybrid environment, with expectation to be in-person with Slalom team members and clients as needed",
        "You also must be within commutable distance to one of the listed Slalom office locations for this role",
        "Slalom Data Engineering discipline is comprised of passionate, flexible technologists who love to practice and hone their craft",
        "As a Data Engineer for Slalom, you will work in collaborative teams to deliver innovative solutions on Amazon Web Services, Microsoft Azure, and Google Cloud Platform using core cloud data warehouse tools, distributed processing engines, event streaming platforms, and other modern data technologies",
        "In addition to building the next generation of data platforms, you will be working with some of the most forward-thinking organizations in data and analytics",
        "You will be engaged to participate in design sessions and be responsible for the timely completion of development items assigned to you in a project backlog",
        "You will have an interest to become the best at what you do and will have many opportunities to gain hands-on experience with new data platforms and programming languages as you explore the range of technologies that we help our clients with including:",
        "Cloud Data Warehouses (Amazon Redshift, Snowflake, Google BigQuery)",
        "Object Oriented Coding (Java, Python)",
        "Container Management Systems (Kubernetes, Amazon ECS)",
        "Artificial Intelligence / Machine Learning (Amazon Sagemaker, Azure ML Studio)",
        "Streaming Data Ingestion and Analytics (Amazon Kinesis, Apache Kafka)",
        "Visual Analytics (Tableau, PowerBI)"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-linkedin-com-jobs-view-data-engineer-at-slalom-4369144916",
    "_source": "new_jobs"
  },
  {
    "job_id": "MNfi2T5-f63RyD9hAAAAAA==",
    "job_title": "Platform Intelligence Engineer(Data Engineer) - Innovative Global Technology Leader",
    "employer_name": "Andiamo",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPPuewVyYM1D2v5HZ-VKB7WewXJku1CAZWBC7r&s=0",
    "employer_website": "https://andiamogo.com",
    "job_publisher": "LinkedIn",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.linkedin.com/jobs/view/platform-intelligence-engineer-data-engineer-innovative-global-technology-leader-at-andiamo-4362561414?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/platform-intelligence-engineer-data-engineer-innovative-global-technology-leader-at-andiamo-4362561414?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/f722c7cec5f754036b90fed1c2b9ec9e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobright",
        "apply_link": "https://jobright.ai/jobs/info/6971857b587dfa0bb55f378d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobrapido",
        "apply_link": "https://us.jobrapido.com/jobpreview/8058483939464970240?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Platform Intelligence Engineer\n\nWe are seeking a Platform Intelligence Engineer to join a high impact data organization operating at the intersection of advanced analytics, large scale platforms, and mission critical decision making. This role is ideal for an experienced data engineer who enjoys transforming complex data into actionable insight and driving measurable business outcomes across a sophisticated technology environment.\n\nLocation and Work Model\n• Based in New York City\n• Hybrid schedule with approximately two to three days in the office, with flexibility\n\nCitizenship and Clearance Requirements\n• United States citizenship is required\n• Ability to obtain a top secret security clearance\n• No felony convictions\n\nAbout The Role\n\nThis position has evolved from a traditional data engineering role into a more expansive platform focused function. The Platform Intelligence Engineer partners closely with engineering, finance, and operations teams to uncover inefficiencies, identify cost savings, and turn data into strategic leverage. The work directly influences how large scale technology platforms are built, optimized, and governed.\n\nWhat You Will Do\n• Explore complex datasets to surface opportunities for efficiency, optimization, and financial impact\n• Design, build, and maintain reliable data pipelines that support analytics and decision making at scale\n• Translate ambiguous business problems into structured data solutions\n• Partner with cross functional stakeholders to operationalize insights and drive adoption\n• Present findings and proposals clearly to both technical and non technical audiences\n• Collaborate deeply with platform and infrastructure engineers on data driven initiatives\n\nWhat We Are Looking For\n• A strong foundation in data engineering rather than purely analytical or research focused data science\n• Advanced proficiency in Python and SQL\n• Demonstrated experience architecting and implementing production grade data pipelines\n• Exceptional communication skills with the ability to influence across teams\n• Comfort operating in fast moving, ambiguous environments\n• Curiosity, adaptability, and a desire to continuously learn\n\nInterview Process\n• Online technical assessment focused on Python and SQL\n• Initial conversation with a recruiter\n• One hour technical and behavioral interview with a senior engineer\n• Virtual onsite consisting of three technical sessions covering problem decomposition, analytics, and scripting\n• Final interview with the hiring manager\n\nCompensation\n\nCompensation is determined on an individual basis and is flexible depending on experience and qualifications. Details will be discussed during the interview process.\n\nSecurity Clearance Process\n• The clearance process begins after hire and must be initiated within thirty days of the start date\n• The process typically takes six to twelve months to complete\n• Support and guidance are provided throughout the clearance journey\n• If clearance is ultimately not granted, alternative team placements may be explored unless disqualifying issues arise\n\nThis is a unique opportunity to work on complex, high stakes data challenges within a deeply technical organization where your work directly shapes efficiency, cost structure, and platform intelligence.\n\nAbout Andiamo\n\nTalent Partners for the AI Revolution. As a globally recognized staffing and consulting firm, we specialize in placing the top 2% of technology and go-to-market professionals with the world’s largest and most well-known companies.\n\nFor over 20 years, we've maintained the status of tier-one vendor for firms such as Palantir, Amazon, Fluidstack, Bloomberg, Relativity Space, Firefly, MasterCard, Visa, Two Sigma, Citadel, as well as other major financial services firms, elite hedge funds, Google-backed tech start-ups, and major software firms.\n\nOur talent solutions include Permanent Placement, Contract Staffing, Executive Search, and Dedicated Recruiting Services (RPO). Find out more at www.andiamogo.com",
    "job_is_remote": false,
    "job_posted_at": "5 days ago",
    "job_posted_at_timestamp": 1770854400,
    "job_posted_at_datetime_utc": "2026-02-12T00:00:00.000Z",
    "job_location": "New York, NY",
    "job_city": "New York",
    "job_state": "New York",
    "job_country": "US",
    "job_latitude": 40.7127753,
    "job_longitude": -74.0059728,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DMNfi2T5-f63RyD9hAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "This role is ideal for an experienced data engineer who enjoys transforming complex data into actionable insight and driving measurable business outcomes across a sophisticated technology environment",
        "Citizenship and Clearance Requirements",
        "United States citizenship is required",
        "Ability to obtain a top secret security clearance",
        "No felony convictions",
        "A strong foundation in data engineering rather than purely analytical or research focused data science",
        "Advanced proficiency in Python and SQL",
        "Demonstrated experience architecting and implementing production grade data pipelines",
        "Exceptional communication skills with the ability to influence across teams",
        "Comfort operating in fast moving, ambiguous environments",
        "Curiosity, adaptability, and a desire to continuously learn",
        "Interview Process",
        "Online technical assessment focused on Python and SQL",
        "Initial conversation with a recruiter",
        "One hour technical and behavioral interview with a senior engineer",
        "The clearance process begins after hire and must be initiated within thirty days of the start date",
        "The process typically takes six to twelve months to complete"
      ],
      "Benefits": [
        "Compensation is determined on an individual basis and is flexible depending on experience and qualifications"
      ],
      "Responsibilities": [
        "Hybrid schedule with approximately two to three days in the office, with flexibility",
        "The Platform Intelligence Engineer partners closely with engineering, finance, and operations teams to uncover inefficiencies, identify cost savings, and turn data into strategic leverage",
        "The work directly influences how large scale technology platforms are built, optimized, and governed",
        "Explore complex datasets to surface opportunities for efficiency, optimization, and financial impact",
        "Design, build, and maintain reliable data pipelines that support analytics and decision making at scale",
        "Translate ambiguous business problems into structured data solutions",
        "Partner with cross functional stakeholders to operationalize insights and drive adoption",
        "Present findings and proposals clearly to both technical and non technical audiences",
        "Collaborate deeply with platform and infrastructure engineers on data driven initiatives",
        "Virtual onsite consisting of three technical sessions covering problem decomposition, analytics, and scripting",
        "Support and guidance are provided throughout the clearance journey"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-linkedin-com-jobs-view-platform-intelligence-engineer-data-engineer-innovative-global-technology-leader-at-andiamo-4362561414",
    "_source": "new_jobs"
  },
  {
    "job_id": "Pu7OuzUrNErDCm84AAAAAA==",
    "job_title": "Staff Analytics Engineer",
    "employer_name": "Coinbase",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ5OL4_4viaeK1GNWKlusWTU0WPLNurfsu9Lsbt&s=0",
    "employer_website": "https://www.coinbase.com",
    "job_publisher": "National Labor Exchange",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://usnlx.com/baton-rouge-la/staff-analytics-engineer/ED4CA0E9E33642179CD8A2B150985E68/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "National Labor Exchange",
        "apply_link": "https://usnlx.com/baton-rouge-la/staff-analytics-engineer/ED4CA0E9E33642179CD8A2B150985E68/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Lensa",
        "apply_link": "https://lensa.com/job-v1/coinbase/baton-rouge-la/analytics-engineer/4c881f6e3387eef7914ee64a7c19acfc?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Adzuna",
        "apply_link": "https://www.adzuna.com/details/5609497715?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "WhatJobs",
        "apply_link": "https://www.whatjobs.com/jobs/staff-analytics-engineer?id=2430323615&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Ready to be pushed beyond what you think you’re capable of?\n\nAt Coinbase, our mission is to increase economic freedom in the world. It’s a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform — and with it, the future global financial system.\n\nTo achieve our mission, we’re seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the company’s hardest problems.\n\nOur work culture is intense and isn’t for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, there’s no better place to be.\n\nWhile many roles at Coinbase are remote-first, we are not remote-only. In-person participation is required throughout the year. Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment. Attendance is expected and fully supported.\n\nThe CX Analytics Engineering team bridges the gap between data engineering, data science, and business analytics by building scalable, impactful data solutions. We transform raw data into actionable insights through robust pipelines, well-designed data models, and tools that empower stakeholders across the organization to make data-driven decisions. As an Analytics Engineer on our team, you will function as a force multiplier, enabling Analytics and Operations to function seamlessly at scale. You’ll have the opportunity to translate complex technical and operational requirements into easily consumable front end data solutions, while also heavily influencing the overarching strategy for CX Analytics and its partners.\n\nOur team combines technical expertise with a deep understanding of the business to unlock the full potential of our data. We prioritize data quality, reliability, and usability, ensuring stakeholders can rely on our data to drive meaningful outcomes.\n\nWhat We Do\n• Trusted Data Sources: Develop and maintain foundational data models that serve as the single source of truth for analytics across the organization.\n• Actionable Insights: Empower stakeholders by translating business requirements into scalable data models, dashboards, and tools.\n• Cross-Functional Collaboration: Partner with engineering, data science, product, and business teams to ensure alignment on priorities and data solutions.\n• Scalable Data Products: Build frameworks, tools, and workflows that maximize efficiency for data users, while maintaining high standards of data quality and performance.\n• Outcome-Focused Solutions: Use modern development and analytics tools to deliver value quickly, while ensuring long-term maintainability.\n\nWhat you’ll be doing (ie. job duties):.\n\nAnalytics engineer is a hybrid Data Engineer/Data Scientist/Business Analyst role that has the expertise to understand data flows end to end, and the engineering toolkit to extract the most value out of it indirectly (building tables) or directly (solving problems, delivering insights).\n\nExpectations\n• *Be the expert: *Quickly build subject matter expertise in a specific business area and data domain. Understand the data flows from creation, ingestion, transformation, and delivery.\n• Examples:\n\nStep into a new line of business and work with Engineering and Product partners to deliver first data pipelines and insights.Communicate with engineering teams to fix data gaps for downstream data users.Take initiative and accountability for fixing issues anywhere in the stack.\n• Generate business value: Interface with stakeholders on data and product teams to deliver the most commercial value from data (directly or indirectly).\n• Examples:\n\nBuild out a new data model allowing multiple downstream DS teams to more easily unlock business value through experimentation and ad hoc analysis.Combine Eng details of the algo engine with stats and data expertise to come up with feasible solutions for Eng to make the algo better.Work with PMs to tie together new x-PG, and x-Product data into one holistic framework to optimize key financing product business metrics.\n• Focus on outcomes not tools: Use a variety of frameworks and paradigms to identify the best-fit tools to deliver value.\n• Examples:\n\nDevelop new abstractions (e.g. UDFs, Python packages, dashboards) to support scalable data workflows/infra.Stand up a framework for building data apps internally, enabling other DS teams to quickly add value.Use established tools with mastery (e.g. Google Sheets, SQL) to quickly deliver impact when speed is top priority.**\n\nWhat We Look For in You\n\nIn addition to out of the box thinking, attention to detail, a sense of urgency and a high degree of autonomy and accountability, we expect you to have the following skills:\n• *Customer Support Data Experience: *Familiarity with data elements and processes supporting successful Customer Support initiatives, including employee performance monitoring, workforce/staffing inputs, and the handling of sensitive PII across a broad stakeholder base.\n• Data Modeling Expertise: Strong understanding of best practices for designing modular and reusable data models (e.g., star schemas, snowflake schemas).\n• *Prompt Design and Engineering: *Expertise in prompt engineering and design for LLMs (e.g., GPT), including creating, refining, and optimizing prompts to improve response accuracy, relevance, and performance for internal tools and use cases.\n• Advanced SQL: Proficiency in advanced SQL techniques for data transformation, querying, and optimization.\n• Intermediate to Advanced Python: Expertise in scripting and automation, with experience in Object-Oriented Programming (OOP) and building scalable frameworks.\n• Collaboration and Communication: Strong ability to translate technical concepts into business value for cross-functional stakeholders. Proven ability to manage projects and communicate effectively across teams.\n• Data Pipeline Development: Experience building, maintaining, and optimizing ETL/ELT pipelines, using modern tools like dbt, Airflow, or similar.\n• Data Visualization: Proficiency in building polished dashboards using tools like Looker, Tableau, Superset, or Python visualization libraries (Matplotlib, Plotly).\n• Development Tools: Familiarity with version control (GitHub), CI/CD, and modern development workflows.\n• Data Architecture: Knowledge of modern data lake/warehouse architectures (e.g., Snowflake, Databricks) and transformation frameworks.\n• Business Acumen: Ability to understand and address business challenges through analytics engineering.\n• *Data savvy: *Familiarity with statistics and probability.\n• Bonus Skills:\n• Experience with cloud platforms (e.g., AWS, GCP).\n• Familiarity with Docker or Kubernetes.\n\nJob #: P71393\n\nPay Transparency Notice: Depending on your work location, the target annual *base *salary for this position can range as detailed below. Full time offers from Coinbase also include bonus eligibility + equity eligibility + benefits (including medical, dental, vision and 401(k)).\n\nBase salary range shown. Total compensation also includes equity and bonus eligibility and benefits:\n\n$207,485—$244,100 USD\n\nPlease be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.\n\nCommitment to Equal Opportunity\n\nCoinbase is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law. For US applicants, you may view the Employee Rights and the Know Your Rights notices by clicking on their corresponding links. Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law.\n\nCoinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information. For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).\n\nGlobal Data Privacy Notice for Job Candidates and Applicants\n\nDepending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.\n\nAI Disclosure\n\nFor select roles, Coinbase is piloting an AI tool based on machine learning technologies to conduct initial screening interviews to qualified applicants. The tool simulates realistic interview scenarios and engages in dynamic conversation. A human recruiter will review your interview responses, provided in the form of a voice recording and/or transcript, to assess them against the qualifications and characteristics outlined in the job description.\n\nFor select roles, Coinbase is also piloting an AI interview intelligence platform to transcribe and summarize interview notes, allowing our interviewers to fully focus on you as the candidate.\n\nThe above pilots are for testing purposes and Coinbase will not use AI to make decisions impacting employment. To request a reasonable accommodation due to disability, please contact accommodations[at]coinbase.com",
    "job_is_remote": false,
    "job_posted_at": "11 days ago",
    "job_posted_at_timestamp": 1770336000,
    "job_posted_at_datetime_utc": "2026-02-06T00:00:00.000Z",
    "job_location": "Baton Rouge, LA",
    "job_city": "Baton Rouge",
    "job_state": "Louisiana",
    "job_country": "US",
    "job_latitude": 30.4514677,
    "job_longitude": -91.18714659999999,
    "job_benefits": [
      "dental_coverage",
      "paid_time_off",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DPu7OuzUrNErDCm84AAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up",
        "We want someone who will run towards, not away from, solving the company’s hardest problems",
        "Use established tools with mastery (e.g",
        "Google Sheets, SQL) to quickly deliver impact when speed is top priority.**",
        "In addition to out of the box thinking, attention to detail, a sense of urgency and a high degree of autonomy and accountability, we expect you to have the following skills:",
        "*Prompt Design and Engineering: *Expertise in prompt engineering and design for LLMs (e.g., GPT), including creating, refining, and optimizing prompts to improve response accuracy, relevance, and performance for internal tools and use cases",
        "Intermediate to Advanced Python: Expertise in scripting and automation, with experience in Object-Oriented Programming (OOP) and building scalable frameworks",
        "Collaboration and Communication: Strong ability to translate technical concepts into business value for cross-functional stakeholders",
        "Proven ability to manage projects and communicate effectively across teams",
        "Data Pipeline Development: Experience building, maintaining, and optimizing ETL/ELT pipelines, using modern tools like dbt, Airflow, or similar",
        "Data Visualization: Proficiency in building polished dashboards using tools like Looker, Tableau, Superset, or Python visualization libraries (Matplotlib, Plotly)",
        "Development Tools: Familiarity with version control (GitHub), CI/CD, and modern development workflows",
        "Data Architecture: Knowledge of modern data lake/warehouse architectures (e.g., Snowflake, Databricks) and transformation frameworks",
        "Business Acumen: Ability to understand and address business challenges through analytics engineering",
        "*Data savvy: *Familiarity with statistics and probability",
        "Experience with cloud platforms (e.g., AWS, GCP)",
        "Familiarity with Docker or Kubernetes"
      ],
      "Benefits": [
        "Pay Transparency Notice: Depending on your work location, the target annual *base *salary for this position can range as detailed below",
        "Full time offers from Coinbase also include bonus eligibility + equity eligibility + benefits (including medical, dental, vision and 401(k))",
        "Base salary range shown",
        "Total compensation also includes equity and bonus eligibility and benefits:",
        "$207,485—$244,100 USD"
      ],
      "Responsibilities": [
        "In-person participation is required throughout the year",
        "Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment",
        "Attendance is expected and fully supported",
        "We transform raw data into actionable insights through robust pipelines, well-designed data models, and tools that empower stakeholders across the organization to make data-driven decisions",
        "As an Analytics Engineer on our team, you will function as a force multiplier, enabling Analytics and Operations to function seamlessly at scale",
        "You’ll have the opportunity to translate complex technical and operational requirements into easily consumable front end data solutions, while also heavily influencing the overarching strategy for CX Analytics and its partners",
        "Trusted Data Sources: Develop and maintain foundational data models that serve as the single source of truth for analytics across the organization",
        "Actionable Insights: Empower stakeholders by translating business requirements into scalable data models, dashboards, and tools",
        "Cross-Functional Collaboration: Partner with engineering, data science, product, and business teams to ensure alignment on priorities and data solutions",
        "Scalable Data Products: Build frameworks, tools, and workflows that maximize efficiency for data users, while maintaining high standards of data quality and performance",
        "Outcome-Focused Solutions: Use modern development and analytics tools to deliver value quickly, while ensuring long-term maintainability",
        "Analytics engineer is a hybrid Data Engineer/Data Scientist/Business Analyst role that has the expertise to understand data flows end to end, and the engineering toolkit to extract the most value out of it indirectly (building tables) or directly (solving problems, delivering insights)",
        "*Be the expert: *Quickly build subject matter expertise in a specific business area and data domain",
        "Understand the data flows from creation, ingestion, transformation, and delivery",
        "Step into a new line of business and work with Engineering and Product partners to deliver first data pipelines and insights",
        "Communicate with engineering teams to fix data gaps for downstream data users",
        "Take initiative and accountability for fixing issues anywhere in the stack",
        "Generate business value: Interface with stakeholders on data and product teams to deliver the most commercial value from data (directly or indirectly)",
        "Build out a new data model allowing multiple downstream DS teams to more easily unlock business value through experimentation and ad hoc analysis",
        "Combine Eng details of the algo engine with stats and data expertise to come up with feasible solutions for Eng to make the algo better",
        "Work with PMs to tie together new x-PG, and x-Product data into one holistic framework to optimize key financing product business metrics",
        "Focus on outcomes not tools: Use a variety of frameworks and paradigms to identify the best-fit tools to deliver value",
        "Develop new abstractions (e.g",
        "UDFs, Python packages, dashboards) to support scalable data workflows/infra.Stand up a framework for building data apps internally, enabling other DS teams to quickly add value",
        "*Customer Support Data Experience: *Familiarity with data elements and processes supporting successful Customer Support initiatives, including employee performance monitoring, workforce/staffing inputs, and the handling of sensitive PII across a broad stakeholder base",
        "Data Modeling Expertise: Strong understanding of best practices for designing modular and reusable data models (e.g., star schemas, snowflake schemas)",
        "Advanced SQL: Proficiency in advanced SQL techniques for data transformation, querying, and optimization"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "usnlx-com-baton-rouge-la-staff-analytics-engineer-ed4ca0e9e33642179cd8a2b150985e68-job",
    "_source": "new_jobs"
  },
  {
    "job_id": "4PMXCF0Zj3csVibCAAAAAA==",
    "job_title": "Data Engineering Manager - Advanced Analytics",
    "employer_name": "Niagara Bottling",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQD1lp7Y_nPmktOrGBYuyI9Zyj9tBqyLbRlieZB&s=0",
    "employer_website": "https://www.niagarawater.com",
    "job_publisher": "Niagara Bottling",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.niagarawater.com/us/en/job/R45735/Data-Engineering-Manager-Advanced-Analytics?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Niagara Bottling",
        "apply_link": "https://careers.niagarawater.com/us/en/job/R45735/Data-Engineering-Manager-Advanced-Analytics?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=b3a692c155871761&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Career.io",
        "apply_link": "https://career.io/job/advanced-analytics-manager-data-engineering-diamond-bar-niagara-bottling-f8a97cc14e8a3b1597c041e2c1db509c?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Built In LA",
        "apply_link": "https://www.builtinla.com/job/lead-power-bi-developer/4193106?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Built In",
        "apply_link": "https://builtin.com/job/lead-power-bi-developer/4193106?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/data-engineering-manager-advanced-analytics_7ea1afe75026a4bcd9f82ae335cbe32f2704f?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/Niagara-Bottling/Job/Data-Engineering-Manager-Advanced-Analytics/-in-Diamond-Bar,CA?jid=3b90f12867465791&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/data-engineering-manager-advanced-analytics-at-niagara-bottling-4354561864?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "At Niagara, we’re looking for Team Members who want to be part of achieving our mission to provide our customers the highest quality most affordable bottled water.\n\nConsider applying here, if you want to:\n• Work in an entrepreneurial and dynamic environment with a chance to make an impact.\n• Develop lasting relationships with great people.\n• Have the opportunity to build a satisfying career.\n\nWe offer competitive compensation and benefits packages for our Team Members.\n\nData Engineering Manager - Advanced Analytics\n\nAs a key people leader within our data and analytics function, the Advanced Analytics Manager plays a critical role in architecting and maintaining the data infrastructure that underpins enterprise analytics. This role leads a team of data engineers and analytics professionals, focusing on the design, implementation, and optimization of scalable, reliable, and secure data pipelines, especially for complex, high-volume sources such as IoT and sensor-based systems. Working cross-functionally with operations, IT, and business stakeholders, the Advanced Analytics Manager ensures that data from diverse sources, including real-time telemetry, manufacturing systems, and traditional enterprise platforms are efficiently ingested, transformed, and made accessible for analytical consumption. In addition, the role includes light but growing exposure to Generative AI use cases, such as document summarization, chat interfaces for data access, and large language model (LLM) integration—especially in scenarios that augment data accessibility and user experience across the organization. This position requires not only technical expertise but also strategic thinking and leadership skills to evolve data infrastructure, support analytics scalability, and drive a data-first culture. A proven ability to lead high-performing teams and deliver impactful solutions in dynamic, data-rich environments is essential for success.\n• Lead and manage a team of data engineers and analytics professionals, providing strategic direction, mentorship, train, coach, performance reviews, and hands-on support to foster a collaborative, high-performing team environment focused on delivering impactful data solutions.\n• Establish clear objectives and key results (OKRs) for the team that align with the enterprise analytics and data strategy, ensuring close coordination with business goals and evolving priorities.\n• Conduct regular performance reviews, deliver constructive feedback, and champion continuous learning by identifying training, upskilling, and development opportunities for team members.\n• Partner with cross-functional teams, including business analysts, data scientists, IT, and key business stakeholders, to understand data requirements and deliver solutions that support business intelligence, operational reporting, and advanced analytics use cases.\n• Define and implement best practices in data engineering, covering data modeling, pipeline orchestration (ETL/ELT), data integration, and data quality, while ensuring reliable access to data from diverse sources such as databases, APIs, cloud platforms, and IoT systems.\n• Drive continuous improvement and innovation in data architecture and engineering techniques, with a focus on increasing scalability, performance, and reusability across the analytics ecosystem.\n• Oversee project planning and execution, balancing team capacity with priority management, delivery timelines, and quality standards to ensure successful outcomes for strategic and operational analytics initiatives.\n• Collaborate with cross-functional business and IT stakeholders to define and implement data and analytics strategies that support enterprise decision-making, ensuring data integrity, security, and governance across all analytical initiatives.\n• Provide technical leadership in data engineering and analytics infrastructure, leveraging modern cloud-native tools to enable high-performance data platforms that support BI, reporting, and advanced analytics.\n• Champion a culture of data innovation and continuous learning, encouraging the team to explore new data patterns, tooling, and architectural practices that improve scalability, reliability, and time-to-insight.\n• Oversee resource planning, vendor coordination, and budget management for the analytics engineering function, ensuring alignment with strategic priorities and operational efficiency.\n• Lead the design and implementation of high-volume, scalable data pipelines, models, and data marts across Data Lakes and Data Warehouses to support reporting, dashboarding, and analytics workloads.\n• Translate technical and project outcomes into business context through executive-ready presentations and analytics steering committee briefings, facilitating alignment and decision-making.\n• Demonstrate proficiency in Microsoft Azure Cloud (preferred) and/or Amazon Web Services, particularly within data engineering and analytics service ecosystems (e.g., Azure Data Factory, Synapse, Databricks, Redshift).\n• Build and manage DevOps pipelines for CI/CD and analytics solution deployment, ensuring consistency, automation, and compliance with change control standards.\n• Serve as a proactive leader who delivers on commitments and identifies opportunities for process improvement, team development, and organizational data literacy.\n• Coordinate and collaborate with onsite and offshore consultants to support scalable delivery and knowledge transfer across global analytics initiatives.\n• Maintain flexibility and responsiveness to evolving business needs; this job description may be adjusted to reflect emerging priorities or strategic direction.\n\nPlease note that this job description is not designed to contain a comprehensive list of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without prior notice.\n\nAdditionally, the Advanced Analytics Manager is expected to demonstrate:\n• Excellent communication, leadership and collaboration skills\n• Possesses solid project management skills\n• Advanced decision making and problem-solving skills\n• Ability to guide technical projects successfully from inception to completion\n• Experienced with Microsoft Word, Excel, PowerPoint, Visio and Outlook\n• Team Work - balances team and individual responsibilities; gives and welcomes feedback; contributes to building a positive team spirit; puts success of team above own interests; able to build morale and group commitments to goals and objectives\n• Adaptability - adapts to changes in the work environment; able to deal with frequent change, delays, or unexpected events\n• Planning/Organizing - uses time efficiently; plans for additional resources; sets goals and objectives; organizes or schedules other people and their tasks\n• Project Management - coordinates projects; communicates changes and progress; completes projects on time; budget management; manages project team activities\n• Oral Communication - speaks clearly and persuasively in positive or negative situations; listens and gets clarification; responds well to questions\n• Excellent team player\n\nWork Experience\n• Required:\n• 8-10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities\n• 8-10 years – Experience in data modeling, ETL processes, and data warehousing\n• 8-10 years – Experience in building and managing enterprise scale data pipelines\n• 8-10 years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)\n• 8-10 years – Experience in DevOps, CI/CD pipelines\n• 8-10 years – Experience in Python/R, Spark/Kafka\n• 8-10 years – Experience with Azure Databricks/Data Factory or similar technology\n• 8-10 years – Experience in Project management\n• Preferred:\n• 10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities\n• 10+ years – Experience in data modeling, ETL processes, and data warehousing\n• 10+ years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)\n• 10+ years – Experience in DevOps, CI/CD pipelines\n• 10+ years – Experience in Python/R, Spark/Kafka\n• 10+ years – Experience with Azure Databricks/Data Factory or similar technology\n• 10+ years – Experience in Project management\n• 2 years – Experience with Large language Models and building Gen AI applications\n\nEducation\n• Minimum Required:\n• Bachelor's Degree in Computer Science or Engineering\n• Preferred:\n• Master's Degree in Computer Science or Engineering\n\nCertification/License:\n• Required: None Required\n• Preferred: Data Engineering/Cloud certifications/Gen AI\n\nTypical Compensation Range\nPay Rate Type: Salary\n\n$136,778.46 - $198,328.77 / Yearly\n\nBonus Target: 10% Annual\n\nBenefits\n\nhttps://careers.niagarawater.com/us/en/benefits\n\nAny employment agency, person or entity that submits a résumé into this career site or to a hiring manager does so with the understanding that the applicant's résumé will become the property of Niagara Bottling, LLC. Niagara Bottling, LLC will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person or entity.\n\nEmployment agencies that have fee agreements with Niagara Bottling, LLC and have been engaged on a search shall submit résumé to the designated Niagara Bottling, LLC recruiter or, upon authorization, submit résumé into this career site to be eligible for placement fees.\nNiagara Plant Name\nCORP-MAIN",
    "job_is_remote": false,
    "job_posted_at": "1 day ago",
    "job_posted_at_timestamp": 1771200000,
    "job_posted_at_datetime_utc": "2026-02-16T00:00:00.000Z",
    "job_location": "Diamond Bar, CA",
    "job_city": "Diamond Bar",
    "job_state": "California",
    "job_country": "US",
    "job_latitude": 34.0009951,
    "job_longitude": -117.8112041,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D4PMXCF0Zj3csVibCAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "This position requires not only technical expertise but also strategic thinking and leadership skills to evolve data infrastructure, support analytics scalability, and drive a data-first culture",
        "Possesses solid project management skills",
        "Advanced decision making and problem-solving skills",
        "Ability to guide technical projects successfully from inception to completion",
        "Experienced with Microsoft Word, Excel, PowerPoint, Visio and Outlook",
        "Team Work - balances team and individual responsibilities; gives and welcomes feedback; contributes to building a positive team spirit; puts success of team above own interests; able to build morale and group commitments to goals and objectives",
        "Excellent team player",
        "8-10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities",
        "8-10 years – Experience in data modeling, ETL processes, and data warehousing",
        "8-10 years – Experience in building and managing enterprise scale data pipelines",
        "8-10 years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)",
        "8-10 years – Experience in DevOps, CI/CD pipelines",
        "8-10 years – Experience in Python/R, Spark/Kafka",
        "8-10 years – Experience with Azure Databricks/Data Factory or similar technology",
        "8-10 years – Experience in Project management",
        "10 years – Experience managing an onsite team of 5-6 full time direct reports, to include mentoring, coaching, performance reviews, and team building activities",
        "10+ years – Experience in data modeling, ETL processes, and data warehousing",
        "10+ years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)",
        "10+ years – Experience in DevOps, CI/CD pipelines",
        "10+ years – Experience in Python/R, Spark/Kafka",
        "10+ years – Experience with Azure Databricks/Data Factory or similar technology",
        "10+ years – Experience in Project management",
        "2 years – Experience with Large language Models and building Gen AI applications",
        "Bachelor's Degree in Computer Science or Engineering",
        "Master's Degree in Computer Science or Engineering",
        "Required: None Required"
      ],
      "Benefits": [
        "Work in an entrepreneurial and dynamic environment with a chance to make an impact",
        "Develop lasting relationships with great people",
        "Have the opportunity to build a satisfying career",
        "We offer competitive compensation and benefits packages for our Team Members",
        "Typical Compensation Range",
        "Pay Rate Type: Salary",
        "$136,778.46 - $198,328.77 / Yearly",
        "Bonus Target: 10% Annual"
      ],
      "Responsibilities": [
        "This role leads a team of data engineers and analytics professionals, focusing on the design, implementation, and optimization of scalable, reliable, and secure data pipelines, especially for complex, high-volume sources such as IoT and sensor-based systems",
        "Working cross-functionally with operations, IT, and business stakeholders, the Advanced Analytics Manager ensures that data from diverse sources, including real-time telemetry, manufacturing systems, and traditional enterprise platforms are efficiently ingested, transformed, and made accessible for analytical consumption",
        "In addition, the role includes light but growing exposure to Generative AI use cases, such as document summarization, chat interfaces for data access, and large language model (LLM) integration—especially in scenarios that augment data accessibility and user experience across the organization",
        "A proven ability to lead high-performing teams and deliver impactful solutions in dynamic, data-rich environments is essential for success",
        "Lead and manage a team of data engineers and analytics professionals, providing strategic direction, mentorship, train, coach, performance reviews, and hands-on support to foster a collaborative, high-performing team environment focused on delivering impactful data solutions",
        "Establish clear objectives and key results (OKRs) for the team that align with the enterprise analytics and data strategy, ensuring close coordination with business goals and evolving priorities",
        "Conduct regular performance reviews, deliver constructive feedback, and champion continuous learning by identifying training, upskilling, and development opportunities for team members",
        "Partner with cross-functional teams, including business analysts, data scientists, IT, and key business stakeholders, to understand data requirements and deliver solutions that support business intelligence, operational reporting, and advanced analytics use cases",
        "Define and implement best practices in data engineering, covering data modeling, pipeline orchestration (ETL/ELT), data integration, and data quality, while ensuring reliable access to data from diverse sources such as databases, APIs, cloud platforms, and IoT systems",
        "Drive continuous improvement and innovation in data architecture and engineering techniques, with a focus on increasing scalability, performance, and reusability across the analytics ecosystem",
        "Oversee project planning and execution, balancing team capacity with priority management, delivery timelines, and quality standards to ensure successful outcomes for strategic and operational analytics initiatives",
        "Collaborate with cross-functional business and IT stakeholders to define and implement data and analytics strategies that support enterprise decision-making, ensuring data integrity, security, and governance across all analytical initiatives",
        "Provide technical leadership in data engineering and analytics infrastructure, leveraging modern cloud-native tools to enable high-performance data platforms that support BI, reporting, and advanced analytics",
        "Champion a culture of data innovation and continuous learning, encouraging the team to explore new data patterns, tooling, and architectural practices that improve scalability, reliability, and time-to-insight",
        "Oversee resource planning, vendor coordination, and budget management for the analytics engineering function, ensuring alignment with strategic priorities and operational efficiency",
        "Lead the design and implementation of high-volume, scalable data pipelines, models, and data marts across Data Lakes and Data Warehouses to support reporting, dashboarding, and analytics workloads",
        "Translate technical and project outcomes into business context through executive-ready presentations and analytics steering committee briefings, facilitating alignment and decision-making",
        "Build and manage DevOps pipelines for CI/CD and analytics solution deployment, ensuring consistency, automation, and compliance with change control standards",
        "Serve as a proactive leader who delivers on commitments and identifies opportunities for process improvement, team development, and organizational data literacy",
        "Coordinate and collaborate with onsite and offshore consultants to support scalable delivery and knowledge transfer across global analytics initiatives",
        "Maintain flexibility and responsiveness to evolving business needs; this job description may be adjusted to reflect emerging priorities or strategic direction",
        "Duties, responsibilities and activities may change at any time with or without prior notice",
        "Additionally, the Advanced Analytics Manager is expected to demonstrate:",
        "Excellent communication, leadership and collaboration skills",
        "Adaptability - adapts to changes in the work environment; able to deal with frequent change, delays, or unexpected events",
        "Planning/Organizing - uses time efficiently; plans for additional resources; sets goals and objectives; organizes or schedules other people and their tasks",
        "Project Management - coordinates projects; communicates changes and progress; completes projects on time; budget management; manages project team activities",
        "Oral Communication - speaks clearly and persuasively in positive or negative situations; listens and gets clarification; responds well to questions"
      ]
    },
    "job_onet_soc": "11302100",
    "job_onet_job_zone": "4",
    "id": "careers-niagarawater-com-us-en-job-r45735-data-engineering-manager-advanced-analytics",
    "_source": "new_jobs"
  },
  {
    "job_id": "5FJGrJp-KLWXkkHBAAAAAA==",
    "job_title": "Staff Analytics Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=0df90abea72f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=0df90abea72f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Jobilize",
        "apply_link": "https://www.jobilize.com/job/us-ny-syracuse-staff-analytics-engineer-nitrogen-hiring-now-job-immediately?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Staff Analytics Engineer to transform raw data into trusted business insights.\n\nKey Responsibilities\n\nArchitect the complete data lifecycle and own the gold layer, designing the semantic layer and optimizing data tables\n\nTranslate complex business questions into technical definitions and build consensus on enterprise-wide metric definitions\n\nChampion a product-oriented mindset by establishing standards for documentation, testing, and data model design\n\nRequired Qualifications\n\n10+ years of experience in Analytics Engineering, Software Engineering, or Data Engineering, with 4 years in large-scale data environments\n\nExpertise in dimensional modeling best practices and designing reusable data models\n\nProficiency in advanced SQL techniques and performance tuning\n\nStrong expertise in Python for scripting and data manipulation\n\nBachelor's degree in Computer Science, Software Engineering, Data Engineering, or a related field",
    "job_is_remote": false,
    "job_posted_at": "3 days ago",
    "job_posted_at_timestamp": 1771027200,
    "job_posted_at_datetime_utc": "2026-02-14T00:00:00.000Z",
    "job_location": "Syracuse, NY",
    "job_city": "Syracuse",
    "job_state": "New York",
    "job_country": "US",
    "job_latitude": 43.0494832,
    "job_longitude": -76.1473977,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D5FJGrJp-KLWXkkHBAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "10+ years of experience in Analytics Engineering, Software Engineering, or Data Engineering, with 4 years in large-scale data environments",
        "Expertise in dimensional modeling best practices and designing reusable data models",
        "Proficiency in advanced SQL techniques and performance tuning",
        "Strong expertise in Python for scripting and data manipulation",
        "Bachelor's degree in Computer Science, Software Engineering, Data Engineering, or a related field"
      ],
      "Responsibilities": [
        "Architect the complete data lifecycle and own the gold layer, designing the semantic layer and optimizing data tables",
        "Translate complex business questions into technical definitions and build consensus on enterprise-wide metric definitions",
        "Champion a product-oriented mindset by establishing standards for documentation, testing, and data model design"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "Sb3uO7REaIixrkvHAAAAAA==",
    "job_title": "Global IT Data Engineer Expert Director",
    "employer_name": "Boston Consulting Group",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxMy3OJRSwXcqB_s6dIHtI8zYYudxFVfaOcfGQ&s=0",
    "employer_website": null,
    "job_publisher": "BCG Careers - Boston Consulting Group",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.bcg.com/global/en/job/55729/Global-IT-Data-Engineer-Expert-Director?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "BCG Careers - Boston Consulting Group",
        "apply_link": "https://careers.bcg.com/global/en/job/55729/Global-IT-Data-Engineer-Expert-Director?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "ZipRecruiter",
        "apply_link": "https://www.ziprecruiter.com/c/The-Boston-Consulting-Group/Job/Global-IT-Data-Engineer-Expert-Director/-in-Boston,MA?jid=17684eef51a37d98&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=7031f37702de&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/global-it-data-engineer-expert-director-at-boston-consulting-group-bcg-4318684330?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Simplify",
        "apply_link": "https://simplify.jobs/p/4db77930-aeab-4c47-a932-37b11a514678/Global-IT-Data-Engineer-Expert-Director?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "InHerSight",
        "apply_link": "https://www.inhersight.com/company/the-boston-consulting-group/job/ihs/zf4bmxvw?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Teal",
        "apply_link": "https://www.tealhq.com/job/global-it-solution-architect-director_a1fd660a-ea85-4261-b3ac-cdfdb551ba7b?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "KSNT Jobs",
        "apply_link": "https://jobs.ksnt.com/jobs/global-it-data-engineer-expert-director-boston-massachusetts/2608970072-2/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Who We Are\n\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\n\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\n\nWhat You'll Do\n\nAs Global IT Data Engineer Expert Director, you will shape and lead the vision for enterprise data architecture, pipelines, and governance while remaining a hands-on technical contributor. You will ensure high-quality, trusted data powers analytics, reporting, and emerging GenAI use cases. Your leadership will bridge strategy, execution, and innovation—guiding the team while actively engaging in design and delivery.\n\nWHAT YOU’LL DO\n• Architect and build enterprise-grade data pipelines and models enabling downstream analytics, reporting, and GenAI-driven insights.\n• Actively contribute to the development of scalable data solutions using dbt, Apache Airflow, FiveTran/AWS Glue and Snowflake, optimizing for reliability, observability, and performance.\n• Champion data quality by ensuring completeness, accuracy, timeliness, and lineage across ingestion, transformation, and delivery.\n• Partner with analytics, AI, and business teams to deliver high-value data assets that power BI dashboards, predictive models, and generative AI applications.\n• Lead cross-functional collaboration with product owners, architects, and governance teams to define and evolve data standards and architectures.\n• Drive experimentation, developing proofs of concept and minimum viable products to evaluate new technologies and patterns.\n• Establish and enforce data performance, quality, and security policies aligned with enterprise governance and regulatory frameworks.\n• Serve as a player-coach—mentoring engineers while contributing directly to complex design and code reviews.\n• Lead resolution of critical production issues, triaging technical challenges that demand immediate action.\n\nYOU’RE GOOD AT\n\nYou bring a rare combination of strategic leadership and deep technical ability. You can design data architectures at scale while still contributing directly to engineering excellence.\n• Expert in data modeling, warehousing, and pipeline orchestration, with proven ability to design and implement production-grade data systems.\n• Hands-on experience developing and optimizing ETL/ELT pipelines with SQL, Python, dbt, Airflow, FiveTran, AWS Glue, and Snowflake.\n• Skilled at analyzing and resolving performance bottlenecks in complex data flows, transformations, and reporting layers.\n• Deep understanding of data quality frameworks such as SCD, CDC, and DQ or DV, with a focus on automated validation and observability.\n• Comfortable working with structured, semi-structured, and unstructured data for analytics and GenAI consumption.\n• Experienced in integrating pipelines with AI, ML, and GenAI workflows, ensuring models are powered by high-fidelity, explainable data.\n• Collaborative and pragmatic—able to dive into the codebase when needed while guiding architectural direction for scalability and reliability.\n• Strong advocate for Agile principles, iterative improvement, and an engineering culture rooted in accountability, innovation, and mentorship.\n\nWhat You'll Bring\n• Over ten years of experience in data engineering, architecture, or platform leadership, including at least three years leading technical teams.\n• Proven experience as a hands-on data engineer or architect capable of designing, coding, and reviewing complex data solutions.\n• Expertise in modern data stacks including Snowflake, dbt, Airflow, AWS, GCP, or Azure, and integration tools such as FiveTran or Glue.\n• Strong track record in data modeling, ETL or ELT orchestration, and implementation of data governance frameworks.\n• Demonstrated ability to design secure, compliant, and high-performing data architectures.\n• Deep understanding of data observability, monitoring, and lineage tools.\n• Familiarity with APIs, event-driven architectures, and near real-time data pipelines.\n• Excellent communication and presentation skills, with the ability to translate technical solutions into strategic business value.\n\nEssential Education\n• Bachelor's degree or equivalent combination of education and experience.\n• Bachelor's degree in information science, data management, computer science or related field preferred.\n\nWho You'll Work With\n• Legal product portfolio technical leaders, product owners, functional area teams across levels\n• Global IT Teams (Enterprise Architecture, Global Data Portfolio)\n• Consulting and internal Data Product Portfolio teams across BCG\n\nAdditional info\n• ** For US locations only ***\n\nIn the US, we have a compensation transparency approach.\n\nTotal compensation for this role includes base salary, annual discretionary performance bonus, retirement contribution, and a market leading benefits package described below.\n\n• The base salary range for this role in Boston is $180,000.00 - $219,300.00.\n\nThis is an estimated range, however, specific base salaries within the range depend on various factors such as experience and skill set. It is not common for new BCG employees to be hired at the high-end of the salary range. BCG regularly reviews its ranges to ensure market competitiveness.\n\nIn addition to your base salary, your total compensation will include a bonus of up to 30% and a generous retirement contribution that starts at 5% and moves to 10% after 2 years.\n\nAll of our plans provide best in class coverage:\n• Zero dollar ($0) health insurance premiums for BCG employees, spouses, and children\n• Low $10 (USD) copays for trips to the doctor, urgent care visits and prescriptions for generic drugs\n• Dental coverage, including up to $5,000 in orthodontia benefits\n• Vision insurance with coverage for both glasses and contact lenses annually\n• Reimbursement for gym memberships and other fitness activities\n• Fully vested Profit Sharing Retirement Fund contributions made annually, whether you contribute or not, plus the option for employees to make personal contributions to a 401(k) plan\n• Paid Parental Leave and other family benefits such as elective egg freezing, surrogacy, and adoption reimbursement\n• Generous paid time off including 12 holidays per year, an annual office closure between Christmas and New Years, and 15 vacation days per year (earned at 1.25 days per month)\n• Paid sick time on an as needed basis\n\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\n\nBCG is an E - Verify Employer. Click here for more information on E-Verify.",
    "job_is_remote": false,
    "job_posted_at": "1 day ago",
    "job_posted_at_timestamp": 1771200000,
    "job_posted_at_datetime_utc": "2026-02-16T00:00:00.000Z",
    "job_location": "Boston, MA",
    "job_city": "Boston",
    "job_state": "Massachusetts",
    "job_country": "US",
    "job_latitude": 42.355507599999996,
    "job_longitude": -71.0565364,
    "job_benefits": [
      "paid_time_off",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DSb3uO7REaIixrkvHAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "You bring a rare combination of strategic leadership and deep technical ability",
        "You can design data architectures at scale while still contributing directly to engineering excellence",
        "Expert in data modeling, warehousing, and pipeline orchestration, with proven ability to design and implement production-grade data systems",
        "Hands-on experience developing and optimizing ETL/ELT pipelines with SQL, Python, dbt, Airflow, FiveTran, AWS Glue, and Snowflake",
        "Over ten years of experience in data engineering, architecture, or platform leadership, including at least three years leading technical teams",
        "Proven experience as a hands-on data engineer or architect capable of designing, coding, and reviewing complex data solutions",
        "Expertise in modern data stacks including Snowflake, dbt, Airflow, AWS, GCP, or Azure, and integration tools such as FiveTran or Glue",
        "Strong track record in data modeling, ETL or ELT orchestration, and implementation of data governance frameworks",
        "Demonstrated ability to design secure, compliant, and high-performing data architectures",
        "Deep understanding of data observability, monitoring, and lineage tools",
        "Familiarity with APIs, event-driven architectures, and near real-time data pipelines",
        "Excellent communication and presentation skills, with the ability to translate technical solutions into strategic business value",
        "Bachelor's degree or equivalent combination of education and experience"
      ],
      "Benefits": [
        "Total compensation for this role includes base salary, annual discretionary performance bonus, retirement contribution, and a market leading benefits package described below",
        "The base salary range for this role in Boston is $180,000.00 - $219,300.00",
        "This is an estimated range, however, specific base salaries within the range depend on various factors such as experience and skill set",
        "In addition to your base salary, your total compensation will include a bonus of up to 30% and a generous retirement contribution that starts at 5% and moves to 10% after 2 years",
        "Zero dollar ($0) health insurance premiums for BCG employees, spouses, and children",
        "Low $10 (USD) copays for trips to the doctor, urgent care visits and prescriptions for generic drugs",
        "Dental coverage, including up to $5,000 in orthodontia benefits",
        "Vision insurance with coverage for both glasses and contact lenses annually",
        "Reimbursement for gym memberships and other fitness activities",
        "Fully vested Profit Sharing Retirement Fund contributions made annually, whether you contribute or not, plus the option for employees to make personal contributions to a 401(k) plan",
        "Paid Parental Leave and other family benefits such as elective egg freezing, surrogacy, and adoption reimbursement",
        "Generous paid time off including 12 holidays per year, an annual office closure between Christmas and New Years, and 15 vacation days per year (earned at 1.25 days per month)",
        "Paid sick time on an as needed basis"
      ],
      "Responsibilities": [
        "As Global IT Data Engineer Expert Director, you will shape and lead the vision for enterprise data architecture, pipelines, and governance while remaining a hands-on technical contributor",
        "You will ensure high-quality, trusted data powers analytics, reporting, and emerging GenAI use cases",
        "Your leadership will bridge strategy, execution, and innovation—guiding the team while actively engaging in design and delivery",
        "Architect and build enterprise-grade data pipelines and models enabling downstream analytics, reporting, and GenAI-driven insights",
        "Actively contribute to the development of scalable data solutions using dbt, Apache Airflow, FiveTran/AWS Glue and Snowflake, optimizing for reliability, observability, and performance",
        "Champion data quality by ensuring completeness, accuracy, timeliness, and lineage across ingestion, transformation, and delivery",
        "Partner with analytics, AI, and business teams to deliver high-value data assets that power BI dashboards, predictive models, and generative AI applications",
        "Lead cross-functional collaboration with product owners, architects, and governance teams to define and evolve data standards and architectures",
        "Drive experimentation, developing proofs of concept and minimum viable products to evaluate new technologies and patterns",
        "Establish and enforce data performance, quality, and security policies aligned with enterprise governance and regulatory frameworks",
        "Serve as a player-coach—mentoring engineers while contributing directly to complex design and code reviews",
        "Lead resolution of critical production issues, triaging technical challenges that demand immediate action",
        "Skilled at analyzing and resolving performance bottlenecks in complex data flows, transformations, and reporting layers",
        "Deep understanding of data quality frameworks such as SCD, CDC, and DQ or DV, with a focus on automated validation and observability",
        "Comfortable working with structured, semi-structured, and unstructured data for analytics and GenAI consumption",
        "Experienced in integrating pipelines with AI, ML, and GenAI workflows, ensuring models are powered by high-fidelity, explainable data",
        "Collaborative and pragmatic—able to dive into the codebase when needed while guiding architectural direction for scalability and reliability",
        "Strong advocate for Agile principles, iterative improvement, and an engineering culture rooted in accountability, innovation, and mentorship",
        "Legal product portfolio technical leaders, product owners, functional area teams across levels",
        "Global IT Teams (Enterprise Architecture, Global Data Portfolio)",
        "Consulting and internal Data Product Portfolio teams across BCG"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "careers-bcg-com-global-en-job-55729-global-it-data-engineer-expert-director",
    "_source": "new_jobs"
  },
  {
    "job_id": "4GHeUqb67eilko0QAAAAAA==",
    "job_title": "Simulation Engineer- Supply Chain",
    "employer_name": "Cencora",
    "employer_logo": null,
    "employer_website": "https://www.cencora.com",
    "job_publisher": "Cencora Careers",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://careers.cencora.com/us/en/job/R2523242/Simulation-Engineer-Supply-Chain?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Cencora Careers",
        "apply_link": "https://careers.cencora.com/us/en/job/R2523242/Simulation-Engineer-Supply-Chain?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/cCMwXHk6HcfhsFhWMSOkJvsMbRYzJa1VoQehAqbdWDeno7Y_Oz0JNQ?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/8a691ec6b6682787516e82bdcee83da8?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Our team members are at the heart of everything we do. At Cencora, we are united in our responsibility to create healthier futures, and every person here is essential to us being able to deliver on that purpose. If you want to make a difference at the center of health, come join our innovative company and help us improve the lives of people and animals everywhere. Apply today!\n\nJob Details\n\nWe are seeking a talented and experienced Supply Chain Simulation Engineer to lead and collaborate on the design, development, and deployment of tools and strategies that will enable more effective data-driven decision making.\n\nThis individual will provide guidance through advanced analytics modeling and optimizing facilities within the Supply Chain.\n\nThe Simulation Engineer should have a firm understanding of distribution operational and automation processes.\n\nThe ideal candidate will be a skilled communicator with experience telling compelling stories through data-driven insights.\n\nRoles and Responsibilities:\n• Create simulation models of our distribution centers that will help determine efficiency opportunities.\n• Understand and have experience with design and / or implementation of automation solutions such as conveyors, sorters, high speed picking and packaging lines, robotic work cells.\n• Work closely with other teams, such as Engineering and Operations, in the validation of the models and in the design of potential scenarios that will improve the total outcome.\n• Collaborate in developing a cost to serve model.\n• Implement and support the new inhouse simulation capabilities – process, tools, training.\n• Collaborate in the creation of business cases to close gaps and define capex requirements.\n• Provide advice and insights on improving existing simulation capabilities.\n• Design interactive business intelligence dashboards to share input and outputs.\n• Develop and train team to utilize self-service modeling functionality.\n• Stay up to date with modeling and simulations trends.\n• Perform other duties as assigned.\n\nEducation:\n• A Bachelors degree in Industrial Engineering, Operations Research, Quantitative Methods, Data Science or related field or equivalent professional qualification/workplace skills.\n• Master’s degree preferred.\n\nExperience:\n• Requires five (5) to seven (7) years of directly related and progressively responsible experience.\n• Hands-on experience using simulation and analytical tools to solve operational problems.\n• Practical experience with Simulation frameworks (discrete-event, agent-based) and technologies such as AnyLogic/Arena/EnterpriseDynamics/FlexSim/etc\n• Project Management / Agile hands-on experience.\n• Experience working in an Operations environment.\n• Experience with business intelligence tools (PowerBI, Tableau, Qlik).\n• Experience pulling and cleaning data from Cloud Platforms (Google, Azure), or Supply Chain Tools (including ERP, WMS, TMS, Inventory & Forecasting Tools).\n• Experience programming with data analytic tools such as SQL, Python, DataBricks, etc.\n• Experience transforming CAD data into simulation tools.\n• Experience building business cases and cost/benefit analysis to support strategic decision making.\n\nSkills and Abilities:\n• Strong analytical and critical thinking skills, with the ability to identify and resolve complex issues quickly and innovative. Experience leveraging analytic based approaches to problem solving, such as Statistical Process Control, Design of Experiments, Six Sigma, or other statistical analysis frameworks.\n• Team oriented and collaborative working style.\n• Growth mindset, positive attitude and strong interest in solving business challenges and adapting to a changing work environment.\n• Ability to communicate effectively both orally and in writing; ability to communicate (and work) effectively with people from different technical and business backgrounds, acting as a liaison, understanding, and appreciating different perspectives and translating into terms necessary for any group or individual to understand.\n• Presentation skills: ability to present and discuss technical information in a manner that establishes rapport, persuades others, and establishes understanding for technical and non-technical audiences.\n• Strong organizational skills; attention to detail.\n• Must be able to interact well with others both directly (face-to-face) and remotely within a multi-discipline shared work environment.\n• Ability to influence through the use of data and insights while showing tactful discretion with difficult/sensitive information.\n• Travel required per project, estimated at 2 weeks per quarter.\n• Ability to manage multiple projects\n\nWhat Cencora offers\n\nWe provide compensation, benefits, and resources that enable a highly inclusive culture and support our team members’ ability to live with purpose every day. In addition to traditional offerings like medical, dental, and vision care, we also provide a comprehensive suite of benefits that focus on the physical, emotional, financial, and social aspects of wellness. This encompasses support for working families, which may include backup dependent care, adoption assistance, infertility coverage, family building support, behavioral health solutions, paid parental leave, and paid caregiver leave. To encourage your personal growth, we also offer a variety of training programs, professional development resources, and opportunities to participate in mentorship programs, employee resource groups, volunteer activities, and much more. For details, visit https://www.virtualfairhub.com/cencora\n\nFull time\n\nSalary Range*\n\n$88,700 - 126,940\n• This Salary Range reflects a National Average for this job. The actual range may vary based on your locale. Ranges in Colorado/California/Washington/New York/Hawaii/Vermont/Minnesota/Massachusetts/Illinois State-specific locations may be up to 10% lower than the minimum salary range, and 12% higher than the maximum salary range.\n\nEqual Employment Opportunity\n\nCencora is committed to providing equal employment opportunity without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, disability, veteran status or membership in any other class protected by federal, state or local law.\n\nThe company’s continued success depends on the full and effective utilization of qualified individuals. Therefore, harassment is prohibited and all matters related to recruiting, training, compensation, benefits, promotions and transfers comply with equal opportunity principles and are non-discriminatory.\n\nCencora is committed to providing reasonable accommodations to individuals with disabilities during the employment process which are consistent with legal requirements. If you wish to request an accommodation while seeking employment, please call 888.692.2272 or email hrsc@cencora.com. We will make accommodation determinations on a request-by-request basis. Messages and emails regarding anything other than accommodations requests will not be returned\n\n.\nAffiliated Companies:\nAffiliated Companies: AmerisourceBergen Drug Corporation",
    "job_is_remote": false,
    "job_posted_at": "12 days ago",
    "job_posted_at_timestamp": 1770249600,
    "job_posted_at_datetime_utc": "2026-02-05T00:00:00.000Z",
    "job_location": "W CNSHOHOCKEN, PA",
    "job_city": "Conshohocken",
    "job_state": "Pennsylvania",
    "job_country": "US",
    "job_latitude": 40.0792766,
    "job_longitude": -75.3015714,
    "job_benefits": [
      "health_insurance",
      "dental_coverage"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D4GHeUqb67eilko0QAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "The ideal candidate will be a skilled communicator with experience telling compelling stories through data-driven insights",
        "A Bachelors degree in Industrial Engineering, Operations Research, Quantitative Methods, Data Science or related field or equivalent professional qualification/workplace skills",
        "Requires five (5) to seven (7) years of directly related and progressively responsible experience",
        "Hands-on experience using simulation and analytical tools to solve operational problems",
        "Practical experience with Simulation frameworks (discrete-event, agent-based) and technologies such as AnyLogic/Arena/EnterpriseDynamics/FlexSim/etc",
        "Project Management / Agile hands-on experience",
        "Experience working in an Operations environment",
        "Experience with business intelligence tools (PowerBI, Tableau, Qlik)",
        "Experience pulling and cleaning data from Cloud Platforms (Google, Azure), or Supply Chain Tools (including ERP, WMS, TMS, Inventory & Forecasting Tools)",
        "Experience programming with data analytic tools such as SQL, Python, DataBricks, etc",
        "Experience transforming CAD data into simulation tools",
        "Experience building business cases and cost/benefit analysis to support strategic decision making",
        "Strong analytical and critical thinking skills, with the ability to identify and resolve complex issues quickly and innovative",
        "Experience leveraging analytic based approaches to problem solving, such as Statistical Process Control, Design of Experiments, Six Sigma, or other statistical analysis frameworks",
        "Growth mindset, positive attitude and strong interest in solving business challenges and adapting to a changing work environment",
        "Ability to communicate effectively both orally and in writing; ability to communicate (and work) effectively with people from different technical and business backgrounds, acting as a liaison, understanding, and appreciating different perspectives and translating into terms necessary for any group or individual to understand",
        "Presentation skills: ability to present and discuss technical information in a manner that establishes rapport, persuades others, and establishes understanding for technical and non-technical audiences",
        "Strong organizational skills; attention to detail",
        "Must be able to interact well with others both directly (face-to-face) and remotely within a multi-discipline shared work environment"
      ],
      "Benefits": [
        "We provide compensation, benefits, and resources that enable a highly inclusive culture and support our team members’ ability to live with purpose every day",
        "In addition to traditional offerings like medical, dental, and vision care, we also provide a comprehensive suite of benefits that focus on the physical, emotional, financial, and social aspects of wellness",
        "This encompasses support for working families, which may include backup dependent care, adoption assistance, infertility coverage, family building support, behavioral health solutions, paid parental leave, and paid caregiver leave",
        "To encourage your personal growth, we also offer a variety of training programs, professional development resources, and opportunities to participate in mentorship programs, employee resource groups, volunteer activities, and much more",
        "Salary Range*",
        "$88,700 - 126,940",
        "This Salary Range reflects a National Average for this job"
      ],
      "Responsibilities": [
        "This individual will provide guidance through advanced analytics modeling and optimizing facilities within the Supply Chain",
        "The Simulation Engineer should have a firm understanding of distribution operational and automation processes",
        "Create simulation models of our distribution centers that will help determine efficiency opportunities",
        "Understand and have experience with design and / or implementation of automation solutions such as conveyors, sorters, high speed picking and packaging lines, robotic work cells",
        "Work closely with other teams, such as Engineering and Operations, in the validation of the models and in the design of potential scenarios that will improve the total outcome",
        "Collaborate in developing a cost to serve model",
        "Implement and support the new inhouse simulation capabilities – process, tools, training",
        "Collaborate in the creation of business cases to close gaps and define capex requirements",
        "Provide advice and insights on improving existing simulation capabilities",
        "Design interactive business intelligence dashboards to share input and outputs",
        "Develop and train team to utilize self-service modeling functionality",
        "Stay up to date with modeling and simulations trends",
        "Perform other duties as assigned",
        "Team oriented and collaborative working style",
        "Ability to influence through the use of data and insights while showing tactful discretion with difficult/sensitive information",
        "Travel required per project, estimated at 2 weeks per quarter",
        "Ability to manage multiple projects"
      ]
    },
    "job_onet_soc": "13108100",
    "job_onet_job_zone": "4",
    "id": "careers-cencora-com-us-en-job-r2523242-simulation-engineer-supply-chain",
    "_source": "new_jobs"
  },
  {
    "job_id": "QMFI59Aeon5OiMxQAAAAAA==",
    "job_title": "Data Solutions Engineer",
    "employer_name": "Early Career",
    "employer_logo": null,
    "employer_website": null,
    "job_publisher": "Citi Careers",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://jobs.citi.com/job/irving/data-solutions-engineer/287/91594717280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Citi Careers",
        "apply_link": "https://jobs.citi.com/job/irving/data-solutions-engineer/287/91594717280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=12272bb5413dda94&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/data-solutions-engineer-citi-JV_IC1140006_KO0,23_KE24,28.htm?jl=1010030029481&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "SimplyHired",
        "apply_link": "https://www.simplyhired.com/job/-ZBW4eiGrDb3Dr5czTYeI2QaJErXFTVKY7CiC8HcO-gC_AN4pjITwg?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "LinkedIn",
        "apply_link": "https://www.linkedin.com/jobs/view/data-solutions-engineer-at-citi-4370775693?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Experteer",
        "apply_link": "https://us.experteer.com/career/view-jobs/data-solutions-engineer-irving-tx-usa-56103968?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "BeBee",
        "apply_link": "https://us.bebee.com/job/18342d1b3a5230bb8ebc6b74cb10e255?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "PowerToFly",
        "apply_link": "https://powertofly.com/jobs/detail/2498189?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "This Data Solutions Engineer (Applications Development Senior Programmer Analyst - C12) is responsible for building next-generation Data Engineering solutions. This intermediate-level position involves active participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. A key aspect of this role is liaising between business users and technologists to facilitate the exchange of information regarding solutions, including requirements and usage.\n\nResponsibilities:\n• Serve as an integral team member of our Data Engineering team, responsible for the design and development of Big Data solutions.\n• Partner with domain experts, product managers, analysts, and data scientists to develop robust Big Data pipelines in Hadoop or Snowflake environments.\n• Responsible for delivering a data-as-a-service framework.\n• Responsible for moving all legacy workloads to cloud platform.\n• Lead the migration of all legacy workloads to cloud platforms.\n• Engage with key stakeholders to elicit and document requirements, including detailed data flow specifications.\n• Assess appropriate solutions and collaborate with relevant teams to drive optimal implementations.\n• Work with data scientists to build client pipelines using heterogeneous sources and provide essential engineering services for data science applications.\n• Research and evaluate open-source technologies and components, recommending and integrating them into design and implementation efforts.\n• Act as a technical expert, mentoring other team members on Big Data and Cloud technology stacks.\n• Define comprehensive requirements for maintainability, testability, performance, security, quality, and usability across the data platform.\n• Drive the implementation of consistent patterns, reusable components, and coding standards for all data engineering processes.\n• Convert SAS-based pipelines into modern languages like PySpark and Scala for execution on Hadoop and non-Hadoop ecosystems.\n• Optimize Big Data applications on both Hadoop and non-Hadoop platforms for peak performance.\n• Evaluate new IT developments and evolving business requirements, recommending appropriate system alternatives and/or enhancements to current systems through analysis of business processes, systems, and industry standards.\n• Appropriately assess risk when making business decisions, demonstrating consideration for the firm's reputation and safeguarding Citigroup, its clients, and assets. This includes driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct, and business practices, and escalating, managing, and reporting control issues with transparency.\n\nRequired Qualifications:\n• 5+ years of experience with Hadoop and Big Data technologies\n• Demonstrated proficiency in Python, PySpark, and Scala, including practical experience with fundamental machine learning libraries\n• Experience in developing robust data solutions leveraging Google Cloud or AWS platforms; relevant certifications are preferred\n• Experience with SAS\n• Experience with containerization and related technologies (e.g., Docker, Kubernetes)\n• Comprehensive understanding of software engineering and data analytics\n• In-depth knowledge and hands-on experience with the Hadoop ecosystem and Big Data technologies (e.g., HDFS, MapReduce, Hive, Pig, Impala, Kafka, Kudu, Solr)\n• Knowledge of Agile (Scrum) development methodologies.\n• Strong development and automation skills.\n• System-level understanding of data structures, algorithms, distributed storage, and compute.\n• A proactive approach to solving complex business problems, complemented by strong interpersonal and teamwork skills.\n\nDesired Qualifications\n• Familiarity with Hadoop administration and Snowflake.\n• Proficiency in Java or additional experience with Apache Beam.\n\nEducation:\n• Bachelor’s degree/University degree or equivalent experience\n\nApplicants must be authorized to work in the U.S for this position; Citi will not sponsor applicants for U.S. work authorization for this role. Candidate must be located within commuting distance or be willing to relocate to the area.\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nPrimary Location:\nIrving Texas United States\n\n------------------------------------------------------\n\nPrimary Location Full Time Salary Range:\n$107,120.00 - $160,680.00\n\nIn addition to salary, Citi’s offerings may also include, for eligible employees, discretionary and formulaic incentive and retention awards. Citi offers competitive employee benefits, including: medical, dental & vision coverage; 401(k); life, accident, and disability insurance; and wellness programs. Citi also offers paid time off packages, including planned time off (vacation), unplanned time off (sick leave), and paid holidays. For additional information regarding Citi employee benefits, please visit citibenefits.com. Available offerings may vary by jurisdiction, job level, and date of hire.\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nFor complementary skills, please see above and/or contact the recruiter.\n\n------------------------------------------------------\n\nAnticipated Posting Close Date:\nFeb 24, 2026\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi’s EEO Policy Statement and the Know Your Rights poster.",
    "job_is_remote": false,
    "job_posted_at": "7 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Jacksonville, FL",
    "job_city": "Jacksonville",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 30.3297566,
    "job_longitude": -81.6591529,
    "job_benefits": [
      "health_insurance",
      "paid_time_off",
      "dental_coverage"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DQMFI59Aeon5OiMxQAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "5+ years of experience with Hadoop and Big Data technologies",
        "Demonstrated proficiency in Python, PySpark, and Scala, including practical experience with fundamental machine learning libraries",
        "Experience with SAS",
        "Experience with containerization and related technologies (e.g., Docker, Kubernetes)",
        "Comprehensive understanding of software engineering and data analytics",
        "In-depth knowledge and hands-on experience with the Hadoop ecosystem and Big Data technologies (e.g., HDFS, MapReduce, Hive, Pig, Impala, Kafka, Kudu, Solr)",
        "Knowledge of Agile (Scrum) development methodologies",
        "Strong development and automation skills",
        "System-level understanding of data structures, algorithms, distributed storage, and compute",
        "A proactive approach to solving complex business problems, complemented by strong interpersonal and teamwork skills",
        "Bachelor’s degree/University degree or equivalent experience",
        "Applicants must be authorized to work in the U.S for this position; Citi will not sponsor applicants for U.S. work authorization for this role",
        "Candidate must be located within commuting distance or be willing to relocate to the area",
        "Please see the requirements listed above",
        "For complementary skills, please see above and/or contact the recruiter"
      ],
      "Benefits": [
        "$107,120.00 - $160,680.00",
        "In addition to salary, Citi’s offerings may also include, for eligible employees, discretionary and formulaic incentive and retention awards",
        "Citi offers competitive employee benefits, including: medical, dental & vision coverage; 401(k); life, accident, and disability insurance; and wellness programs",
        "Citi also offers paid time off packages, including planned time off (vacation), unplanned time off (sick leave), and paid holidays"
      ],
      "Responsibilities": [
        "This intermediate-level position involves active participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team",
        "A key aspect of this role is liaising between business users and technologists to facilitate the exchange of information regarding solutions, including requirements and usage",
        "Serve as an integral team member of our Data Engineering team, responsible for the design and development of Big Data solutions",
        "Partner with domain experts, product managers, analysts, and data scientists to develop robust Big Data pipelines in Hadoop or Snowflake environments",
        "Responsible for delivering a data-as-a-service framework",
        "Responsible for moving all legacy workloads to cloud platform",
        "Lead the migration of all legacy workloads to cloud platforms",
        "Engage with key stakeholders to elicit and document requirements, including detailed data flow specifications",
        "Assess appropriate solutions and collaborate with relevant teams to drive optimal implementations",
        "Work with data scientists to build client pipelines using heterogeneous sources and provide essential engineering services for data science applications",
        "Research and evaluate open-source technologies and components, recommending and integrating them into design and implementation efforts",
        "Act as a technical expert, mentoring other team members on Big Data and Cloud technology stacks",
        "Define comprehensive requirements for maintainability, testability, performance, security, quality, and usability across the data platform",
        "Drive the implementation of consistent patterns, reusable components, and coding standards for all data engineering processes",
        "Convert SAS-based pipelines into modern languages like PySpark and Scala for execution on Hadoop and non-Hadoop ecosystems",
        "Optimize Big Data applications on both Hadoop and non-Hadoop platforms for peak performance",
        "Evaluate new IT developments and evolving business requirements, recommending appropriate system alternatives and/or enhancements to current systems through analysis of business processes, systems, and industry standards",
        "Appropriately assess risk when making business decisions, demonstrating consideration for the firm's reputation and safeguarding Citigroup, its clients, and assets",
        "This includes driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct, and business practices, and escalating, managing, and reporting control issues with transparency",
        "This job description provides a high-level review of the types of work performed"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "jobs-citi-com-job-irving-data-solutions-engineer-287-91594717280",
    "_source": "new_jobs"
  },
  {
    "job_id": "zwAG5QQq-v9l2VvrAAAAAA==",
    "job_title": "Data Analytics Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=23eaffa71bc9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=23eaffa71bc9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Data / Analytics Engineer to support the VHA Veteran Family Member Program Modernization initiative.\n\nKey Responsibilities\n\nBuild and maintain data pipelines and workflows\n\nSupport analytics, modeling, and visualization efforts\n\nEnsure data integrity, security, and alignment with VA architecture standards\n\nRequired Qualifications\n\nBachelor's degree\n\n5+ years in analytics, data engineering, and visualization tools such as Azure and Databricks\n\nAbility to work without sponsorship in the US indefinitely",
    "job_is_remote": false,
    "job_posted_at": "5 days ago",
    "job_posted_at_timestamp": 1770854400,
    "job_posted_at_datetime_utc": "2026-02-12T00:00:00.000Z",
    "job_location": "Lake Charles, LA",
    "job_city": "Lake Charles",
    "job_state": "Louisiana",
    "job_country": "US",
    "job_latitude": 30.2265949,
    "job_longitude": -93.2173758,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DzwAG5QQq-v9l2VvrAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's degree",
        "5+ years in analytics, data engineering, and visualization tools such as Azure and Databricks",
        "Ability to work without sponsorship in the US indefinitely"
      ],
      "Responsibilities": [
        "Build and maintain data pipelines and workflows",
        "Support analytics, modeling, and visualization efforts",
        "Ensure data integrity, security, and alignment with VA architecture standards"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "ObQrQ-xXvc7iMgweAAAAAA==",
    "job_title": "Staff Data Engineer – Cloud Data Platform",
    "employer_name": "01 Calix North America",
    "employer_logo": null,
    "employer_website": null,
    "job_publisher": "Workday",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://calix.wd1.myworkdayjobs.com/en-US/External/job/Staff-Data-Engineer---Cloud-Data-Platform_R-10714?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Workday",
        "apply_link": "https://calix.wd1.myworkdayjobs.com/en-US/External/job/Staff-Data-Engineer---Cloud-Data-Platform_R-10714?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Please note that all emails from Calix will come from a @calix.com email address. If you receive a communication that you think may not be from Calix, please report it to us at talentandculture@calix.com. This is a remote position that could be based anywhere in the United States. Calix is leading a service provider transformation to deliver a differentiated subscriber experience around the Smart Home and Business, while monetizing their network using Role based Cloud Services, Telemetry, Analytics, Automation, and the deployment of Software Driven Adaptive networks. As part of a high performing global team, the right candidate will play a significant role as Calix Cloud Data Engineer involved in architecture design, implementation, technical leadership in data ingestion, extraction, transformation and analytics. Responsibilities and Duties: Work closely with Cloud product owners to understand, analyze product requirements and provide feedback. Develop conceptual, logical, physical models and meta data solutions. Design and manage an array of data design deliverables including data models, data diagrams, data flows and corresponding data dictionary documentations. Determine database structural requirements by analyzing client operations, applications, and data from existing systems. Technical leadership of software design in meeting requirements of service stability, reliability, scalability, and security Guiding technical discussions within engineer group and making technical recommendations. Design review and code review with peer engineers Guiding testing architecture for large scale data ingestion and transformations. Customer facing engineering role in debugging and resolving field issues. Qualifications: This role may be required to travel and attend face-to-face meetings and Calix sponsored events. 10+ years of development experience performing Data modeling, master data management and building ETL/data pipeline implementations. Cloud Platforms: Proficiency in both Google Cloud Platform (GCP) services (BigQuery, Dataflow, Dataproc, PubSub/Kafka, Cloud Storage) and AWS Big Data Technologies: Knowledge of big data processing frameworks such as Apache Spark ,Flink . Programming Languages: Strong knowledge of SQL and at least one programming language (Python, Java, or Scala),DBT. Data Visualization: Experience with BI tools such as Google Data Studio, Looker, ThoughtSpot, and using BigQuery BI Engine for optimized reporting Problem Solving: Strong analytical and troubleshooting skills, particularly in complex data scenarios. Collaboration: Ability to work effectively in a team environment and engage with cross-functional teams. Communication: Proficient in conveying complex technical concepts to stakeholders. Knowledge of data governance, security best practices, and compliance regulations in both GCP and AWS environments. Bachelor’s degree in Computer Science, Information Technology or a related field. Location: Remote-based position located in the United States. #LI-Remote The base pay range for this position varies based on the geographic location. More information about the pay range specific to candidate location and other factors will be shared during the recruitment process. Individual pay is determined based on location of residence and multiple factors, including job-related knowledge, skills and experience. San Francisco Bay Area: 156,400 - 265,700 USD Annual All Other US Locations: 136,000 - 231,000 USD Annual As a part of the total compensation package, this role may be eligible for a bonus. For information on our benefits click here. PLEASE NOTE: All emails from Calix will come from a '@calix.com' email address. Please verify and confirm any communication from Calix prior to disclosing any personal or financial information. If you receive a communication that you think may not be from Calix, please report it to us at talentandculture@calix.com. Calix delivers a broadband platform and managed services that enable our customers to improve life one community at a time. We’re at the forefront of a once in a generational change in the broadband industry. Join us as we innovate, help our customers reach their potential, and connect underserved communities with unrivaled digital experiences. This is the Calix mission - to enable BSPs of all sizes to Simplify. Innovate. Grow. To learn more, visit the Calix web site at www.calix.com To learn more about our international job opportunities, please visit our International Careers Page If you are a person with a disability needing assistance with the application process please: Email us at calix.interview@calix.com; or Call us at +1 (408) 514-3000. Calix is a Drug Free Workplace. You may access a copy of Calix Candidate Privacy Policy HERE and other Calix Privacy Policies HERE.",
    "job_is_remote": false,
    "job_posted_at": "7 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Remote, OR",
    "job_city": "Remote",
    "job_state": "Oregon",
    "job_country": "US",
    "job_latitude": 43.005945499999996,
    "job_longitude": -123.8925908,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DObQrQ-xXvc7iMgweAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "10+ years of development experience performing Data modeling, master data management and building ETL/data pipeline implementations",
        "Cloud Platforms: Proficiency in both Google Cloud Platform (GCP) services (BigQuery, Dataflow, Dataproc, PubSub/Kafka, Cloud Storage) and AWS Big Data Technologies: Knowledge of big data processing frameworks such as Apache Spark ,Flink ",
        "Programming Languages: Strong knowledge of SQL and at least one programming language (Python, Java, or Scala),DBT",
        "Data Visualization: Experience with BI tools such as Google Data Studio, Looker, ThoughtSpot, and using BigQuery BI Engine for optimized reporting Problem Solving: Strong analytical and troubleshooting skills, particularly in complex data scenarios",
        "Collaboration: Ability to work effectively in a team environment and engage with cross-functional teams",
        "Communication: Proficient in conveying complex technical concepts to stakeholders",
        "Knowledge of data governance, security best practices, and compliance regulations in both GCP and AWS environments",
        "Bachelor’s degree in Computer Science, Information Technology or a related field"
      ],
      "Benefits": [
        "#LI-Remote The base pay range for this position varies based on the geographic location",
        "More information about the pay range specific to candidate location and other factors will be shared during the recruitment process",
        "Individual pay is determined based on location of residence and multiple factors, including job-related knowledge, skills and experience",
        "San Francisco Bay Area: 156,400 - 265,700 USD Annual All Other US Locations: 136,000 - 231,000 USD Annual As a part of the total compensation package, this role may be eligible for a bonus"
      ],
      "Responsibilities": [
        "As part of a high performing global team, the right candidate will play a significant role as Calix Cloud Data Engineer involved in architecture design, implementation, technical leadership in data ingestion, extraction, transformation and analytics",
        "Responsibilities and Duties: Work closely with Cloud product owners to understand, analyze product requirements and provide feedback",
        "Develop conceptual, logical, physical models and meta data solutions",
        "Design and manage an array of data design deliverables including data models, data diagrams, data flows and corresponding data dictionary documentations",
        "Determine database structural requirements by analyzing client operations, applications, and data from existing systems",
        "Technical leadership of software design in meeting requirements of service stability, reliability, scalability, and security Guiding technical discussions within engineer group and making technical recommendations",
        "Design review and code review with peer engineers Guiding testing architecture for large scale data ingestion and transformations",
        "Customer facing engineering role in debugging and resolving field issues",
        "Qualifications: This role may be required to travel and attend face-to-face meetings and Calix sponsored events"
      ]
    },
    "job_onet_soc": "15113200",
    "job_onet_job_zone": "4",
    "id": "calix-wd1-myworkdayjobs-com-en-us-external-job-staff-data-engineer-cloud-data-platform_r-10714",
    "_source": "new_jobs"
  },
  {
    "job_id": "N9VeVo-USprwDr2HAAAAAA==",
    "job_title": "Cloud and Business Intelligence (BI) Engineer",
    "employer_name": "Wintrio",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBXOxoJDJA3G51Q89kFt81z1hGGuVeYZ9CRPD_&s=0",
    "employer_website": "https://www.wintrio.com",
    "job_publisher": "Glassdoor",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.glassdoor.com/job-listing/cloud-and-business-intelligence-bi-engineer-wintrio-JV_KO0,43_KE44,51.htm?jl=1006714706313&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Glassdoor",
        "apply_link": "https://www.glassdoor.com/job-listing/cloud-and-business-intelligence-bi-engineer-wintrio-JV_KO0,43_KE44,51.htm?jl=1006714706313&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Dice",
        "apply_link": "https://www.dice.com/job-detail/50c39ca0-9bfb-4e2a-ade1-c22cef1ff471?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Indeed",
        "apply_link": "https://www.indeed.com/viewjob?jk=a7f918cb006f50e7&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "Freelanly",
        "apply_link": "https://freelanly.com/company/lalamove/jobs/business-intelligence-bi-engineer-lalamove?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": true
      },
      {
        "publisher": "Lensa",
        "apply_link": "https://lensa.com/job-v1/boeing/remote/business-intelligence-engineer/8dd85046423dcaae17442b16da74e80d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      },
      {
        "publisher": "USA Remote Job Ca MySmartPros",
        "apply_link": "https://ca.mysmartpros.com/job/business-intelligence-bi-developer-engineer-needed/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "Data Science/BI/Cloud Projects Bentonville, AR\n\nCompany Overview:\n\nWintrio is a leading provider of cloud managed services, agile software development, DevOps, systems engineering, IT service management and risk analytics. We work collaboratively with our customers to solve their biggest challenges through a commitment to delivering innovation, agility, and maximum value. Our employees are empowered to think outside of the box and provide innovative solutions to our customers and provide measurable cost saving.\n\nRequirements:\n• The candidate MUST HAVE Business Intelligence (BI), Enterprise Data Warehousing (EDW), and ETL type background. The candidate must have led and managed BI and EDW initiatives with an ability to manage a demanding client by proposing alternate solutions. This type of critical thinking comes from experience and exposure in this domain that you grow after being in the industry for 8+ years.\n• Deep hands-on MS Power BI experience is a MUST.\n• Deep and Broad BI, EDW, and ETL type background is a MUST.\n• The candidate must be well-versed in cloud solution technologies like AWS, Microsoft Azure, etc.\n• Bachelor’s or MS degree in Engineering, Computer Science, and/or related field.\n• 10+ years of industry experience; preferably, a candidate should have Supply Chain and Consumer Goods background working for large US retailers.\n• Strong analytical and problem solving skills.\n• Excellent written and verbal communication, and presentation skills.\n• Ability to regularly interact with customer, discuss and design requirements.\n• Ability to hold grounds in complex and tough discussions. Remain objective and goal focused in all phases of project.\n• Ability to communicate with offshore team on regular basis and become a communication bridge between customer and dev team.\n• Ability to organize raw data in spreadsheets and perform basic statistical analysis.\n• Ability to Work effectively in fast-paced, team-oriented, rapidly changing environment.\n• Ability to learn and efficiently use a service tool BI tool like Power BI\n• Expertise in relational databases and schema design.\n• Familiarity with BI models, star schema.\n• Ability to create BI reports examples, prototypes and demonstrations autonomously.\n• Wintrio LLC’s Benefits:\n• Medical insurance\n• Dental Insurance\n• Vision Insurance\n• Flexible Spending Account (FSA) – You may elect to participate in the FSA plan\n• Health Savings Account (HSA) – If you elect to participate in an HDHP plan, you can enroll in the available HSA Program.\n• 401K and Retirement Savings Account\n• Annual Bonus and Profit Sharing – Based upon individual performance, client feedback, and business development results\n• Vacation – Company paid vacation and federal holidays followed by the client\n• Employee Assistance Program (EAP) – Through available sponsors the 24 hours EAP program.\n• Life and Personal Accident Insurance – Both are part of your benefit package and equal 1x your annual earnings ($15,000 minimum; $50,000 maximum); Voluntary Life and Personal Accident Insurance is optional.\n• Voluntary Disability Insurance – Both short and Long-term disability insurance is optional\n• Training – An abundance of training resources can be found on the Employee Service Center.\n\nWintrio is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
    "job_is_remote": false,
    "job_posted_at": "5 days ago",
    "job_posted_at_timestamp": 1770854400,
    "job_posted_at_datetime_utc": "2026-02-12T00:00:00.000Z",
    "job_location": "United States",
    "job_city": null,
    "job_state": null,
    "job_country": "US",
    "job_latitude": 38.794595199999996,
    "job_longitude": -106.5348379,
    "job_benefits": [
      "paid_time_off",
      "dental_coverage",
      "health_insurance"
    ],
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DN9VeVo-USprwDr2HAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": "YEAR",
    "job_highlights": {
      "Qualifications": [
        "The candidate MUST HAVE Business Intelligence (BI), Enterprise Data Warehousing (EDW), and ETL type background",
        "The candidate must have led and managed BI and EDW initiatives with an ability to manage a demanding client by proposing alternate solutions",
        "This type of critical thinking comes from experience and exposure in this domain that you grow after being in the industry for 8+ years",
        "Deep hands-on MS Power BI experience is a MUST",
        "Deep and Broad BI, EDW, and ETL type background is a MUST",
        "The candidate must be well-versed in cloud solution technologies like AWS, Microsoft Azure, etc",
        "Bachelor’s or MS degree in Engineering, Computer Science, and/or related field",
        "10+ years of industry experience; preferably, a candidate should have Supply Chain and Consumer Goods background working for large US retailers",
        "Strong analytical and problem solving skills",
        "Excellent written and verbal communication, and presentation skills",
        "Ability to regularly interact with customer, discuss and design requirements",
        "Ability to hold grounds in complex and tough discussions",
        "Ability to organize raw data in spreadsheets and perform basic statistical analysis",
        "Ability to Work effectively in fast-paced, team-oriented, rapidly changing environment",
        "Ability to learn and efficiently use a service tool BI tool like Power BI",
        "Expertise in relational databases and schema design",
        "Familiarity with BI models, star schema",
        "Ability to create BI reports examples, prototypes and demonstrations autonomously"
      ],
      "Benefits": [
        "Wintrio LLC’s Benefits:",
        "Medical insurance",
        "Dental Insurance",
        "Vision Insurance",
        "Flexible Spending Account (FSA) – You may elect to participate in the FSA plan",
        "Health Savings Account (HSA) – If you elect to participate in an HDHP plan, you can enroll in the available HSA Program",
        "401K and Retirement Savings Account",
        "Annual Bonus and Profit Sharing – Based upon individual performance, client feedback, and business development results",
        "Vacation – Company paid vacation and federal holidays followed by the client",
        "Employee Assistance Program (EAP) – Through available sponsors the 24 hours EAP program",
        "Life and Personal Accident Insurance – Both are part of your benefit package and equal 1x your annual earnings ($15,000 minimum; $50,000 maximum); Voluntary Life and Personal Accident Insurance is optional",
        "Voluntary Disability Insurance – Both short and Long-term disability insurance is optional",
        "Training – An abundance of training resources can be found on the Employee Service Center"
      ],
      "Responsibilities": [
        "Remain objective and goal focused in all phases of project",
        "Ability to communicate with offshore team on regular basis and become a communication bridge between customer and dev team"
      ]
    },
    "job_onet_soc": "15119900",
    "job_onet_job_zone": "4",
    "id": "www-glassdoor-com-job-listing-cloud-and-business-intelligence-bi-engineer-wintrio-jv_ko0-43_ke44-51-htm",
    "_source": "new_jobs"
  },
  {
    "job_id": "uuiihkAJSRtJByehAAAAAA==",
    "job_title": "Senior Data Analytics Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=04813c62bcb3&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=04813c62bcb3&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Senior Data Analytics Engineer to join their Data Solutions team.\n\nKey Responsibilities\n\nLead data analytics projects to build innovative solutions while ensuring adherence to budget, schedule, and scope\n\nMentor members in the Analytics Center of Excellence and assist with data catalog and visualization software oversight\n\nDrive data and analytics solutions from conception to deployment with clear ROI impact\n\nRequired Qualifications\n\nBachelor's degree in computer or information science preferred or relevant experience\n\n5+ years of relevant experience in a data-driven professional setting\n\nStrong command of databases and SQL, with proficiency in Python or R for data manipulation and analysis\n\nThorough understanding of project management principles and information technology practices\n\nStrong data analytics background, including experience with SQL, Snowflake Database, Azure cloud, and data visualization tools",
    "job_is_remote": false,
    "job_posted_at": "4 days ago",
    "job_posted_at_timestamp": 1770940800,
    "job_posted_at_datetime_utc": "2026-02-13T00:00:00.000Z",
    "job_location": "Southport, IN",
    "job_city": "Southport",
    "job_state": "Indiana",
    "job_country": "US",
    "job_latitude": 39.6618814,
    "job_longitude": -86.1166506,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DuuiihkAJSRtJByehAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "5+ years of relevant experience in a data-driven professional setting",
        "Strong command of databases and SQL, with proficiency in Python or R for data manipulation and analysis",
        "Thorough understanding of project management principles and information technology practices",
        "Strong data analytics background, including experience with SQL, Snowflake Database, Azure cloud, and data visualization tools"
      ],
      "Responsibilities": [
        "Lead data analytics projects to build innovative solutions while ensuring adherence to budget, schedule, and scope",
        "Mentor members in the Analytics Center of Excellence and assist with data catalog and visualization software oversight",
        "Drive data and analytics solutions from conception to deployment with clear ROI impact"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "8JZA4-i-u69bI9q_AAAAAA==",
    "job_title": "Senior Analytics Developer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=e89889122b9c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=e89889122b9c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Senior Analytics Developer, Brokerage & Ledger Product Data Science.\n\nKey Responsibilities\n\nDesign, build, and maintain high-quality analytical data models for brokerage and ledger workflows\n\nOwn critical datasets that support client-facing metrics, operational decision-making, and regulatory reporting\n\nCollaborate with cross-functional teams to translate stakeholder needs into durable data solutions\n\nRequired Qualifications\n\nExperience working with large, complex analytical datasets in a production environment\n\nStrong SQL skills and experience building analytical models or data marts\n\nProduct-oriented mindset focused on data usability and long-term ownership\n\nFamiliarity with modern analytics tooling such as dbt, Airflow, Python, and cloud data warehouses\n\nExperience in financial services, trading, or accounting is a plus",
    "job_is_remote": false,
    "job_posted_at": "6 days ago",
    "job_posted_at_timestamp": 1770768000,
    "job_posted_at_datetime_utc": "2026-02-11T00:00:00.000Z",
    "job_location": "Davie, FL",
    "job_city": "Davie",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 26.076478299999998,
    "job_longitude": -80.25211569999999,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D8JZA4-i-u69bI9q_AAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Experience working with large, complex analytical datasets in a production environment",
        "Strong SQL skills and experience building analytical models or data marts",
        "Product-oriented mindset focused on data usability and long-term ownership",
        "Familiarity with modern analytics tooling such as dbt, Airflow, Python, and cloud data warehouses"
      ],
      "Responsibilities": [
        "Design, build, and maintain high-quality analytical data models for brokerage and ledger workflows",
        "Own critical datasets that support client-facing metrics, operational decision-making, and regulatory reporting",
        "Collaborate with cross-functional teams to translate stakeholder needs into durable data solutions"
      ]
    },
    "job_onet_soc": "43911100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  },
  {
    "job_id": "Hh3sYVJawgugevAGAAAAAA==",
    "job_title": "Thermal Analysis Engineer",
    "employer_name": "VirtualVocations",
    "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxZcedD_3dF93ViStyNIWTQoxuaUqovO_AbE5a&s=0",
    "employer_website": "https://www.virtualvocations.com",
    "job_publisher": "Talent.com",
    "job_employment_type": "Full-time",
    "job_employment_types": [
      "FULLTIME"
    ],
    "job_apply_link": "https://www.talent.com/view?id=02ae34287d13&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "job_apply_is_direct": false,
    "apply_options": [
      {
        "publisher": "Talent.com",
        "apply_link": "https://www.talent.com/view?id=02ae34287d13&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "is_direct": false
      }
    ],
    "job_description": "A company is looking for a Thermal Analysis Engineer for a fully remote contract position.\n\nKey Responsibilities\n\nDevelop and modify thermal models for reactor structures and evaluate thermal profiles\n\nAssess specific areas of challenge in configurations and provide recommendations for modifications\n\nCollaborate with design leads and analysis engineers to address component issues and provide feedback\n\nRequired Qualifications\n\nBachelor's degree in mechanical engineering or a relevant equivalent program\n\n5-10 years of relevant experience, with a preference for candidates with a PE license\n\nExperience in ASME BPVC Section III, Division 1, and high temperature applications\n\nQualification indoctrination to the client's quality program\n\nStrong integrity and teamwork orientation",
    "job_is_remote": false,
    "job_posted_at": "7 days ago",
    "job_posted_at_timestamp": 1770681600,
    "job_posted_at_datetime_utc": "2026-02-10T00:00:00.000Z",
    "job_location": "Ocala, FL",
    "job_city": "Ocala",
    "job_state": "Florida",
    "job_country": "US",
    "job_latitude": 29.185078299999997,
    "job_longitude": -82.1342596,
    "job_benefits": null,
    "job_google_link": "https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DHh3sYVJawgugevAGAAAAAA%3D%3D&vssid=jobs-detail-viewer",
    "job_salary": null,
    "job_min_salary": null,
    "job_max_salary": null,
    "job_salary_period": null,
    "job_highlights": {
      "Qualifications": [
        "Bachelor's degree in mechanical engineering or a relevant equivalent program",
        "5-10 years of relevant experience, with a preference for candidates with a PE license",
        "Experience in ASME BPVC Section III, Division 1, and high temperature applications",
        "Qualification indoctrination to the client's quality program",
        "Strong integrity and teamwork orientation"
      ],
      "Responsibilities": [
        "Develop and modify thermal models for reactor structures and evaluate thermal profiles",
        "Assess specific areas of challenge in configurations and provide recommendations for modifications",
        "Collaborate with design leads and analysis engineers to address component issues and provide feedback"
      ]
    },
    "job_onet_soc": "17214100",
    "job_onet_job_zone": "4",
    "id": "www-talent-com-view",
    "_source": "new_jobs"
  }
]